This is toolsmanual.info, produced by makeinfo version 4.2 from
toolsmanual.texi.

INFO-DIR-SECTION Development
START-INFO-DIR-ENTRY
* toolsmanual: (toolsmanual).      Developing software with GNU
END-INFO-DIR-ENTRY


File: toolsmanual.info,  Node: Data files with Automake,  Prev: Guile with Automake,  Up: Using Automake

Data files with Automake
========================

   To install data files, you should use the `DATA' primitive instead
of `SCRIPTS'. The main difference is that `DATA' will allow you to
install files in data installation locations, whereas `SCRIPTS' will
only allow you to install files in executable installation locations.

   Normally it is assumed that the files listed in `DATA' are written
by _you_ and are not generated by a program, therefore they are not
cleaned by default. If you want your data to be generated by a program,
you must provide a target for building the data, and you must also
mention the data file in `CLEANFILES' so that it's cleaned when you
type `make clean'. You should of course include the source for the
program and the appropriate lines in `Makefile.am' for building the
program. For example:
     noinst_PROGRAMS = mkdata
     mkdata_SOURCES = mkdata.cc
     
     pkgdata_DATA = thedata
     CLEANFILES = $(pkgdata_DATA)
     
     thedata: mkdata
     <TAB> ./mkdata > thedata

Note that because the data generation program is a one-time-use program,
we don't want to install it so we list in in `noinst_*'.

   If your data files are written by hand, then all you need to do is
list them in the `DATA' assignment:
     pkgdata_DATA = foo1.dat foo2.dat foo3.dat

In general, you should install data files in `pkgdata'. However, if
your data files are configuration files or files that the program
modifies as it runs, they should be installed in other directories.
For more details *Note Installation standard directories::.


File: toolsmanual.info,  Node: Using Libtool,  Next: Using C effectively,  Prev: Using Automake,  Up: Top

Using Libtool
*************


File: toolsmanual.info,  Node: Using C effectively,  Next: Using Fortran effectively,  Prev: Using Libtool,  Up: Top

Using C effectively
*******************


File: toolsmanual.info,  Node: Using Fortran effectively,  Next: Internationalization,  Prev: Using C effectively,  Up: Top

Using Fortran effectively
*************************

   This chapter is devoted to Fortran. We will show you how to build
programs that combine Fortran and C or C++ code in a portable manner.
The main reason for wanting to do this is because there is a lot of
free software written in Fortran. If you browse
`http://www.netlib.org/' you will find a repository of lots of old,
archaic, but very reliable free sources.  These programs encapsulate a
lot of experience in numerical analysis research over the last couple
of decades, which is crucial to getting work done.  All of these sources
have been written in Fortran. As a developer today, if you know other
programming languages, it is unlikely that you will want to write
original code in Fortran. You may need, however, to use legacy Fortran
code, or the code of a neighbour who still writes in Fortran.

   The most portable way to mix Fortran with your C/C++ programs is to
translate the Fortran code to C with the `f2c' compiler and compile
everything with a C/C++ compiler. The `f2c' compiler is available at
`http://www.netlib.org/' and you will find it installed on a typical
Debian GNU/Linux system. Another alternative is to use the GNU Fortran
compiler `g77' with `g++' and `gcc'. This compiler is portable among
many platforms, so if you want to use a native Fortran compiler without
sacrificing portability, this is one way to do it.  Another way is to
use your OS's native Fortran compiler, which is usually called `f77',
*if* it is compatible with `g77' and `f77'.  Because performance is
also very important in numerical codes, a good strategy is to prefer to
use the native compiler if it is compatible, and support `f2c' and
`g77' as backups.

* Menu:

* Fortran compilers and linkage::
* Walkthrough a simple example::
* Portability problems with Fortran::
* Other Fortran dialects::
* Popular free software in Fortran::

   *Warning:* Optimization on the GNU `g77' compiler is still buggy in
many versions. In general, don't compile with optimization greater than
`-O' if you are using `g77'. On a Debian GNU/Linux system you might
find that it is actually more efficient to compile your Fortran source
code with `f2c' and `-O3' optimization, which is reliable, than using
`g77' with `-O' optimization.


File: toolsmanual.info,  Node: Fortran compilers and linkage,  Next: Walkthrough a simple example,  Prev: Using Fortran effectively,  Up: Using Fortran effectively

Fortran compilers and linkage
=============================

   The traditional Hello world program in Fortran looks like this:
     c....:++++++++++++++=
           PROGRAM MAIN
           PRINT*,'Hello World!'
           END

All lines that begin with `c' are comments. The first line is the
equivalent of `main()' in C. The second line says hello, and the third
line indicates the end of the code. It is important that all command
lines are indented by 7 spaces, otherwise the compiler will issue a
syntax error. Also, if you want to be ANSI compliant, you must write
your code all in caps. Nowadays most compilers don't care, but some may
still do.

   To compile this with `g77' (or `f77') you do something like:
     % g77 -o hello hello.f
     % hello

To compile it with the f2c translator:
     % f2c hello.f
     % gcc -o hello hello.c -lf2c -lm

where `-lf2c' links in the translator's system library.  In order for
this to work, you will have to make sure that the header file `f2c.h'
is present since the translated code in `hello.c' includes it with a
statement like
     #include "f2c.h"

which explicitly requires it to be present in the current working
directory.

   In this case, the `main' is written in Fortran. However most of the
Fortran you will be using will actually be subroutines and functions.
A subroutine looks like this:
     c....:++++++++++++++
           SUBROUTINE FHELLO (C)
           CHARACTER *(*) C
           PRINT*,'From Fortran: ',C
           RETURN
           END

This is the analog of a `void' function in C, because it takes
arguments but doesn't return anything. The prototype declaration is
"K&R" style: you list all the arguments in parenthesis, seperated with
commas, and you declare the types of the variables in the subsequent
lines.

   Suppose that this subroutine is saved as `fhello.f'. To call it from
C you need to know what it looks like from the point of the C compiler.
To find out type:
     % f2c -P fhello.f
     % cat fhello.P

You will find that this subroutine has the following prototype
declaration:
     extern int fhello_(char *c__, ftnlen c_len);

It may come as a surprise, and this is a moment of revelation, but
although in Fortran it appears that the subroutine is taking _one_
argument, in C it appears that it takes *two*! And this is what makes
it difficult to link code in a portable manner between C and Fortran. In
C, everything is what it appears to be. If a function takes two
arguments, then this means that down to the machine language level,
there is two arguments that are being passed around. In Fortran, things
are being hidden from you and done in a magic fashion. The Fortran
programmer thinks that he is passing one argument, but the compiler
compiles code that actually passes two arguments around. In this
particular case, the reason for this is that the argument you are
passing is a string. In Fortran, strings are not null-terminated, so
the `f2c' compiler passes the length of the string as an extra hidden
argument. This is called the "linkage method" of the compiler.
Unfortunately, linkage in Fortran is not standard, and there exist
compilers that handle strings differently. For example, some compilers
will prepend the string with a few bytes containing the length and pass
a pointer to the whole thing. This problem is not limitted to strings.
It happens in many other instances.  The `f2c' and `g77' compilers
follow compatible linkage, and we will use this linkage as the _ad-hoc
standard_. A few proprietary Fortran compilers like the Dec Alpha `f77'
and the Irix `f77' are also `f2c'-compatible. The reason for this is
because most of the compiler developers derived their code from `f2c'.
So although a standard was not really intended, there we have one
anyway.

   A few things to note about the above prototype declaration is that
the symbol `fhello' is in lower-case, even though in Fortran we write
everything uppercase, and it is appended with an underscore. On some
platforms, the proprietary Fortran compiler deviates from the `f2c'
standard either by forcing the name to be in upper-case or by omitting
the underscore. Fortunately, these cases can be detected with Autoconf
and can be worked around with conditional compilation. However, beyond
this, other portability problems, such as the strings issue, are too
involved to deal with and it is best in these cases that you fall back
to `f2c' or `g77'.  A final thing to note is that although `fhello'
doesn't return anything, it has return type `int' and not `void'. The
reason for this is that `int' is the default return type for functions
that are not declared. Therefore, to prevent compilation problems, in
case the user forgets to declare a Fortran function, `f2c' uses `int'
as the return type for subroutines.

   In Fortran parlance, a "subroutine" is what we'd call a `void'
function. To Fortran programmers in order for something to be a
"function" it has to return something back. This reflects on the syntax.
For example, here's a function that adds two numbers and returns the
result:
     c....:++++++++++++++++
           DOUBLE PRECISION FUNCTION ADD(A,B)
           DOUBLE PRECISION A,B
           ADD = A + B
           RETURN
           END

The name of the function is also the name of the return variable.  If
you run this one through `f2c -P' you will find that the C prototype is:
     extern doublereal add_(doublereal *a, doublereal *b);

There's plenty of things to note here:
   * The typenames being used are funny. `doublereal'? what's that!?
     These are all defined in a header file called `f2c.h' which you are
     supposed to include in your source code before declaring any
     prototypes.  We will show you how this is all done in the next
     section. The following table showes the types that are most likely
     to interest you. For more info, take a look at the `f2c.h' file
     itself:
            integer         ==> int
            real            ==> float
            doublereal      ==> double
            complex         ==> struct { real r,i; };
            doublecomplex   ==> struct { doublereal r,i; };

   * The arguments are passed by pointer. In Fortran all arguments are
     passed by reference. The `f2c' compiler implements this by passing
     the arguments by pointer. On the C/C++ level you may want to wrap
     the fortran routine with another routine so that you don't have to
     directly deal with pointers all of the time.

   * The value returned now is not an `int' but `doublereal'.  Of
     course, the name of the function is lower-case, as always, and
     there is an underscore at the end.

   A more interesting case is when we deal with complex numbers.
Consider a function that multiplies two complex numbers:
     c....:++++++++++++++++++++++++++++++
           COMPLEX*16 FUNCTION MULT(A,B)
           COMPLEX*16 A,B
           MULT = A*B
           RETURN
           END

As it turns out, the prototype for this function is:
     extern Z_f mult_ (doublecomplex *ret_val,
                       doublecomplex *a,
                       doublecomplex *b);

Because complex numbers are not a native type in C, they can not be
returned efficiently without going through at least one copy.
Therefore, for this special case the return value is placed as the
first argument in the prototype!  Actually despite many people's
feelings that Fortran must die, it is still the best language for
writing optimized functions that are perform complex arithmetic.


File: toolsmanual.info,  Node: Walkthrough a simple example,  Next: Portability problems with Fortran,  Prev: Fortran compilers and linkage,  Up: Using Fortran effectively

Walkthrough a simple example
============================

   _FIXME: Needs to be rewritten_


File: toolsmanual.info,  Node: Portability problems with Fortran,  Next: Other Fortran dialects,  Prev: Walkthrough a simple example,  Up: Using Fortran effectively

Portability problems with Fortran
=================================

   Fortran has a few portability problems.  There exist two important
Fortran standards: one that was written in 1966 and one that was written
in 1977. The 1977 standard is considered to be _the_ standard Fortran.
Most of the Fortran code is written by scientists who have never had any
formal training in computer programming. As a result, they often write
code that is dependent on vendor-extensions to the standard, and not
necessarily easy to port. The standard itself is to blame as well, since
it is sorely lacking in many aspects. For example, even though standard
Fortran has both `REAL' and `DOUBLE PRECISION' data types
(corresponding to `float' and `double') the standard only supports
single precision complex numbers (`COMPLEX'). Since many people will
also want double precision complex numbers, many vendors provided
extensions. Most commonly, the double precision complex number is called
`COMPLEX*16' but you might also see it called `DOUBLE COMPLEX'.  Other
such vendors extensions include providing a `flush' operation of some
sort for file I/O, and other such esoteric things.

   On the flip side, if you limit your Fortran code just to
number-crunching, then it becomes much easier to write portable code.
There are still a few things you should take into account however.
Some Fortran code has been written in the archaic 1966 style. An example
of such code is the `fftpack' package from `netlib'. The main problems
with such code are the following:
   * *Implicit types*: In Fortran 66, programmers were too lazy to
     define the types of their variables.  The idea was that the type
     was inferred by the first letter of the variable name. That's
     horror for you! The convention then is that all variables with
     initial `I,J,...,N' are type `INTEGER'. All others are `REAL' To
     compile this code with modern compilers it is necessary to add the
     following line to every source file:
          IMPLICIT DOUBLE PRECISION (A-H,O-Z)

     This instructs the compiler to do the right thing, which is to
     implicitly assume that all variables starting with `A-H' and `O-Z'
     are double precision and all other variables are integers.
     Alternatively you can say
          IMPLICIT REAL (A-H,O-Z)

     but it is very rarely that you will ever want to go with single
     precision.  Occasionally, you may find that the programmer breaks
     the rules. For example, in `fftpack' the array `IFAC' is supposed
     to be a `double' even though implicitly it is suggested to be an
     `int'. Such inconstances will probably show up in compiler errors.
     To fix them, declare the type of these variables explicitly. If
     it's an array then you do it like this:
          DOUBLE PRECISION IFAC(*)

     If the variable also appears in a `DIMENSION' declaration, then you
     should remove it from the declaration since the two can't coexist
     in _some_ compilers.

   * *Pseudo-pointers*: In archaic Fortran, a dimension declaration of
     the form:
          DIMENSION C(1)

     means that `C' has an unknown length, instead of meaning that it
     has length 1. In modern Fortran, this is an unacceptable notation
     and modern compilers do get confused over it. So all such
     instances must be replaced with the correct form which is:
          DIMENSION C(*)

     Such "arrays" in reality are just pointers. The user can reference
     the array as far as person likes, but of course, if person takes
     it too far, the program will either do the Wrong Thing or crash
     with a segmentation fault.

   * *Constants*: A most insidious problem has to do with constants and
     it is confined, to the best of my knowledge, to the GNU Fortran
     compiler, but it could very well be a problem in other compilers
     to which I have no access to.  Constants tend to appear in `DATA'
     statements or variable assignments.  The problem is that whenever
     a constant is in use, the context is never a determining factor
     for the "type" of the constant, unlike C which does automatic
     casting. Examples: `1' is always type `INTEGER',
     `9.435784839284958' is always type `REAL' (even if the additional
     precision specified is lost, and even when used in a `DOUBLE
     PRECISION' context such as being assigned to a `DOUBLE PRECISION'
     variable!). On the other hand, `1E0' is always `REAL' and `1D0' is
     always `DOUBLE PRECISION'.  If you want your code to be
     exclusively double precision, then you should scan the entire
     source for constants, and make sure that they all have the `D0'
     suffix at the end. Many compilers will tolerate this omission while
     others will not and go ahead and introduce single precision error
     to your computations leading to hard to find bugs.

   In general the code in `http://www.netlib.org/' is very reliable and
portable, but you do need to keep your eyes open for little problems
like the above.


File: toolsmanual.info,  Node: Other Fortran dialects,  Next: Popular free software in Fortran,  Prev: Portability problems with Fortran,  Up: Using Fortran effectively

Other Fortran dialects
======================

   There are many variants of Fortran like Fortran 90, and HPF.
Fortran 90 attempts, quite miserably, to make Fortran 77 more like C++.
HPF allows engineers to write numerical code that runs on parallel
computers. These variants should be avoided for two reasons:
  1. There are no free compilers for Fortran 90 or HPF.  If you happen
     to use a proprietary operating system, you might as well make use
     of proprietary compilers if they generate highly optimized code
     and that is important to you.  Nevertheless, in order for your
     software to be free in a useful way, it should be possible to
     compile it with free tools on a free operating system.  A common
     objection is that since there are no parallel computers running a
     free operating ysstem, the point is moot so one might as well use
     HPF or Fortran 90, if doing so is convenient.  This objection is
     based on a premise that is now out of date. Nowadays, it is
     possible to build parallel computers using commodity hardware, a
     modified version of the Linux kernel, called Beowulf, and the GNU
     system.  Parallelized software can also be free. Therefore both
     Fortran 90 and HPF should be avoided, whenever that is possible
     until we have a free compiler for them.

  2. Another problem with these variants is that they are ad hoc
     languages that have been invented to enable Fortran to do things
     that it can not do by design. Eventually, when engineers will like
     to do things that Fortran 90 can't do either, it will be necessary
     to extend Fortran again, rewrite the compilers and produce yet
     another variant. What engineers really need is a _real_ solid
     programming language, and a collection of well-designed scientific
     libraries written in that language.

Please don't contribute to the spread of these dialects. Instead
contribute infrastructure to better languages, like C and C++, to
support the features that compell you to use Fortran 90 or HPF.


File: toolsmanual.info,  Node: Popular free software in Fortran,  Prev: Other Fortran dialects,  Up: Using Fortran effectively

Popular free software in Fortran
================================

   _FIXME: New section. Needs to be written_


File: toolsmanual.info,  Node: Internationalization,  Next: Maintaining Documentation,  Prev: Using Fortran effectively,  Up: Top

Internationalization
********************

   _FIXME: Needs to be written_


File: toolsmanual.info,  Node: Maintaining Documentation,  Next: Portable shell programming,  Prev: Internationalization,  Up: Top

Maintaining Documentation
*************************

* Menu:

* Browsing documentation::
* Writing proper manuals::
* Introduction to Texinfo::
* Markup in Texinfo::
* GNU Emacs support for Texinfo::
* Writing man pages::
* Writing documentation with LaTeX::
* Creating a LaTeX package::
* Further reading about LaTeX::


File: toolsmanual.info,  Node: Browsing documentation,  Next: Writing proper manuals,  Prev: Maintaining Documentation,  Up: Maintaining Documentation

Browsing documentation
======================


File: toolsmanual.info,  Node: Writing proper manuals,  Next: Introduction to Texinfo,  Prev: Browsing documentation,  Up: Maintaining Documentation

Writing proper manuals
======================

   _FIXME: Advice on how to write a good manual_ _General stuff.
Reference manual vs user manual._ _When to write a manual._ _How to
structure a manual._ _Texinfo vs. Latex_ _Copyright issues._


File: toolsmanual.info,  Node: Introduction to Texinfo,  Next: Markup in Texinfo,  Prev: Writing proper manuals,  Up: Maintaining Documentation

Introduction to Texinfo
=======================


File: toolsmanual.info,  Node: Markup in Texinfo,  Next: GNU Emacs support for Texinfo,  Prev: Introduction to Texinfo,  Up: Maintaining Documentation

Markup in Texinfo
=================


File: toolsmanual.info,  Node: GNU Emacs support for Texinfo,  Next: Writing man pages,  Prev: Markup in Texinfo,  Up: Maintaining Documentation

GNU Emacs support for Texinfo
=============================


File: toolsmanual.info,  Node: Writing man pages,  Next: Writing documentation with LaTeX,  Prev: GNU Emacs support for Texinfo,  Up: Maintaining Documentation

Writing man pages
=================


File: toolsmanual.info,  Node: Writing documentation with LaTeX,  Next: Creating a LaTeX package,  Prev: Writing man pages,  Up: Maintaining Documentation

Writing documentation with LaTeX
================================


File: toolsmanual.info,  Node: Creating a LaTeX package,  Next: Further reading about LaTeX,  Prev: Writing documentation with LaTeX,  Up: Maintaining Documentation

Creating a LaTeX package
========================


File: toolsmanual.info,  Node: Further reading about LaTeX,  Prev: Creating a LaTeX package,  Up: Maintaining Documentation

Further reading about LaTeX
===========================


File: toolsmanual.info,  Node: Portable shell programming,  Next: Writing Autoconf macros,  Prev: Maintaining Documentation,  Up: Top

Portable shell programming
**************************


File: toolsmanual.info,  Node: Writing Autoconf macros,  Next: Legal issues with Free Software,  Prev: Portable shell programming,  Up: Top

Writing Autoconf macros
***********************


File: toolsmanual.info,  Node: Legal issues with Free Software,  Next: Philosophical issues,  Prev: Writing Autoconf macros,  Up: Top

Legal issues with Free Software
*******************************

   If you want to give your programs to other people or use programs
that were written by other people, then you need to worry about
copyright.  The main reason why `autoconf' and `automake' were developed
was to make sharing software easier. So, if you want to use these tools
to develop free software, it is important to understand copyright.  In
this chapter we will address the legal issues involved with releasing
software to the public. *Note Philosophical issues::, for a discussion
of the philosophical issues involved.

* Menu:

* Understanding Copyright::
* Software patents::
* Export restrictions on encryption software::


File: toolsmanual.info,  Node: Understanding Copyright,  Next: Software patents,  Prev: Legal issues with Free Software,  Up: Legal issues with Free Software

Understanding Copyright
=======================

   When you create an original work, like a computer program, or a
novel, and so on, the government automatically grants you a set of
legal rights called "copyright".  Copyright is the right to obstruct
others from _using_, _modifying_ and _redistributing_ your work. Anyone
that would like to use, modify or redistribute your work needs to enter
an agreement with you. By granting you this monopoly, the government
limits the freedom of the public to express themselves in ways that
involve infringing your copyright. The government justifies copyright
by claiming that it is a bargain that benefits the public because it
encourages the creation of more works.  (1) The holder of the
copyright, called the ""owner"", is the only person that can enforce
per copyright.

   Copyright ownership can be transfered to another person or
organization.  When a work is being developed by a team, it makes legal
sense to transfer the copyright to a single organization that can then
coordinate enforcement of the copyright. In the free software
community, some people assign their software to the Free Software
Foundation.  The arrangement is that copyright is transfered to the
FSF. The FSF then grants you all the rights back in the form of a
license agreement, and commits itself legally to distributing the work
only as free software.  If you want to do this, you should contact the
FSF for more information.  It is not a good idea to assign your
copyright to anyone else, unless you know what you are getting into. By
assigning you rights to someone and not getting any of those rights
back in the form of an agreement, you may place yourself in a position
where you are not allowed to use your own work.  Unfortunately, if you
are employed or a student in a University you have probably already
signed many of your rights away. Universities as well as companies like
to lay as much claim on any copyrightable work you produce as possible,
even work that you do as a hobby that has little to do with them.

   Because copyright does not allow your users to do much with your
software, other than have a copy, you need to give them permissions
that allow them to freely use, modify and redistribute it.  In the free
software community, we standardize on using a legal document, the "GNU
General Public License" to grant such permissions.  *Note Applying the
GPL::, for more details on how to use the GPL.

   Copyright covers mainly original works. However, it also introduces
the concept of "derived works". In general, if someone copies a portion
of your work into per work, then it becomes "derived work" of your
work, and both you and person share copyright interest on per work.

   If the only information that you give an impartial observer is a
copy of your work and a copy of per work, the observer has no
deterministic way of deciding whether or not per work is legally
derived from your work.  The legal term "derived work" refers to the
_process_ with which person created per work, rather than an actual
inherent property of the end-result of the effort.  Your copyright
interest is established by the fact that part of that process involved
_copying_ some of your work into per work (and then perhaps modifying
it, but that is not relevant to whether or not you have copyright
interest).

   So, if you and someone write two very similar programs, because the
programs are simple, then you don't have copyright interest in each
others work, because you both worked indepedently. If, however, the
reason for the similarity is that person copied your work, then you
have copyright interest on per work.  When that happens, person can
only distribute the resulting program (i.e. source code, or the
executable) under terms that are consistent with the terms with which
person was allowed to have a copy of your work and use it in per
program.

   The law is less clear about what happens if person refers to your
work without actually doing any copying. A judge will have to decide
this if it goes to court. This is why when you work on a free software
project, the only way to avoid liabilities like this is by not refering
to anyone else's work, unless per work is also free software. This is
one of the many ways that copyright obstructs cooperation between
citizens.

   Fortunately there is a legal precedent with derived work and user
interfaces.  The courts have decided that user interfaces, such as the
"application programming interface" (API) that a software library is
exporting to the programs that link to it can not be copyrighted. So,
if you want to clone a library, while it is not a good idea to refer to
the actual source code of the library, it is okey to refer to a
description of the interface that the library defines. It is best to do
this by reading the documentation, but if no documentation is available,
reading the header files is the next best thing.

   The concept of derived work is very slippery ground and has many gray
areas, especially when it pertains to linking libraries that other
people have written to your programs.  *Note The GPL and libraries::,
for more discussion on this issue.

   ---------- Footnotes ----------

   (1) The Free Software Foundation and many others however believe that
the current policies fall short of this justification and need to be
re-evaluated


File: toolsmanual.info,  Node: Software patents,  Next: Export restrictions on encryption software,  Prev: Understanding Copyright,  Up: Legal issues with Free Software

Software patents
================

   In addition to copyright law, there is another legal beast: the
patent law.  Unlike copyright, which you own automatically by the act
of creating the work, you don't get a patent unless you file an
application for it. If approved, the work is published but others must
pay you royalties in order to use it in any way.

   The problem with patents is that they cover algorithms, and if an
algorithm is patented you can neither write nor use an implementation
for it, without a license.  What makes it worse is that it is very
difficult and expensive to find out whether the algorithms that you use
are patented or will be patented in the future. What makes it insane is
that the patent office, in its infinite stupidity, has patented
algorithms that are very trivial with nothing innovative about them.
For example, the use of "backing store" in a multiprocesing window
system, like X11, is covered by patent 4,555,775. In the spring of
1991, the owner of the patent, AT&T, threatened to sue every member of
the X Consortium including MIT. Backing store is the idea that the
windowing system save the contents of all windows at all times. This
way, when a window is covered by another window and then exposed again,
it is redrawn by the windowing system, and not the code responsible for
the application. Other insane patents include the IBM patent 4,674,040
which covers "cut and paste between files" in a text editor. Recently,
a stupid corporation called "Wang" tried to take Netscape to court over
a patent that covered "bookmarks" and lost.

   Even though this situation is ridiculous, software patents are a
very serious problem because they are taken very seriously by the
judicial system. Unfortunately they are not taken equally seriously by
the patent office (also called PTO) itself. The more patents the PTO
approves, the more income the PTO makes. Therefore, the PTO is very
eager to let dubious patents through. After all, they figure that if
the patent is invalid, someone will knock it down in court eventually.

   It is not necessary for someone to have a solid case to get you into
trouble. The cost of litigation is often sufficient extortion to force
small bussinesses, non-profit organizations and individual software
developers to settle, even when there is not solid case. The only
defense against a patent attac is to prove that there is "prior art";
in other words, you need to show that what is described in the patent
had already been invented before the date on which the application for
that patent was filed. Unfortunately, this is costly, not guaranteed to
work, and the burden of proof rests with the victim of the attack.
Another defense is to make sure you don't have a lot of money. If you
are poor, lawyers are less likely to waste money suing you.

   Companies like to use software patents as strategic weapons for
applying extortion, which is unfortunately sanctioned by the law. They
build an arsenal of software patents by trying to pass whatever can get
through the Patent Office. Then years later, when they feel like it,
they can go through their patent arsenal and find someone to sue and
extort some cash.

   There have actually been patent attacks aimed directly against the
free sofwtare community. The GNU system does not include the Unix
`compress' utility because it infringes a patent, and the patent owner
has specifically targetted the volunteer that wrote a `compress'
program for the GNU project.  There may be more patent attacks in the
future.  On November of 1998 two internal memos were leaked from
Microsoft about our community. According to these memos, Microsoft
perceives the free software community as a competitor and they seem to
consider a patent-based attack among other things.  It is important to
note however that when an algorithm is patented, and, worse, when that
patent is asserted by the owner, this is an attack on _everyone_ that
writes software, not only to the free software community. This is why
it is not important who is being targetted in each specific incident.
Patents hurt all of us.


File: toolsmanual.info,  Node: Export restrictions on encryption software,  Prev: Software patents,  Up: Legal issues with Free Software

Export restrictions on encryption software
==========================================

   An additional legal burden to both copyrights and patents is
governmental boneheadedness over encryption algorithms. According to
the US government, a computer program implementing an encryption
algorithm is considered munition, therefore export-control laws on
munitions apply. What is not allowed under these laws is to export the
software outside the borders of the US. The government is pushing the
issue by claiming that making encryption software available on the
internet is the same thing as exporting it. Zimmermann, the author of a
popular encryption program, was sued by the government based on this
interpretation of the law.  However the government's position was not
tested at court because the government decided to drop the charges,
after dragging the case for a few years, long enough to send a message
of terror to the internet community.  The current wisdom seems to be
that it is okey to make encryption software available on the net
provided that you take strong measures that will prevent foreigners to
download your work. It should be noted however that doing so still _is_
taking a legal risk that could land you to federal prison in the
company of international smugglers of TOW missiles and M1 Abrams tanks.

   The reason why the government's attitude towards encryption is
unconstitutional is because it violates our inalienable right to freedom
of speech. It is the current policy of the government that publishing a
book containing the source code for encryption software is legal, but
publishing the exact same content in digital form is illegal. As the
internet increasingly becomes the library of the future, part of our
freedom will be lost. The reason why the government maintains such a
strange position today is because in the past they have tried to assert
that publishing encryption software _both_ digitally and on books is
illegal. When the RSA algorithm was discovered, the National Security
Agency (also known as NSA - No Such Agency) attempted to prevent the
inventors from publishing their discovery in journals and presenting it
at conferences. Judges understand books and conferences and the
government had to give up fighting that battle. They still haven't
given up on the electronic front however.

   Other countries also have restrictive laws against encryption. In
certain places, like France,  you are not be even allowed to run such
programs.  (1) The reason why governments are so paranoid of encryption
is because it is the key to a wide array of technologies that have the
potential to empower the individual citizens to an extent that makes
governments uncomfortable.  Encryption is routinely used now by human
rights activists operating on totalitarian countries. Encryption can
also be used to create an unsanctioned para-economy based on digital
cash, and allow individuals to carry out transcations and contracts
completely anonymously.  These prospects are not good news for Big
Brother.

   The Free Software Foundation is fighting the US government export
restrictions very effectively by asking volunteers in a free country to
develop free encryption software. The GNU Privacy Guard is now very
stable, and is already being used by software developers.  For more
information, see <http://www.gnupg.org/>.

   ---------- Footnotes ----------

   (1) The laws in France are now changing and they might be completely
different by the time you read this book


File: toolsmanual.info,  Node: Philosophical issues,  Next: Licensing Free Software,  Prev: Legal issues with Free Software,  Up: Top

Philosophical issues
********************

   The GNU development tools were written primarily to aid the
development and distribution of "free software" in the form of source
code distributions.  The philosophy of the GNU project, that software
should be free, is very important to the future of our community. Now
that free software systems, like GNU/Linux, have been noticed by the
mainstream media, our community will have to face many challenges to
our freedom.  We may have a free operating system today, but if we fail
to deal with these challenges, we will not have one tomorrow. What are
these challenges?  Three that we have already had to face are: secret
hardware, non-free libraries, and software patents. Who knows what else
we might have to face tomorrow. Will we respond to these challenges and
protect our freedom?  That depends on our philosophy.

   In this appendix we include a few articles written by Richard
Stallman that discuss the philosophical concerns that lead to the free
software movement. The text of these articles is included here with
permission from the following terms:

   *Copying Notice*
     Copyright (C) 1998 Free Software Foundation Inc
     59 Temple Place, Suite 330, Boston, MA 02111, USA
     Verbatim copying and distribution is permitted in any medium,
     provided this notice is preserved.

   All of these articles, and others are distributed on the web at:
`http://www.gnu.org/philosophy/index.html'

* Menu:

* The Right to Read::
* What is Free Software::
* Why software should not have owners::
* Why free software needs free documentation::
* Categories of software::
* Confusing words::


File: toolsmanual.info,  Node: The Right to Read,  Next: What is Free Software,  Prev: Philosophical issues,  Up: Philosophical issues

The Right to Read
=================

   _This article appeared in the February 1997 issue of Communications
of the ACM (Volume 40, Number 2)._

       (from "The Road To Tycho", a collection of articles about the
      antecedents of the Lunarian Revolution, published in Luna City in
         2096)

   For Dan Halbert, the road to Tycho began in college when Lissa Lenz
asked to borrow his computer. Hers had broken down, and unless she
could borrow another, she would fail her midterm project. There was no
one she dared ask, except Dan.

   This put Dan in a dilemma. He had to help her, but if he lent her his
computer, she might read his books. Aside from the fact that you could
go to prison for many years for letting someone else read your books,
the very idea shocked him at first. Like everyone, he had been taught
since elementary school that sharing books was nasty and wrong,
something that only pirates would do.

   And there wasn't much chance that the SPA, the Software Protection
Authority, would fail to catch him. In his software class, Dan had
learned that each book had a copyright monitor that reported when and
where it was read, and by whom, to Central Licensing. (They used this
information to catch reading pirates, but also to sell personal
interest profiles to retailers.) The next time his computer was
networked, Central Licensing would find out. He, as computer owner,
would receive the harshest punishment, for not taking pains to prevent
the crime.

   Of course, Lissa did not necessarily intend to read his books. She
might want the computer only to write her midterm. But Dan knew she
came from a middle-class family and could hardly afford the tuition,
let alone her reading fees. Reading his books might be the only way she
could graduate. He understood this situation; he himself had had to
borrow to pay for all the research papers he read. (10% of those fees
went to the researchers who wrote the papers; since Dan aimed for an
academic career, he could hope that his own research papers, if
frequently referenced, would bring in enough to repay this loan.)

   Later on, Dan would learn there was a time when anyone could go to
the library and read journal articles, and even books, without having to
pay. There were independent scholars who read thousands of pages
without government library grants. But in the 1990s, both commercial
and nonprofit journal publishers had begun charging fees for access.
By 2047, libraries offering free public access to scholarly literature
were a dim memory.

   There were ways, of course, to get around the SPA and Central
Licensing. They were themselves illegal. Dan had had a classmate in
software, Frank Martucci, who had obtained an illicit debugging tool,
and used it to skip over the copyright monitor code when reading books.
But he had told too many friends about it, and one of them turned him
in to the SPA for a reward (students deep in debt were easily tempted
into betrayal). In 2047, Frank was in prison, not for pirate reading,
but for possessing a debugger.

   Dan would later learn that there was a time when anyone could have
debugging tools. There were even free debugging tools available on CD
or downloadable over the net. But ordinary users started using them to
bypass copyright monitors, and eventually a judge ruled that this had
become their principal use in actual practice. This meant they were
illegal; the debuggers' developers were sent to prison.

   Programmers still needed debugging tools, of course, but debugger
vendors in 2047 distributed numbered copies only, and only to
officially licensed and bonded programmers. The debugger Dan used in
software class was kept behind a special firewall so that it could be
used only for class exercises.

   It was also possible to bypass the copyright monitors by installing a
modified system kernel. Dan would eventually find out about the free
kernels, even entire free operating systems, that had existed around
the turn of the century. But not only were they illegal, like
debuggers; you could not install one if you had one, without knowing
your computer's root password. And neither the FBI nor Microsoft
Support would tell you that.

   Dan concluded that he couldn't simply lend Lissa his computer. But he
couldn't refuse to help her, because he loved her. Every chance to
speak with her filled him with delight. And that she chose him to ask
for help, that could mean she loved him too.

   Dan resolved the dilemma by doing something even more unthinkable-he
lent her the computer, and told her his password. This way, if Lissa
read his books, Central Licensing would think he was reading them. It
was still a crime, but the SPA would not automatically find out about
it. They would only find out if Lissa reported him.

   Of course, if the school ever found out that he had given Lissa his
own password, it would be curtains for both of them as students,
regardless of what she had used it for. School policy was that any
interference with their means of monitoring students' computer use was
grounds for disciplinary action. It didn't matter whether you did
anything harmful. The offense was making it hard for the administrators
to check on you. They assumed this meant you were doing something else
forbidden, and they did not need to know what it was.

   Students were not usually expelled for this, not directly. Instead
they were banned from the school computer systems, and would inevitably
fail all their classes.

   Later, Dan would learn that this kind of university policy started
only in the 1980s, when university students in large numbers began
using computers. Previously, universities maintained a different
approach to student discipline; they punished activities that were
harmful, not those that merely raised suspicion.

   Lissa did not report Dan to the SPA. His decision to help her led to
their marriage, and also led them to question what they had been taught
about piracy as children. The couple began reading about the history of
copyright, about the Soviet Union and its restrictions on copying, and
even the original United States Constitution. They moved to Luna, where
they found others who had likewise gravitated away from the long arm of
the SPA. When the Tycho Uprising began in 2062, the universal right to
read soon became one of its central aims.


*Author's Note*

   The right to read is a battle being fought today. Although it may
take 50 years for our present way of life to fade into obscurity, most
of the specific laws and practices described above have already been
proposed, either by the Clinton Administration or by publishers.

   There is one exception: the idea that the FBI and Microsoft will keep
the root passwords for personal computers. This is an extrapolation
from the Clipper chip and similar Clinton Administration key-escrow
proposals, together with a long-term trend: computer systems are
increasingly set up to give absentee operators control over the people
actually using the computer system.

   The SPA, which actually stands for Software Publisher's Association,
is not today an official police force. Unofficially, it acts like one.
It invites people to inform on their coworkers and friends. Like the
Clinton Administration, it advocates a policy of collective
responsibility whereby computer owners must actively enforce copyright
or be punished.

   The SPA is currently threatening small Internet service providers,
demanding they permit the SPA to monitor all users. Most ISPs surrender
when threatened, because they cannot afford to fight back in court.
(Atlanta Journal-Constitution, 1 Oct 96, D3.) At least one ISP,
Community ConneXion in Oakland CA, refused the demand and was actually
sued. The SPA is said to have dropped this suit recently, but they are
sure to continue the campaign in various other ways.

   The university security policies described above are not imaginary.
For example, a computer at one Chicago-area university prints this
message when you log in (quotation marks are in the original):

     "This system is for the use of authorized users only. Individuals
     using this computer system without authority or in the excess of
     their authority are subject to having all their activities on this
     system monitored and recorded by system personnel. In the course of
     monitoring individuals improperly using this system or in the
     course of system maintenance, the activities of authorized user may
     also be monitored. Anyone using this system expressly consents to
     such monitoring and is advised that if such monitoring reveals
     possible evidence of illegal activity or violation of University
     regulations system personnel may provide the evidence of such
     monitoring to University authorities and/or law enforcement
     officials."

   This is an interesting approach to the Fourth Amendment: pressure
most everyone to agree, in advance, to waive their rights under it.


*References*

   * The administration's "White Paper": Information Infrastructure
     Task Force, Intellectual Property and the National Information
     Infrastructure: The Report of the Working Group on Intellectual
     Property Rights (1995).

   * `An explanation of the White Paper: The Copyright Grab', Pamela
     Samuelson, Wired, Jan. 1996

   * `Sold Out', James Boyle, New York Times, 31 March 1996

   * `Public Data or Private Data', Washington Post, 4 Nov 1996

   * Union for the Public Domain (http://www.public-domain.org/), a new
     organization which aims to resist and reverse the overextension of
     intellectual property powers.


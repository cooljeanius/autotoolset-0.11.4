\input texinfo

@c Copyright (C) 1998, 1999 Eleftherios Gkioulekas <lf@amath.washington.edu>
@c  
@c Permission is granted to make and distribute verbatim copies of
@c this manual provided the copyright notice and this permission notice
@c are preserved on all copies.
@c  
@c Permission is granted to process this file through TeX and print the
@c results, provided the printed document carries copying permission
@c notice identical to this one except for the removal of this paragraph
@c (this paragraph not being relevant to the printed manual).
@c  
@c Permission is granted to copy and distribute modified versions of this
@c manual under the conditions for verbatim copying, provided that the
@c entire resulting derived work is distributed under the terms of a 
@c permission notice identical to this one.
@c  
@c Permission is granted to copy and distribute translations of this manual
@c into another language, under the above conditions for modified versions,
@c except that this permission notice may be stated in a translation
@c approved by the Free Software Foundation
@c  

@c %**start of header
@setfilename toolsmanual.info
@set TITLE Developing software with GNU
@settitle @value{TITLE}
@c %**end of header

@c ---------------------------------------- 
@c Include configuration information here.
@c ---------------------------------------- 
@include version.texi
@set OWNER Eleftherios Gkioulekas
@set YEARS 1998, 1999

@dircategory Development
@direntry
* toolsmanual: (toolsmanual).      Developing software with GNU
@end direntry

@c You should add similar direntries under the category
@c `General Commands' for each ``invoking'' node

@c ------------------------------------------------------------
@c Formatting style commands. You may insert more of them here.
@c For example: headings, indices, etc...
@c ------------------------------------------------------------
@setchapternewpage odd

@c Versions of various programs
@set automake 1.4
@set autoconf 2.13
@set libtool 1.3
@set texinfo 3.12b
@set autotools 0.11
@set emacs 20.3
@set leim 20.3
@set intlfonts 1.1
@set elispmanual 20-2.5
@set emacslispintro 1.05

@c ---------------------------------
@c Canonical title related template
@c ---------------------------------

@shorttitlepage @value{TITLE}
@titlepage
@title @value{TITLE}
@subtitle An introduction to the GNU development tools
@subtitle This is edition @value{EDITION}
@subtitle Last updated, @value{UPDATED}
@c @author @value{OWNER}
@author Eleftherios Gkioulekas
@author @r{Department of Applied Mathematics}
@author @r{University of Washington}
@author @email{lf@@amath.washington.edu}
@page
@vskip 0pt plus 1filll
@format
This edition of the manual is consistent with:
Autoconf @value{autoconf}, Automake @value{automake}, Libtool @value{libtool},
Autotools @value{autotools}, Texinfo @value{texinfo}, Emacs @value{emacs}.
@sp 2
Published on the Internet
@uref{http://www.amath.washington.edu/~lf/tutorials/autoconf/}
@end format

@sp 2
  
Copyright @copyright{} @value{YEARS} @value{OWNER}. All rights reserved.

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

@ignore 
Permission is granted to process this file through Tex and print the
results, provided the printed document carries copying permission notice
identical to this one except for the removal of this paragraph
@end ignore

Permission is granted to copy and distribute modified versions of
this manual under the conditions for verbatim copying, 
provided that
they are marked clearly as modified versions, that the authors'
names and title are unchanged (though subtitles and additional authors'
names may be added), and that other clearly marked sections
held under separate copyright are reproduced under the conditions given
withinthem,
and that the entire resulting derived work
is distributed under the terms of a permission notice identical
to this one.

Permission is granted to copy and distribute translations of this manual
into another language, under the above conditions for modified versions,
except that this permission notice may be stated in a translation approved
by the Free Software Foundation.
@end titlepage

@c ---------------------
@c Menu stuff for info
@c ----------------------

@ifinfo
@node Top, Preface, (dir), (dir)
@comment node-name, next, previous, up
@top @value{TITLE}
This manual is a tutorial introduction to the GNU development tools,
which include Emacs, Make, Automake, Autoconf, Libtool, Gettext,
and Texinfo.
All of these tools are introduced in this manual to help you become
a contributing member of the free software community.
@end ifinfo

@c ===================================================================
@c ===================================================================

@menu
* Preface::                     
* Copying::                     
* Acknowledgements::            
* Installing GNU software::     
* Using GNU Emacs::             
* Compiling with Makefiles::    
* The GNU build system::        
* Using Automake::              
* Using Libtool::               
* Using C effectively::         
* Using Fortran effectively::   
* Internationalization::        
* Maintaining Documentation::   
* Portable shell programming::  
* Writing Autoconf macros::     
* Legal issues with Free Software::  
* Philosophical issues::        
* Licensing Free Software::     
* GNU GENERAL PUBLIC LICENSE::  

@detailmenu
 --- The Detailed Node Listing ---

Installing GNU software

* Installing a GNU package::    
* The Makefile standards::      
* Configuration options::       
* Doing a VPATH build::         
* Making a binary distribution::  

Using GNU Emacs

* Installing GNU Emacs::        
* Basic Emacs concepts::        
* Configuring GNU Emacs::       
* Using vi emulation::          
* Navigating source code::      
* Using Emacs as an email client::  
* Handling patches::            
* Inserting copyright notices with Emacs::  
* Hacker sanity with Emacs::    
* Further reading on Emacs::    

Compiling with Makefiles

* Compiling simple programs::   
* Programs with many source files::  
* Building libraries::          
* Dealing with header files::   
* The GPL and libraries::       
* The language runtime libraries::  
* Basic Makefile concepts::     
* More about Makefiles::        

The GNU build system

* Introducing the GNU tools::   
* Installing the GNU build system::  
* Hello world example with Autoconf and Automake::  
* Understanding the hello world example::  
* Using configuration headers::  
* Maintaining the documentation files::  
* Organizing your project in subdirectories::  
* Applying the GPL::            
* Handling version numbers::    
* Hello world with acmkdir::    

Using Automake

* Simple use of Automake::      
* General Automake principles::  
* Installation standard directories::  
* Libraries with Automake::     
* Applications with Automake::  
* Dealing with built sources::  
* Embedded text with Automake::  
* Scripts with Automake::       
* Emacs Lisp with Automake::    
* Guile with Automake::         
* Data files with Automake::    

Using Fortran effectively

* Fortran compilers and linkage::  
* Walkthrough a simple example::  
* Portability problems with Fortran::  
* Other Fortran dialects::      
* Popular free software in Fortran::  

Maintaining Documentation

* Browsing documentation::      
* Writing proper manuals::      
* Introduction to Texinfo::     
* Markup in Texinfo::           
* GNU Emacs support for Texinfo::  
* Writing man pages::           
* Writing documentation with LaTeX::  
* Creating a LaTeX package::    
* Further reading about LaTeX::  

Legal issues with Free Software

* Understanding Copyright::     
* Software patents::            
* Export restrictions on encryption software::  

Philosophical issues

* The Right to Read::           
* What is Free Software::       
* Why software should not have owners::  
* Why free software needs free documentation::  
* Categories of software::      
* Confusing words::             

Licensing Free Software

* What is Copyleft::            
* Why you should use the GPL::  
* The LGPL vs the GPL::         

@end detailmenu
@end menu

@c ============================================================
@c ============================================================

@shortcontents
@contents

@c ============================================================
@c ============================================================

@node Preface, Copying, Top, Top
@unnumbered Preface

The GNU project was founded in 1984 by Richard Stallman in response to the 
increasing obstacles to cooperation imposed on the computing community
by the owners of proprietary software. The goal of the GNU project is
to remove these obstacles by developing a complete software system,
named GNU @footnote{The acronym GNU means, ``GNU's Not Unix''} and 
distributing it as free software. GNU is not about software that costs
$0. It is about software that gives to all its users the freedom to
use, modify and redistribute it. These freedoms are essential to 
building a community based on cooperation and the open sharing of ideas. 

Today, millions of people use GNU/Linux, a combination of the GNU system
and the popular Linux kernel that was developed since 1991 by Linus Torvalds
and a group of volunteers. 
The GNU project's kernel, the Hurd, is also in service but it is not yet
sufficiently developed for widespread use. Technically, Unix and GNU
have many similarities, and it is very easy to port software from Unix
to GNU or use GNU software on Unix systems.

Because GNU is a community effort, it provides very powerful development
tools that enable every user to contribute to the community by writing
free software. The GNU development tools include the @dfn{GNU compilers},
the @dfn{GNU build system} and @dfn{Emacs}. 
Proprietary systems often do not bundle such tools with their distributions
because their developers regard the users as a market that buys software 
licenses and treats the computer as an appliance. 
@footnote{One very popular operating system 
actually bundles advertising icons on the standard configuration
of their desktop system. This is sick.}

This manual will introduce you to the development tools that are used
in the GNU system. These tools can also be used to develop software with
GNU/Linux and Unix.
This manual will not teach you how to use C, or any other programming
language. It is assumed that you are already familiar with C. This manual
will also not cover every detail about the tools that we discuss. 
Each tool has its own reference manual, and you should also read these 
manuals, sooner or later, if you want to learn more. This manual aims to
be a practical introduction to the GNU development tools that will show
you how to use them together to accomplish specific common tasks. 
The intended audience is a programmer that has learned programming in C,
and would now like to learn everything else that person needs to know to
develop software that conforms to the GNU coding standards. So,
we will tell you what to need to know, and then you can read the specific
reference manuals to learn everything that you can possibly learn.

@ignore
When we speak of the @dfn{GNU build system} we refer primarily to the
following four packages: Make, Autoconf, Automake and Libtool.
These packages make it possible to develop software that can be distributed
freely as source code. Portability has always been a serious problem
with source code distributions, especially on Unix systems. With the
GNU build system it is possible to write source code distributions that
configure and install themselves to the installer's computer automatically.
Another very important benefit of the GNU build system is that it simplifies
the development of software immensely by automating a lot of tedious routine
work. Learning how to use the GNU build system will be the primary focus of 
this manual.

Another important program that will be briefly discussed in this manual
is @emph{Emacs}. In GNU, Emacs gets to play the role that @dfn{IDE}s
(integrated development environments) play in other operating systems.
In this manual we will briefly explain how to use Emacs to
develop and maintain source code. Emacs is a very essential program,
and it can do a lot of things to make software development less work.
@end ignore

@c ============================================================

@heading Note on terminology

There is a growing concern among womyn that there are important gender 
issues with the English language. As a result, it became common to use terms 
such as ``chairperson'' instead of ``chairman''.
In this manual we will use the words @dfn{person}, 
@dfn{per}, @dfn{pers} and @dfn{perself}. These words are used just
like the words she, her, hers, herself. For example, we will say:
``person wrote a manual to feel good about perself, and to encourage per
potential significant other's heart to become pers''. These terms were 
introduced, and
perhaps invented, by Marge Piercy, and have been first used in software 
documentation and email correspondance by Richard Stallman.
By using these terms, we hope to make this manual less threatening to 
womyn and to encourage our womyn readers to join the free software community.

@c ============================================================

@heading Roadmap to manual

This manual was written as a tutorial and not a reference manual,
so in general, it works to read the chapters in the order in which they
are presented. If you came fresh from your CS courses with a good knowledge
of C, but have learned nothing about the GNU development tools, reading
all the chapters in order is probably what you should do.
However, if you are already familiar with some of the
topics that we discuss, you might want to skip a few chapters to get to
the material that is new to you. 

For example, many readers are already
familiar with Emacs and Makefiles, and they just want to get
started with learning about Autoconf and Automake. In that case,
you can skip to @ref{The GNU build system}, and start reading from there.
If you are a vi user and are not interested in learning Emacs, please
reconsider (@pxref{Using vi emulation}). You will find some of the other
development tools, especially the Texinfo documentation system, much easier 
to use with Emacs than without it. 

Here's a brief outline of the chapters in this manual, and what is covered
by each chapter.
@itemize @bullet
@item
@ref{Installing GNU software}, explains how to install free software
that is distributed in autoconfiguring source distributions. The rest of
the manual will tell you what you need to know to make your software
autoconfiguring as well.
@item
@ref{Using GNU Emacs}, shows you how to install and configure Emacs,
and how to use it to develop and maintain your software. 
@item
@ref{Compiling with Makefiles}, introduces the compiler and the @samp{make}
utility and explains how to write Makefiles. 
@item
@ref{The GNU build system}, explains how to develop 
simple programs with Automake and Autoconf.
@item
@ref{Using Automake}, explains in a lot more detail how to write sophisticated
@file{Makefile.am} files.
@item
@ref{Using Libtool}, explains how to use Libtool to write portable source 
distributions that compile shared libraries both on GNU and Unix.
@item
@ref{Using C effectively}, explains how to make the best use of the GNU
build system to develop C programs.
@item
@ref{Using Fortran effectively}, explains how to write programs that use
both Fortran and C.
@item
@ref{Internationalization}, explains how to write programs whose user
interface can be translated to foreign languages.
@item
@ref{Maintaining Documentation}, explains how to document your software
using Texinfo, LaTeX and man pages.
@item
@ref{Portable shell programming}, explains how to write portable shell
scripts. This is essential to writing your own Autoconf macros.
@item
@ref{Writing Autoconf macros}, explains how to write your own Autoconf macros.
@item
@ref{Legal issues with Free Software}, discusses legal issues such as 
software copyrights, patents and governmental stupidity. 
Understanding these issues is essential in keeping your free software free 
and protecting it from hoarders. If you are publishing free software to our 
community it is very important to understand the law, even if in your country
copyrights and patents are not strictly enforced.
@item 
@ref{Philosophical issues}, is a collection of articles by Richard Stallman
that discuss the free software philosophy. Our philosophy is very important,
because it is what will motivate us to keep free software free, and 
defend our freedom now that the free software movement has been noticed
by the mainstream media.
@item
@ref{Licensing Free Software}, is another collection of articles that 
contain advice about licensing free software. Most of these articles,
except for one, have also been written by Richard Stallman.
@end itemize

@c ============================================================

@node Copying, Acknowledgements, Preface, Top
@unnumbered Copying

This book that you are now reading is actually free. The information
in it is freely available to anyone. The machine readable source code
for the book is freely distributed on the internet and anyone may take
this book and make as many copies as they like. (take a moment to
check the copying permissions on the Copyright page). If you paid money
for this book, what you actually paid for was the book's nice printing and
binding, and the publisher's associated costs to produce it.

The @emph{GNU development tools} include Automake, Autoconf, Libtool,
Make, Emacs, Texinfo and the GNU C and C++ compilers. These programs
are ``free''; this means that everyone is free to use them and
free to redistribute them on a free basis. These programs are not in the
public domain; they are copyrighted and there are restrictions on their
distribution, but these restrictions are designed to permit everything that
a good cooperating citizen would want to do. What is not allowed is to try
to prevent others from further sharing any version of these programs
that they might get from you.

Specifically, we want to make sure that you have the right to give away
copies of the programs and documents that relate to them, that you
receive source code or else can get it if you want it, that you can change
these programs or use pieces of them in new free programs, and that you
know you can do these things.

To make sure that everyone has such rights, we don't allow you to deprive
anyone else of these rights. For example, if you distribute copies of the
code related to the @emph{GNU development tools}, you must give the recipients
all the rights that you have. You must make sure that they, too, can get the
source code. And you must tell them their rights.

Also for our own protection, we must make certain that everyone finds out that
there is no warranty for the programs that relate to the 
@emph{GNU development tools}. If these programs are modified by
someone else and passed on, we want their recipients to know that what
they have is not what we distributed, so that any problems introduced by
others will not reflect on our reputation.

The precise conditions of the licenses for the @emph{GNU development tools}
are found in the General Public Licenses that accompany them.


@c ============================================================

@node Acknowledgements, Installing GNU software, Copying, Top
@unnumbered Acknowledgements

This manual was written and is being maintained by Eleftherios Gkioulekas.
Many people have contributed to this effort in various ways. Here is
a list of these contributions. Please help me keep it complete and exempt of
errors.

@itemize @bullet
@item
@ref{Philosophical issues}, and @ref{Licensing Free Software},
were written by Richard Stallman. Richard has also contributed many useful
review comments and helped me with the legal paperwork.
@item
@ref{Installation standard directories}, was adapted from 
@cite{The GNU coding standards}. 
@item
@ref{Maintaining the documentation files}, was adapted from an unfinished
draft of @cite{The GNITS coding standards}, which was developed by the
members of the GNITS-pickers gang: Francois Pinard, Tom Tromey, Jim 
Meyering, Aharon Robbins, Ulrich Drepper, Karl Berry, Greg McGary.
@item
Most of the material in @ref{Using Fortran effectively}, is based
on my studying of GNU Octave's source code, written by John Eaton.
John is the first free software developer, to the best of my knowledge,
that has written an extensive project that combines Fortran, C and C++
so effectively.
@end itemize

@c ============================================================
@c ============================================================

@node Installing GNU software, Using GNU Emacs, Acknowledgements, Top
@chapter Installing GNU software

Free software is distributed in source code distributions. Many of these
programs are difficult to install because they use system dependent features,
and they require the user to edit makefiles and configuration headers.
By contrast, the software distributed by the GNU project is 
@dfn{autoconfiguring}; it is possible to compile it from source code and 
install it automatically, without any tedious user intervention. 

In this chapter we discuss how to compile and install autoconfiguring software 
written by others. In the subsequent chapters we discuss how to use the
development tools that allow you to make your software autoconfiguring as
well. 

@menu
* Installing a GNU package::    
* The Makefile standards::      
* Configuration options::       
* Doing a VPATH build::         
* Making a binary distribution::  
@end menu

@node Installing a GNU package, The Makefile standards, Installing GNU software, Installing GNU software
@section Installing a GNU package

Autoconfiguring software is distributed with packaged source code 
distributions. These are big files with filenames of the form:
@example
@var{package}-@var{version}.tar.gz
@end example
@noindent
For example, the file @file{autoconf-@value{autoconf}.tar.gz} contains
version @value{autoconf} of GNU Autoconf.
We often call these
files @dfn{source distributions}; sometimes we simply call them
@dfn{packages}.

The steps for installing an autoconfiguring source code distribution are
simple, and if the distribution is not buggy, can be carried out without
substantial user intervention.
@enumerate
@item
First, you have to unpack the package to a directory:
@example
% gunzip foo-1.0.tar.gz
% tar xf foo-1.0.tar
@end example
This will create the directory @file{foo-1.0} which contains the package's
source code and documentation. Look for the files @file{README} to see
if there's anything that you should do next. The @file{README} file might
suggest that you need to install other packages before installing this one,
or it might suggest that you have to do unusual things to install this
package. If the source distribution conforms to the GNU coding standards,
you will find many other documentation files like @file{README}. 
@xref{Maintaining the documentation files}, for an explanation of what
these files mean. 
@item
Configure the source code. Once upon a time that used to mean that you have
to edit makefiles and header files. In the wonderful world of Autoconf,
source distributions provide a @file{configure} script that will do that
for you automatically. To run the script type:
@example
% ./configure
@end example
@noindent
@item
Now you can compile the source code. Type:
@example
% cd foo-1.0
% make
@end example
@noindent
and if the program is big, you can make some coffee. After the program
compiles, you can run its regression test-suite, if it has one, 
by typing
@example
% make check
@end example
@noindent
@item
If everything is okey, you can install the compiled distribution with:
@example
% su
# make install
@end example
@end enumerate

The @file{make} program launches the shell commands necessary for compiling,
testing and installing the package from source code. However, @file{make}
has no knowledge of what it is really doing. It takes its orders from
@dfn{makefiles}, files called @file{Makefile} that have to be present
in every subdirectory of your source code directory tree. From the installer 
perspective,
the makefiles define a set of @dfn{targets} that correspond to things
that the installer wants to do. The default target is always compiling the
source code, which is what gets invoked when you simply run @code{make}. 
Other targets, such as @samp{install}, @samp{check} need to be mentioned
explicitly. Because @file{make} takes its orders from the makefile in 
the current directory, it is important to run it from the correct 
directory. @xref{Compiling with Makefiles}, for the full story behind 
@file{make}. 

The @file{configure} program is a shell script that probes your system 
through a set of tests to
determine things that it needs to know, and then uses the results
to generate @file{Makefile} files from templates stored
in files called @file{Makefile.in}. In the early days of the GNU project,
developers used to write @file{configure} scripts by hand. Now, no-one
ever does that any more. Now, @file{configure} scripts are automatically
generated by GNU Autoconf from an input file @file{configure.in}. 
GNU Autoconf is part of the GNU build system and we first introduce
in in @ref{The GNU build system}. 

As it turns out, you don't have to write the @file{Makefile.in} templates
by hand either. Instead you can use another program, GNU Automake, to
generate @file{Makefile.in} templates from higher-level descriptions
stored in files called @file{Makefile.am}. In these files you describe
what is being created by your source code, and Automake computes the
makefile targets for compiling, installing and uninstalling it. Automake
also computes targets for compiling and running test suites, and targets
for recursively calling @code{make} in subdirectories. The details about
Automake are first introduced in @ref{Using Automake}.

@c -------------------------------------------------------------

@node The Makefile standards, Configuration options, Installing a GNU package, Installing GNU software
@section The Makefile standards

The @dfn{GNU coding standards} are a document that describes the requirements
that must be satisfied by all GNU programs. These requirements are driven
mainly by technical ocnsiderations, and they are excellent advice for
writing good software. The @dfn{makefile standards}, a part of the 
GNU coding standards, require that your
makefiles do a lot more than simply compile and install the software.

One requirement is @dfn{cleaning targets}; these targets remove the files
that were generated while installing the package and restore the source
distribution to a previous state. There are three cleaning targets that
corresponds to three levels of cleaning: @code{clean}, @code{distclean},
@code{maintainer-clean}. 
@table @code
@item clean
Cleans up all the files that were generated by @code{make} and 
@code{make check}, but not the files that were generated by running
@code{configure}. This targets cleans the build, but does not undo the
source configuration by the configure script.
@item distclean
Cleans up all the files generated by @code{make} and @code{make check},
but also cleans the files that were generated by running @code{configure}.
As a result, you can not invoke any other make targets until you run
the configure script again. This target reverts your source directory tree
back to the state in which it was when you first unpacked it.
@item maintainer-clean
Cleans up all the files that @code{distclean} cleans. However it also removes
files that the developers have automatically generated with the GNU build
system. Because users shouldn't need the entire GNU build system to install
a package, these files should not be removed in the final source distribution.
However, it is occasionally useful for the maintainer to remove and 
regenerate these files.
@end table

Another type of cleaning that is required is erasing the package itself from
the installation directory; @dfn{uninstalling} the package. To uninstall
the package, you must call
@example
% make uninstall
@end example
@noindent
from the toplevel directory of the source distribution. This will work only
if the source distribution is configured first. It will work best only
if you do it from the same source distribution, with the same configuration,
that you've used to install the package in the first place. 

When you install GNU software, archive the source code to all the packages 
that you install in a directory like @file{/usr/src} or @file{/usr/local/src}. 
To do that, first run @code{make clean} on the source distribution, and then
use a recursive copy to copy it to @file{/usr/src}. The presense of a 
source distribution in one of these directories should be a signal to you
that the corresponding package is currently installed. 

Francois Pinard came up with a cute rule for remembering what the cleaning
targets do:
@itemize @bullet
@item
If @code{configure} or @code{make} did it, @code{make distclean} undoes it.
@item
If @code{make} did it, @code{make clean} undoes it.
@item
If @code{make install} did it, @code{make uninstall} undoes it.
@item
If @emph{you} did it, @code{make maintainer-clean} undoes it.
@end itemize

GNU standard compliant makefiles also have a target for generating @dfn{tags}.
Tags are files, called @file{TAGS}, that are used by GNU Emacs to allow
you to navigate your source distribution more efficiently. 
More specifically, Emacs uses tags to take you from a place where a C function
is being used in a file, to the file and line number where the function is
defined. To generate the tags call:
@example
% make tags
@end example
@noindent
Tags are particularly useful when you are not the original author of the
code you are working on, and you haven't yet memorized where everything is.
@xref{Navigating source code}, for all the details about navigating large
source code trees with Emacs.

Finally, in the spirit of free redistributable code, there must be targets for
cutting a source code distribution. If you type
@example
% make dist
@end example
@noindent
it will rebuild the @file{foo-1.0.tar.gz} file that you started with.
If you modified the source, the modifications will be included in the
distribution (and you should probably change the version number).
Before putting a distribution up on FTP, you can test its integrity
with:
@example
% make distcheck
@end example
@noindent
This makes the distribution, then unpacks it in a temporary subdirectory
and tries to configure it, build it, run the test-suite, and check if the
installation script works. If everything is okey then you're told that
your distribution is ready.

Writing reliable makefiles that support all of these targets is a very
difficult undertaking. This is why we prefer to generate our makefiles
instead with GNU Automake.

@c ----------------------------------------------------

@node Configuration options, Doing a VPATH build, The Makefile standards, Installing GNU software
@section Configuration options

The @samp{configure} script accepts many command-line flags that modify
its behaviour and the configuration of your source distribution. To obtain
a list of all the options that are available type
@example
% ./configure --help
@end example
@noindent
on the shell prompt. 

The most useful parameter that the installer controls during configuration
is the directory where they want the package to be installed. 
During installation, the following files go to the following directories:
@example
Executables   @expansion{} /usr/local/bin
Libraries     @expansion{} /usr/local/lib
Header files  @expansion{} /usr/local/include
Man pages     @expansion{} /usr/local/man/man?
Info files    @expansion{} /usr/local/info
@end example
@noindent

The @file{/usr/local} directory is called the @dfn{prefix}. The default
prefix is always @file{/usr/local} but you can set it to anything you like
when you call @samp{configure} by adding a @samp{--prefix} option.
For example, suppose that you are not a privilidged user, so you can not
install anything in @file{/usr/local}, but you would still like to install
the package for your own use. Then you can tell the @samp{configure} 
script to install the package in your home directory 
@samp{/home/@var{username}}:
@example
% ./configure --prefix=/home/@var{username}
% make
% make check
% make install
@end example
@noindent
The @samp{--prefix} argument tells @samp{configure} where you want to
install your package, and @samp{configure} will take that into account and
build the proper makefile automatically. 

If you are installing the package on a filesystem that is shared by computers
that run variations of GNU or Unix, you need to install the files that
are independent of the operating system in a shared directory, but separate 
the files that are dependent on the operating systems in different 
directories. Header files and documentation can be shared. However,
libraries and executables must be installed separately. Usually the scheme
used to handle such situations is:
@example
Executables   @expansion{} /usr/local/@var{system}/bin
Libraries     @expansion{} /usr/local/@var{system}/lib
Header files  @expansion{} /usr/local/include
Man pages     @expansion{} /usr/local/man/man@var{n}
Info files    @expansion{} /usr/local/info
@end example
@noindent
The directory @file{/var/local/@var{system}} is called the 
@dfn{executable prefix}, and it is usually a subdirectory of the prefix.
In general, it can be any directory. If you don't specify the executable
prefix, it defaults to being equal to the prefix. To change that,
use the @samp{--exec-prefix} flag.
For example, to configure for a GNU/Linux system, you would run:
@example
% configure --exec-prefix=/usr/local/linux
@end example
@noindent
To configure for GNU/Hurd, you would run:
@example
% configure --exec-prefix=/usr/local/hurd
@end example

In general, there are many directories where a package may want to install
files. Some of these directories are controlled by the prefix, where
others are controlled by the executable prefix. 
@xref{Installation standard directories}, for a complete discussion of
what these directories are, and what they are for.

Some packages allow you to enable or disable certain features while you
configure the source code. They do that with flags of the form:
@example
   --with-@var{package}   --enable-@var{feature}
--without-@var{package}  --disable-@var{feature}
@end example
@noindent
The @code{--enable} flags usually control whether to enable certain
optional features of the package. Support for international languages,
debugging features, and shared libraries are features that are usually
controlled by these options. 
The @code{--with} flags instead control whether to compile and install
certain optional components of the package.
The specific flags that are available for a particular source distribution
should be documented in the @file{README} file. 

Finally, @code{configure} scripts can be passed parameters via environment
variables. One of the things that @code{configure} does is decide what
compiler to use and what flags to pass to that compiler. You can
overrule the decisions that @code{configure} makes by setting the flags
@code{CC} and @code{CFLAGS}. For example, to specify that you want the
package to compile with full optimization and without any debugging
symbols (which is a bad idea, yet people want to do it):
@example
% export CFLAGS="-O3"
% ./configure
@end example
@noindent
To tell @code{configure} to use the system's native compiler instead of
@code{gcc}, and compile without optimization and with debugging symbols:
@example
% export CC="cc"
% export CFLAGS="-g"
% ./configure
@end example
@noindent
This assumes that you are using the @code{bash} shell as your default shell.
If you use the @code{csh} or @code{tcsh} shellls, you need to assign 
environment variables with the @code{setenv} command instead. For example:
@example
% setenv CFLAGS "-O3"
% ./configure 
@end example
@noindent
Similarly, the flags @code{CXX}, @code{CXXFLAGS} control the C++ compiler.

@c ----------------------------------------------------

@node Doing a VPATH build, Making a binary distribution, Configuration options, Installing GNU software
@section Doing a VPATH build

Autoconfiguring source distributions also support vpath builds. In a 
vpath build, the source distribution is stored in a, possibly read-only,
directory, and the actual building takes place in a different directory
where all the generated files are being stored. We call the first
directory, the @dfn{source tree}, and the second directory the 
@dfn{build tree}. The build tree may be a subdirectory of the source tree,
but it is better if it is a completely separate directory. 

If you, the developer, use the standard features of the GNU build system, you 
don't need to do anything special to allow your packages to support vpath 
builds. The only exception to this is when you define your own make rules
(@pxref{General Automake principles}). Then you have to follow certain 
conventions to allow vpath to work correctly. 

You, the installer, however do need to do something special. You need
to install and use GNU make. Most Unix make utilities do not support
vpath builds, or their support doesn't work. GNU make is extremely portable,
and if vpath is important to you, there is no excuse for not installing it.

Suppose that @file{/sources/foo-0.1} contains a source distribution,
and you want to build it in the directory @file{/build/foo-0.1}.
Assuming that both directories exist, all you have to do is:
@example
% cd /build/foo-0.1
% /sources/foo-0.1/configure @var{...options...}
% make
% make check
% su
# make install
@end example
@noindent
The configure script and the generated makefiles will take care of the rest.

vpath builds are prefered by some people for the following reasons:
@enumerate
@item
They prevent the build process form cluttering your source directory
with all sorts of build files.
@item
To remove a build, all you have to do is remove the build directory.
@item
You can build the same source multiple times using different options. 
This is very useful if you would like to write a script that will 
run the test suite for a package while the package is configured in
many different ways (e.g. different features, different compiler optimization,
and so on). It is also useful if you would like to do the same with releasing
binary distributions of the source. 
@end enumerate
Some developers like to use vpath builds all the time. Others use them
only when necessary. 
In general, if a source distribution builds with a vpath build, it also
builds under the ordinary build. The opposite is not true however. 
This is why the @code{distcheck} target checks if your distribution is
correct by attempting a vpath build.

@c ------------------------------------------------------------------------

@node Making a binary distribution,  , Doing a VPATH build, Installing GNU software
@section Making a binary distribution

After compiling a source distribution, instead of installing it, you can
make a snapshot of the files that it would install and package that
snapshot in a tarball. It is often convenient to the installers to
install from such snapshots rather than compile from source, especially
when the source is extremely large, or when the amount of packages that
they need to install is large. 

To create a binary distribution run the following commands as root:
@example
# make install DESTDIR=/tmp/dist
# tar -C /tmp/dist -cvf @var{package}-@var{version}.tar
# gzip -9 @var{package}-@var{version}.tar
@end example
@noindent
The variable @code{DESTDIR} specifies a directory, alternative to root,
for installing the compiled package. The directory tree under that directory 
is the exact same tree that would have normally been installed. 
Why not just specify a different prefix? Because very often, the prefix
that you use to install the software affects the contents of the files
that actually get installed. 

@c More discussion needed for making deb and rpm files 

Please note that under the terms of the GNU General Public License, 
if you distribute your software as a binary distribution, you also
need to provide the corresponding source distribution. The simplest way
to comply with this requirement is to distribute both distributions
together.

@c ============================================================
@c ============================================================

@node Using GNU Emacs, Compiling with Makefiles, Installing GNU software, Top
@chapter Using GNU Emacs

Emacs is an environment for running Lisp programs that manipulate text
interactively. To call Emacs merely an @dfn{editor} does not do it
justice, unless you redefine the word ``editor'' to the broadest meaning
possible. Emacs is so extensive, powerful and flexible, that you can almost
think of it as a self-contained ``operating system'' in its own right.

Emacs is a very important part of the GNU development tools
because it provides an integrated environment for software development.
The simplest thing you can do with Emacs is edit your source code.
However, you can do a lot more than that. You can run a debugger,
and step through your program while Emacs showes you the corresponding
sources that you are stepping through. You can browse on-line Info 
documentation and man pages, download and read your email off-line, and 
follow discussions on newsgroups. Emacs is particularly helpful with writing 
documentation with the Texinfo documentation system. You will find it harder 
to use Texinfo, if you don't use Emacs. It is also very helpful with editing 
files on remote machines over FTP, especially when your connection to the 
internet is over a slow modem.
Finally, and most importantly, Emacs
is @emph{programmable}. You can write Emacs functions in Emacs Lisp to
automate any chore that you find particularly useful in your own
work. Because Emacs Lisp is a full programming language, there is no
practical limit to what you can do with it. 

If you already know a lot about Emacs, you can skip this chapter and move on.
If you are a ``vi'' user, then we will assimilate you: 
@xref{Using vi emulation}, for details. 
@footnote{The author is also a former ``vi'' user that has found much
happiness and bliss in Emacs}
This chapter will be most useful to the novice user who would like to
set per Emacs up and running for software development, however it is
not by any means comprehensive. @xref{Further reading on Emacs}, for
references to more comprehensive Emacs documentation.

@menu
* Installing GNU Emacs::        
* Basic Emacs concepts::        
* Configuring GNU Emacs::       
* Using vi emulation::          
* Navigating source code::      
* Using Emacs as an email client::  
* Handling patches::            
* Inserting copyright notices with Emacs::  
* Hacker sanity with Emacs::    
* Further reading on Emacs::    
@end menu

@c ============================================================

@node Installing GNU Emacs, Basic Emacs concepts, Using GNU Emacs, Using GNU Emacs
@section Installing GNU Emacs

If Emacs is not installed on your system, you will need to get a source
code distribution and compile it yourself. Installing Emacs is not
difficult. If Emacs is already installed on your GNU/Linux system, 
you might still need to reinstall it: you might not have the most
recent version, you might have Xemacs instead, you might not have
support for internationalization, or your Emacs might not have compiled
support for reading mail over POP (a feature very useful to developers
that hook up over modem). If any of these is the case, then uninstall 
that version of Emacs, and reinstall Emacs from a source code distribution.

The entire Emacs source code is distributed in three separate files:
@table @file
@item emacs-@value{emacs}.tar.gz
This is the main Emacs distribution. If you do not care about 
international language support, you can install this by itself.
@item leim-@value{emacs}.tar.gz
This supplements the Emacs distribution with support for multiple languages.
If you develop internationalized software, it is likely that you will need
this.
@item intlfonts-@value{intlfonts}.tar.gz
This file contains the fonts that Emacs uses to support international
languages. If you want international language support, you will 
definetely need this.
@end table
Get a copy of these three files, place them under the same directory
and unpack them with the following commands:
@example
% gunzip emacs-@value{emacs}.tar.gz
% tar xf emacs-@value{emacs}.tar
% gunzip leim-@value{emacs}.tar.gz
% tar xf leim-@value{emacs}.tar
@end example
@noindent
Both tarballs will unpack under the @file{emacs-@value{emacs}} directory. 
When this is finished, configure the source code with the following commands:
@example
% cd emacs-@value{emacs}
% ./configure --with-pop --with-gssapi
% make
@end example
@noindent
The @samp{--with-pop} flag is almost always
a good idea, especially if you are running Emacs from a home computer
that is connected to the internet over modem. It will let you use Emacs
to download your email from your internet provider and read it off-line
(@pxref{Using Emacs as an email client}). Most internet providers use
GSSAPI-authenticated POP. If you need to support other authentication
protocols however, you may also want to add one of the following flags:
@table @code
@item --with-kerberos
support Kerberos-authenticated POP
@item --with-kerberos5
support Kerberos version 5 authenticated POP
@item --with-hesiod
support Hesiod to get the POP server host
@end table
Then compile and install Emacs with:
@example
$ make
# make install
@end example
@noindent
Emacs is a very large program, so this will take a while. 

To install @file{intlfonts-@value{intlfonts}.tar.gz} unpack it, and follow 
the instructions in the @file{README} file. Alternatively, you may find it
more straightforward to install it from a Debian package. Packages for
@file{intlfonts} exist as of Debian 2.1.

@c ============================================================

@node Basic Emacs concepts, Configuring GNU Emacs, Installing GNU Emacs, Using GNU Emacs
@section Basic Emacs concepts

In this section we describe what Emacs is and what it does. We will not
yet discuss how to make Emacs work. That discussion is taken up in the
subsequent sections, starting with @ref{Configuring GNU Emacs}. This 
section instead covers the fundamental ideas that you need to understand
in order to make sense out of Emacs.

You can run Emacs from a text terminal, such as a vt100 terminal, but it is
usually nicer to run Emacs under the X-windows system.
To start Emacs type 
@example
% emacs &
@end example
@noindent
on your shell prompt. The seasoned GNU developer usually sets up per
X configuration such that it starts Emacs when person logs in. Then,
person uses that Emacs process for all of per work until person logs out.
To quit Emacs press @kbd{C-x C-c}, or select
@example
Files @expansion{} Exit Emacs
@end example
@noindent
from the menu. The notation @kbd{C-c} means @kbd{@key{CTRL}-c}. The 
separating dash @samp{-} means that you press the key after the dash while
holding down the key before the dash.
Be sure to quit Emacs before logging out, to ensure that your work
is properly saved. If there are any files that you haven't yet saved,
Emacs will prompt you and ask you if you want to save them, before quiting.
If at any time you want Emacs to stop doing what it's doing, press
@kbd{C-g}. 

@c FIXME: describe minibuffer and what the other mouse-buttons do

Under the X window system, Emacs controls multiple x-windows which are
called @dfn{franes}. Each frame has a menubar and the main editing area.
The editing area is divided into @dfn{windows} 
@c --
@footnote{Note that in Emacs lingo a @dfn{window} does not correspond
to an X window. It is the @dfn{frame} that corresponds to an X window. 
A @dfn{window} is merely a region within the frame. And the same Emacs
process can actually be responsible for more than one frame}
@c --
by horizontal bars, called @dfn{status bars}. Every status bar contains 
concise information about the status of the window @emph{above} the status 
bar. The minimal editing area has at least one big window, where editing
takes place, and a small one-line window called the @dfn{minibuffer}.
Emacs uses the minibuffer to display brief messages and to prompt the user
to enter commands or other input. The minibuffer has no status bar of
its own. 

Each window is bound to a @dfn{buffer}. A buffer is an Emacs data structure
that contains text. Most editing commands operate on buffers, modifying
their contents. When a buffer is bound to a window, then you can see its
contents as they are being changed. It is possible for a buffer to be bound
to two windows, on different frames or on the same frame. Then whenever
a change is made to the buffer, it is reflected on both windows. It is
not necessary for a buffer to be bound to a window, in order to operate on
it. In a typical Emacs session you may be manipulating more buffers than 
the windows that you actually have on your screen. 

A buffer can be @dfn{visiting} files. In that case, the contents of the
buffer reflect the contents of a file that is being editted. But buffers
can be associated with anything you like, so long as you program
it up. For example, under the Dired directory editor, a buffer is bound
to a directory, showing you the contents of the directory. When you
press @key{RET} while the cursor is over a file name, Emacs creates
a new buffer, visits the file, and rebinds the window with that buffer.
From the user's perspective, by pressing @key{RET} person ``opened'' the
file for editing. If the file has already been ``opened'' then Emacs
simply rebinds the existing buffer for that file. 

Sometimes Emacs will divide a frame to two or more windows. 
You can switch from one window to another by clicking the 1st mouse button,
while the mouse is inside the destination window.
To resize these windows, grab the status bar with the
1st mouse button and move it up or down. Pressing the 2nd mouse
button, while the mouse is on a status bar, will @dfn{bury} the window bellow 
the status bar. 
Pressing the 3rd mouse button will @dfn{bury} the window above the
status bar, instead. Buried windows are not killed; they still exist and you 
can get back to them by selecting them from the menu bar, under:
@example
Buffers @expansion{} @var{name-of-buffer}
@end example
@noindent
Buffers, with some exceptions, are usually named after the filenames of
the files that they correspond to.

Once you visit a file for editing, then all you need to do is to edit it!
The best way to learn how to edit files using the standard Emacs @emph{editor}
is by working through the on-line Emacs tutorial. To start the on-line tutorial
type @kbd{C-h t} or select:
@example
Help @expansion{} Emacs Tutorial
@end example
@noindent
If you are a vi user, or you simply prefer to use `vi' keybindings, then
read @ref{Using vi emulation}.

In Emacs, every @dfn{event} causes a Lisp function to be executed. 
An @dfn{event} can be any keystroke, mouse movement, mouse clicking or
dragging, or a menu bar selection. The function implements the appropriate
response to the event. Almost all of these functions are written in a
variant of Lisp called Emacs Lisp. The actual Emacs program, the executable,
is an Emacs Lisp interpreter with the implementation of frames, buffers,
and so on. However, the actual functionality that makes Emacs usable is
implemented in Emacs Lisp. 

Sometimes, Emacs will bind a few words of text to an Emacs function. 
For example, when you use Emacs to browse Info documentation, certain
words that corresponds to hyperlinks to other nodes are bound to a function
that makes Emacs follow the hyperlink. When such a binding is actually
installed, moving the mouse over the bound text highlights it momentarily. 
While the text is highlighted, you can invoke the binding by clicking the
2nd mouse button.

Sometimes, an Emacs function might go into an infinite loop, or it might
start doing something that you want to stop. You can @strong{always} make
Emacs abort
@footnote{Proposed Federal censorship regulations may prohibit us from giving you information about the possibility of aborting Emacs functions. We would be required to say that this is not an acceptable way of terminating an unwanted  function}
the function it is currently running by pressing @kbd{C-g}.

Emacs functions are usually spawned by Emacs itself in response to an
event. However, the user can also spawn an Emacs function by typing:
@example
@key{ALT}-x @var{function-name} @key{RET}
@end example
@noindent
These functions can also be aborted with @kbd{C-g}.

It is standard in Emacs documentation to refer to the @key{ALT} key with
the letter @samp{M}. So, in the future, we will be refering to function
invokations as:
@example
M-x @var{function-name}
@end example
@noindent

Because Emacs functionality is implemented in an @dfn{event-driven} fashion,
the Emacs developer has to write Lisp functions that implement functionality,
and then bind these functions to events. Tables of such bindings are
called @dfn{keymaps}.

Emacs has a @dfn{global keymap}, which is in effect
at all times, and then it has specialized keymaps depending on what
@dfn{editing mode} you use. Editing modes are selected when you visit a
file depending on the name of the file. So, for example, if you visit a
C file, Emacs goes into the C mode. If you visit @file{Makefile}, Emacs
goes into makefile mode. The reason for associating different modes
with different types of files is that the user's editing needs depend
on the type of file that person is editing. 

You can also enter a mode by running the Emacs function that 
initializes the mode. 
Here are the most commonly used modes:
@table @code
@item M-x c-mode
Mode for editing C programs according to the GNU coding standards.
@item M-x c++-mode
Mode for editing C++ programs
@item M-x sh-mode
Mode for editing shell scripts.
@item M-x m4-mode 
Mode for editing Autoconf macros.
@item M-x texinfo-mode
Mode for editing documentation written in the Texinfo formatting language.
@xref{Introduction to Texinfo}.
@item M-x makefile-mode
Mode for editing makefiles.
@end table
@noindent
As a user you shouldn't have to worry too much about the modes. The defaults
do the right thing. However, you might want to enhance Emacs to suit your
needs better. 

@c ============================================================

@node Configuring GNU Emacs, Using vi emulation, Basic Emacs concepts, Using GNU Emacs
@section Configuring GNU Emacs

To use Emacs effectively for software development you need to configure it.
Part of the configuration needs to be done in your X-resources file.
On a Debian GNU/Linux system, the X-resources can be configured by editing 
@example
/etc/X11/Xresources
@end example
@noindent
In many systems, you can configure X-resources by editing a file called
@file{.Xresources} or @file{.Xdefaults} on your home directory, but
that is system-dependent. The configuration that I use on my system
is:
@example
! Emacs defaults
emacs*Background: Black
emacs*Foreground: White
emacs*pointerColor: White
emacs*cursorColor: White
emacs*bitmapIcon: on
emacs*font: fixed
emacs*geometry: 80x40
@end example
@noindent
In general I favor dark backgrounds and @samp{fixed} fonts. Dark backgrounds
make it easier to sit in front of the monitor for a prolonged period of
time. @samp{fixed} fonts looks nice and it's small enough to make efficient
use of your screenspace. Some people might prefer larger fonts however.

When Emacs starts up, it looks for a file called @file{.emacs} at the user's
home directory, and evaluates it's contents through the Emacs Lisp 
interpreter. You can customize and modify Emacs' behaviour by
adding commands, written in Emacs Lisp, to this file. Here's a brief
outline of the ways in which you can customize Emacs:

@enumerate
@item
A common change to the standard configuration is
assigning @dfn{global variables} to non-default
values. Many Emacs features and behaviours can be controlled and 
customized this way.
This is done with the @samp{setq} command, which accepts the
following syntax:
@example
(setq @var{variable} @var{value})
@end example
@noindent
For example:
@example
(setq viper-mode t)
@end example
@noindent
You can access on-line documentation for global variables by running:
@example
M-x describe-variable
@end example
@noindent

@item
In some cases, Emacs depends on the values of shell 
@dfn{environment variables}. These can be manipulated with @samp{setenv}:
@example
(setenv "@var{variable}" "@var{value}")
@end example
@noindent
For example:
@example
(setenv "INFOPATH" "/usr/info:/usr/local/info")
@end example
@noindent
@samp{setenv} does not affect the shell that invoked Emacs, but it does
affect Emacs itself, and shells that are run under Emacs.

@item
Another way to enhance your Emacs configuration is by modifying the
global keymap. This can be done with the @samp{global-set-key} command,
which follows the following syntax:
@example
(global-set-key [@var{key sequence}] '@var{function})
@end example
@noindent
For example, adding:
@example
(global-set-key [F12 d] 'doctor)
@end example
@noindent
to @file{.emacs} makes the key sequence @kbd{F12 d} equivalent to
running @samp{M-x doctor}. Emacs has many functions that provide all
sorts of features. To find out about specific functions, consult
the @cite{Emacs user manual}. Once you know that a function exists,
you can also get on-line documentation for it by running:
@example
M-x describe-function
@end example
@noindent
You can also write your own functions in Emacs Lisp. 

@item
It is not always good to introduce bindings to the global map. Any bindings
that are useful only within a certain mode should be added only to the local
keymap of that mode. Consider for example the following Emacs Lisp function:
@example
(defun texi-insert-@@example ()
  "Insert an @@example @@end example block"
  (interactive)
  (beginning-of-line)
  (insert "\n@@example\n")
  (save-excursion 
    (insert "\n")
    (insert "@@end example\n")
    (insert "\n@@noindent\n")))
@end example
@noindent
We would like to bind this function to the key @samp{F9}, however we
would like this binding to be in effect only when we are within 
@samp{texinfo-mode}. To do that, first we must define a hook function
that establishes the local bindings using @samp{define-key}:
@example
(defun texinfo-elef-hook ()
  (define-key texinfo-mode-map [F9] 'texi-insert-@@example))
@end example
@noindent
The syntax of @samp{define-key} is similar to @samp{global-set-key}
except it takes the name of the local keymap as an additional 
argument. The local keymap of any @samp{@var{name}-mode} is 
@samp{@var{name}-mode-map}. Finally, we must ask @samp{texinfo-mode}
to call the function @samp{texinfo-elef-hook}. To do that use the
@samp{add-hook} command:
@example
(add-hook 'texinfo-mode-hook 'texinfo-elef-hook)
@end example
@noindent
In some cases, Emacs itself will provide you with a few optional hooks
that you can attach to your modes.

@item
You can write your own modes! If you write a program whose use involves
editing some type of input files, it is very much appreciated by the
community if you also write an Emacs mode for thet file and distribute
it with your program. 
@end enumerate

With the exception of simple customizations, most of the more complicated
ones require that you write new Emacs Lisp functions, distribute them
with your software and somehow make them visible to the installer's 
Emacs when person installs your software. 
@xref{Emacs Lisp with Automake}, for more details on how to include
Emacs Lisp packages to your software. 

Here are some simple customizations that you might want to add to your
@file{.emacs} file:

@itemize @bullet
@item
Set your default background and foreground color for all your Emacs frames:
@example
(set-background-color "black")
(set-foreground-color "white")
@end example
@noindent
You can change the colors to your liking.
@item
Tell Emacs your name and your email address. This is particularly useful
when you work on an off-line home system but you want Emacs to use the email
address of your internet provider, and your real name. Specifying your real
name is necessary if you call yourself ``Skeletor'' or ``Dude'' on your
home computer.
@example
(setq user-mail-address "karl@@whitehouse.com")
(setq user-full-name "President Karl Marx")
@end example
@noindent
Make sure the name is your real name, and the email address that you
include can receive email 24 hours per day.
@item
Add a few toys to the status bar. These commands tell Emacs to display a
clock, and the line and column number of your cursor's position at all times.
@example
(display-time)
(line-number-mode 1)
(column-number-mode 1)
@end example
@item
When you use the mouse to cut and paste text with Emacs, mouse button 1
will select text and mouse button 2 will paste it. Unfortunately, 
when you click mouse button 2, emacs will first move the cursor at the
location of the mouse, and then insert the text in that location.
If you are used to editing with vi under xterms, you will instead prefer
to position the cursor yourself, and use mouse button 2 to simply cause
the text to be pasted without changing the position of the cursor. If you
prefer this behaviour, then add the following line to your @file{.emacs}:
@example
(global-set-key [mouse-2] 'yank)
@end example
By default, selected text in Emacs buffers is highlighted with blue color.
However, you can also select and paste into an Emacs buffer text that
you select from other applications, like your web browser, or your xterm.
@item
Use @dfn{font-lock}. Font-lock decorates your editted text with colors that
make it easier to read text with complicated syntax, such as software
source codes. This is one of the coolest features of Emacs. To use it, add
the following lines to your @file{.emacs}:
@example
(global-font-lock-mode t)
(setq font-lock-maximum-size nil)
@end example
@noindent
@item
To get rid of the scrollbar at the left of your Emacs window, type
@example
(setq scroll-bar-mode nil)
@end example
@noindent
The only reason that the scrollbar is default is to make Emacs more similar
to what lusers are used to. It is assumed that seasoned hacker, who will
be glad to see the scrollbar bite it, will figure out how to make it go away.
@item
With most versions of Emacs, you should add the following to your @file{.emacs}
to make sure that editing @file{configure.in} takes you to @code{m4-mode}
and editing @file{Makefile.am} takes you to @code{makefile-mode}. 
@example
(setq auto-mode-alist
  (append '(
    ("configure.in" . m4-mode)
    ("\\.m4\\'" . m4-mode)
    ("\\.am\\'" . makefile-mode))
   auto-mode-alist))
@end example
@noindent
You will have to edit such files if you use the GNU build system.
@xref{The GNU build system}, for more details.
@item
If you have installed Emacs packages in non-standard directories,
you need to add them to the @samp{load-path} variable. For example,
here's how to add a couple of directories:
@example
(setq load-path
      (append "/usr/share/emacs/site-lisp"
              "/usr/local/share/emacs/site-site"
              (expand-file-name "~lf/lisp")
              load-path))
@end example
@noindent
Note the use of @samp{expand-file-name} for dealing with non-absolute
directories. If you are a user in an account where you don't have root
priviledge, you are very likely to need to install your Emacs packages
in a non-standard directory.
@item
@xref{Using vi emulation}, if you would like to customize Emacs to run
a vi editor under the Emacs system.
@item
@xref{Navigating source code}, for more details on how to customize Emacs to 
make navigating a source code directory tree easier.
@item
@xref{Using Emacs as an email client}, if you would like to set up Emacs to
process your email. 
@item
Autotools distributes two Emacs packages. One for handling copyright notices,
and another one for handling Texinfo documentation.
@xref{Inserting copyright notices with Emacs}, and 
@xref{GNU Emacs support for Texinfo}, for more details.
@end itemize
Emacs now has a graphical user interface to customization that will 
write @file{.emacs} for you automatically. To use it, select:
@example
Help @expansion{} Customize @expansion{} Browse Customization Groups
@end example
@noindent
from the menu bar. You can also manipulate some common settings from:
@example
Help @expansion{} Options
@end example

@c ============================================================

@node Using vi emulation, Navigating source code, Configuring GNU Emacs, Using GNU Emacs
@section Using vi emulation

Many hackers prefer to use the @samp{vi} editor. The @samp{vi} editor is
the standard editor on Unix. It is also always available on GNU/Linux.
Many system administrators find it necessary to use vi, especially when they
are in the middle of setting up a system in which Emacs has not been 
installed yet. Besides that, there are many compelling reasons why people 
like vi.
@itemize @bullet
@item
Vi requires only two special keys: the @key{SHIFT} key and the @key{ESC}
key. All the other keys that you need are standard on all keyboards. 
You do not need @key{CTRL},@key{ALT},the cursor keys or any of the function
keys. Some terminals that miss the escape key, usually have the control
key and you can get escape with: 
@kbd{@key{CTRL}-[} @c }
@item
Vi was designed to deal with terminals that connect to mainframes over
a very slow line. So it has been optimized to allow you to do the most
editing possible with the fewest keystrokes. This allows users to edit
text very efficiently.
@item
Vi allows your fingers to stay at the center of the keyboard, with the
occasional hop to the escape key. It does not require you to stretch your
fingers in funny control combinations, which makes typing less tiring
and more comfortable.
@end itemize
Because most rearrangements of finger habits are not as optimal as the
vi finger habits, most vi users react very unpleasently to other editors.
For the benefit of these users, in this section we describe how to 
run a vi editor under the Emacs system. Similarly, users of other editors
find the vi finger habits strange and unintuitive. For the benefit of 
these users we describe briefly how to use the vi editor, so they can
try it out if they like.

The vi emulation package for the Emacs system is called @dfn{Viper}. 
To use Viper, add the following lines in your @file{.emacs}:
@example
(setq viper-mode t)
(setq viper-inhibit-startup-message 't)
(setq viper-expert-level '3)
(require 'viper)
@end example
@noindent
We recommend expert level 3, as the most balanced blend
of the vi editor with the Emacs system. Most editing modes are aware of
Viper, and when you begin editing the text you are immediately thrown into
Viper. Some modes however do not do that. In some modes, like the Dired mode,
this is very appropriate. In other modes however, especially custom modes
that you have added to your system, Viper does not know about them, so
it does not configure them to enter Viper mode by default. To tell a
mode to enter Viper by default, add a line like the following to
your @file{.emacs} file:
@example
(add-hook 'm4-mode-hook 'viper-mode)
@end example
@noindent
The modes that you are most likely to use during software development are
@example
c-mode  , c++-mode , texinfo-mode
sh-mode , m4-mode  , makefile-mode
@end example
@noindent
Sometimes, Emacs will enter Viper mode by default in modes where you prefer
to get Emacs modes. In some versions of Emacs, the 
@code{compilation-mode} is such a mode. To tell a mode @strong{not} to
enter Viper by default, add a line like the following to your
@file{.emacs} file:
@example
(add-hook 'compilation-mode-hook 'viper-change-state-to-emacs)
@end example
@noindent
The Emacs distribution has a Viper manual. For more details on setting
Viper up, you should read that manual.

The vi editor has these things called @emph{editing modes}. An editing
mode defines how the editor responds to your keystrokes. Vi has three
editing modes: @dfn{insert mode}, @dfn{replace mode} and @dfn{command mode}. 
If you run Viper, there is also the Emacs mode. Emacs indicates which
mode you are in by showing one of
@samp{<I>}, @samp{<R>}, @samp{<V>}, @samp{<E>} on the statusbar 
correspondingly for the Insert, Replace, Command and Emacs modes.
Emacs also shows you the mode by the color of the cursor. This makes it
easy for you to keep track of which mode you are in.
@itemize @bullet
@item
@dfn{Insert mode}:
When you are in insert mode, the editor simply @dfn{inserts} the things that
you type into the text that is being editted. If there are any characters
in front of your cursor, these characters are pushed ahead and they are
not overwritten. Under Viper, when you are in insert mode, the color
of your cursor is green. The only key that has special meaning, while you
are in insert mode is @key{ESC}. If you press the escape key, you are taken
to @dfn{command mode}.
@item
@dfn{Replace mode}:
When you are in replace mode, the editor replaces the text under the cursor
with the text that is being typed. So, you want insert mode when you want
to write over what's already written. Under Viper, when you are in 
replace mode, the color of your cursor is red. The @key{ESC} will take you
to @dfn{command mode.}
@item
@dfn{Command mode}:
When you are in command mode, every letter key that you press is a command
and has a special meaning. Some of these keys allow you to navigate the
text. Other keys allow you to enter either insert or replace mode. 
And other keys do various special things. Under Viper, when you are in
command mode, the color of your cursor is white. 
@item
@dfn{Emacs mode}:
When you are in Emacs mode, then Viper is turned off on the specific 
buffer, and Emacs behaves as the default Emacs editor. 
You can switch between Emacs mode and Command mode by pressing
@kbd{@key{CTRL}-z}. So to go to Emacs mode, from Insert of Replace mode, you 
need to go through Command mode. When you are dealing with a buffer that
runs a special editing mode, like Dired,
Emacs defines a specialized ``command mode'' for manipulating that buffer,
that can be completely different from the canonical Viper command mode.
You want to be in that mode to access the intended functionality. Occasionally
however, you may like to hop to viper's command mode to navigate the buffer,
do a search or save the buffer's contents. When you hop to one of the 
other three modes, the buffer will suddendly be just text to your editor.
@end itemize
While you are in Command mode, you can prepend keystrokes with a number. 
Then the subsequent keystroke will be executed as many times as the number.
We now list the most important keystrokes that are available to you, 
while you are in Viper's command mode:
@itemize @bullet
@item
The following keystrokes allow you to navigate the cursor around your text
without making any changes on the text itself
@table @kbd
@item h
moves one character to the left
@item j 
moves down one line
@item k
moves up one line
@item l
moves one character to the left
@item w
moves forward one word
@item 5w
moves forward five words (get the idea?)
@item b
moves back one word
@item 0
moves to the beginning of the current line
@item $
moves to the end of the current line
@item G
moves to the last line in the file
@item 1G
moves to the first line in the file
@item :10
moves to line 10 in the file (get the idea?)
@item @{
moves up one paragraph
@item @}
moves down one paragraph
@end table
@item
The following keystrokes allow you to delete text
@table @kbd
@item x
Deletes the character under the cursor
@item dd
Deletes the current line
@item 4dd
Deletes four lines
@item dw
Deletes the current word
@item 8dw
Deletes the next eight words
@end table
@item
The following keystrokes allow you to enter Insert mode
@table @kbd
@item a
Append text after the cursor position
@item i
Insert text at the current cursor position
@item o
Insert text on a new line bellow the current line
@item O
Insert text on a new line above the current line
@end table
@item
The following keystrokes allow you to enter Replace mode.
@table @kbd
@item R
Replace text at the cursor position and stay in Replace mode.
@item s
Replace (substitute) only the character at the cursor position, and
enter Insert mode for all subsequent characters.
@end table
@item
The following commands handle file input/output. All of these commands
are prepended by the @kbd{:} character. The @kbd{:} character is used 
for commands that require many characters to be properly expressed. 
The full text of these commands is entered in the minibuffer. Under viper,
the minibuffer itself can run under insert, replace and command mode.
By default you get insert mode, but you can switch to command mode 
by pressing @key{ESC}.
@table @kbd
@item :w
Save the file to the disk
@item :w!
Force the file to be saved to disk even when file permissions do not allow
it but you have the power to overrule the permissions.
@item :w @var{filename} <RET>
Save the file to the disk under a specific filename. 
When you press @key{SPACE} Emacs inserts the full pathname of the current
directory for you, which you can edit if you like.
@item :w! @var{filename} <RET>
Force the file to be saved to the disk under a specific filename.
@item :r @var{filename} <RET>
Paste a file from the disk at the cursor's current position.
@item :W
Save all the files on all the Emacs buffers that correspond to open files.
@item :q
Kill the buffer. This does not quite the editor at expert level 3.
@item :q!
Kill the buffer even if the contents are not saved. Use with caution!
@end table
@item
The following commands handle search and replace
@table @kbd
@item /@var{string} <RET>
Search for @var{string}.
@item n
Go to the next occurance of @var{string}.
@item N
Go to the previous occurance of @var{string}.
@item :%s/@var{string1}/@var{string2}/g <RET>
Replace all occurances of @var{string1} with @var{string2}.
Use this with extreme caution!
@end table
@item
The following commands handle @dfn{undo}
@table @kbd
@item u
Undo the previous change. Press again to undo the undo
@item .
Press this if you want to repeat the undo further.
@end table
@end itemize
These are enough to get you started. Getting used to dealing with the modes
and learning the commands is a matter of building finger habits. It may take
you a week or two before you become comfortable with Viper. When Viper
becomes second nature to you however, you won't want to tolerate what you
used to use before.

@c ==================================================================

@node Navigating source code, Using Emacs as an email client, Using vi emulation, Using GNU Emacs
@section Navigating source code

When you develop software, you need to edit many files at the same time,
and you need an efficient way to switch from one file to another. 
The most general solution in Emacs is by going through @dfn{Dired}, the
Emacs Directory Editor. 

To use Dired effectively, we recommend that you add the following 
customizations to your @file{.emacs} file:
First, add
@example
(add-hook 'dired-load-hook (function (lambda () (load "dired-x"))))
(setq dired-omit-files-p t)
@end example
@noindent
to activate the extended features of @dfn{Dired}.
Then add the following key-bindings to the global keymap:
@example
(global-set-key [f1] 'dired)
(global-set-key [f2] 'dired-omit-toggle)
(global-set-key [f3] 'shell)
(global-set-key [f4] 'find-file)
(global-set-key [f5] 'compile)
(global-set-key [f6] 'visit-tags-table)
(global-set-key [f8] 'add-change-log-entry-other-window)
(global-set-key [f12] 'make-frame)
@end example
@noindent
If you use viper (@pxref{Using vi emulation}), you should also add the
following customization to your @file{.emacs}:
@example
(add-hook 'compilation-mode-hook 'viper-change-state-to-emacs)
@end example
@noindent

With these bindings, you can navigate from file to file or switch between
editing and the shell simply by pressing the right function keys.
Here's what these key bindings do:
@table @kbd
@item f1
Enter the directory editor.
@item f2
Toggle the omission of boring files.
@item f3
Get a shell at the current Emacs window.
@item f4
Jump to a file, by filename.
@item f5
Run a compilation job.
@item f6
Load a @file{TAGS} file.
@item f8
Update the @file{ChangeLog} file.
@item f12
Make a new frame.
@end table
@noindent
When you first start Emacs, you should create a few frames with @kbd{f12}
and move them around on your screen. Then press @kbd{f1} to enter the
directory editor and begin navigating the file system. To select a
file for editing, move the cursor over the filename and press enter.
You can select the same file from more than one emacs window, and edit 
different parts of it in every different window, or use the mouse to
cut and paste text from one part of the file to another. 
If you want to take a direct jump to a specific file, and you know the
filename of that file, it may be faster to press @kbd{f4} and enter the
filename rather than navigate your way there through the directory editor.

To go down a directory, move the cursor over the directory filename and
press enter. To go up a few directories, press @kbd{f1} and when you
are prompted for the new directory, with the current directory as the
default choice, erase your way up the hierarchy and press @key{RET}.
To take a jump to a substantially different directort that you have
visited recently, press @kbd{f1} and then when prompted for the destination
directory name, use the cursor keys to select the directory that you want
among the list of directories that you have recently visited.

While in the directory navigator, you can use the cursor keys to move
to another file. Pressing @key{<RET>} will bring that file up for editing.
However there are many other things that Dired will let you do instead:
@table @kbd
@item Z
Compress the file. If already compressed, uncompress it.
@item L 
Parse the file through the Emacs Lisp interpreter. Use this
only on files that contain Emacs Lisp code.
@item I, N
Visit the current file as an Info file, or as a @dfn{man page}.
@xref{Browsing documentation}.
@item d
Mark the file for deletion
@item u
Remove a mark on the file for deletion
@item x
Delete all the files marked for deletion
@item C @var{destination} <RET>
Copy the file to @var{destination}.
@item R @var{filename} <RET>
Rename the file to @var{filename}.
@item + @var{directoryname} <RET>
Create a directory with name @var{directoryname}.
@end table
@noindent
Dired has many other features. See the @cite{GNU Emacs User Manual},
for more details.

Emacs provides another method for jumping from file to file: @dfn{tags}.
Suppose that you are editing a C program whose source code is distributed
in many files, and while editing the source for the function @code{foo},
you note that it is calling another function @code{gleep}. If you move
your cursor on @code{gleep}, then Emacs will let you jump to the file
where @code{gleep} is defined by pressing @kbd{M-.}. You can also jump to
other occurances in your code where @code{gleep} is invoked by pressing
@kbd{M-,}. In order for this
to work, you need to do two things: you need to generate a tags
file, and you need to tell emacs to load the file. If your source code
is maintained with the GNU build system, you can create that tags files
by typing:
@example
% make tags
@end example
@noindent
from the top-level directory of your source tree. Then load the tags
file in Emacs by navigating Dired to the toplevel directory of your 
source code, and pressing @kbd{f6}. 

While editing a file, you may want to hop to the shell prompt to run a 
program. You can do that at any time, on any frame, by pressing 
@kbd{f3}. To get out of the shell, and back into the file that you were
editing, enter the directory editor by pressing @kbd{f1}, and then
press @kbd{<RET>} repeatedly. The default selections will take you back
to the file that you were most recently editing on that frame. 

One very nice feature of Emacs is that it understands tar files. 
If you have a tar file @file{foo.tar} and you select it under Dired,
then Emacs will load the entire file, parse it, and let you edit the
individual files that it includes directly. This only works, however,
when the tar file is not compressed. Usually tar files are distributed
compressed, so you should uncompress them first with @kbd{Z} before
entering them. Also, be careful not to load an extremely huge tar file.
Emacs may mean ``eating memory and constantly swaping'' to some people, but 
don't push it!

Another very powerful feature of Emacs is the Ange-FTP package: it allows
you to edit files on other computers, remotely, over an FTP connection. 
From a user perspective, remote files behave just like local files.
All you have to do is press @kbd{f1} or @kbd{f4} and request a directory
or file with filename following this form:
@example
/@var{username}@@@var{host}:/@var{pathname}
@end example
@noindent
Then Emacs will access for you the file @file{/@var{pathname}} on the
remote machine @var{host} by logging in over FTP as @var{username}.
You will be prompted for a password, but that will happen only once per
host. Emacs will then 
download the file that you want to edit and let you make your changes locally.
When you save your changes, Emacs will use an FTP connection again to upload
the new version back to the remote machine, replacing the older version of
the file there. When you develop software on a remote computer, this feature
can be very useful, especially if your connection to the Net is over
a slow modem line. This way you can edit remote files just like you do
with local files. You will still have to telnet to the remote computer
to get a shell prompt. In Emacs, you can do this with @code{M-x telnet}.
An advantage to telneting under Emacs is that it records your session,
and you can save it to a file to browse it later.

While you are making changes to your files, you should also be keeping
a diary of these changes in a @file{ChangeLog} file
(@pxref{Maintaining the documentation files}). Whenever you are done
with a modification that you would like to log, press @kbd{f8},
@emph{while the cursor is still at the same file}, and preferably near the 
modification (for example, if you are editing a C program, be inside the
same C function). Emacs will split the frame
to two windows. The new window brings up your @file{ChangeLog} file. 
Record your changes and click on the status bar that separates the two
windows with the 2nd mouse button to get rid of the @file{ChangeLog} file.
Because updating the log is a frequent chore, this Emacs help is
invaluable.

If you would like to compile your program, you can use the shell prompt
to run @samp{make}. However, the Emacs way is to use the @code{M-x compile}
command. Press @kbd{f5}. Emacs will prompt you for the command that you
would like to run. You can enter something like: @samp{configure},
@samp{make}, @samp{make dvi}, and so on
(@pxref{Installing a GNU package}). The directory on which this command
will run is the current directory of the current buffer. If your current
buffer is visiting a file, then your command will run on the same directory
as the file. If your current buffer is the directory editor, then your
command will run on that directory. When you press @kbd{<RET>}, Emacs will
split the frame into another window, and it will show you the command's
output on that window. If there are error messages, then Emacs converts
these messages to hyperlinks and you can follow them by pressing @kbd{<RET>}
while the cursor is on them, or by clicking on them with the 2nd mouse button.
When you are done, click on the status bar with the 2nd mouse button to
get the compilation window off your screen.

@c ==============================================================

@node Using Emacs as an email client, Handling patches, Navigating source code, Using GNU Emacs
@section Using Emacs as an email client

@c Hackers get lots of email
@c Explain about GNUS and RMAIL.
@c How to configure RMAIL
@c Running RMAIL
@c keybindings for sending/reading mail
@c all about labeling mail. advice on what labels are nice to use
@c saving mail to other files
@c replying to spam

You can use Emacs to read your email. If you maintain free software, or
in general maintain a very active internet life, you will get a lot of
email. The Emacs mail readers have been designed to address the needs
of software developers who get endless tons of email every day. 

Emacs has two email programs: Rmail and Gnus. Rmail is simpler to learn,
and it is similar to many other mail readers. The philosophy behind Rmail
is that instead of separating messages to different folders, you attach
@dfn{labels} to each message but leave the messages on the same folder.
Then you can tell Rmail to browse only messages that have specific labels.
Gnus, on the other hand, has a rather eccentric approach to email. It is
a news-reader, so it makes your email look like another newsgroup! 
This is actually very nice if you are subscribed to many mailing lists
and want to sort your email messages automatically. To learn more about
Gnus, read the excellent Gnus manual. In this manual, we will only describe
Rmail.

@c FIXME: This should change. I should learn GNUS and see how one can
@c combine the two readers to sort out mailing list mail from
@c communication mail

When you start Rmail, it moves any new mail from your mailboxes to the file
@file{~/RMAIL} in your home directory. So, the 
first thing you need to tell Rmail is where your mailboxes are.
To do that, add the following to your @file{.emacs}:
@example
(require 'rmail)
(setq rmail-primary-inbox-list
      (list @var{"mailbox1"} @var{"mailbox2"} ...))
@end example
@noindent
If your mailboxes are on a filesystem that is mounted to your computer,
then you just have to list the corresponding filenames. 
If your mailbox
is on a remote computer, then you have to use the POP protocol to
download it to your own computer. In order for this to work, the remote
computer must support POP. Many hobbyist developers receive their email
on an internet provider computer that is connected to the network 24/7
and download it on their personal computer whenever they dial up. 

For example, if @code{karl@@whitehouse.gov} is your email address at your
internet provider, and they support POP, you would have to add the 
following to your @file{.emacs}:
@example
(require 'rmail)
(setq rmail-primary-inbox-list
      (list "po:karl"))
(setenv "MAILHOST" "whitehouse.gov")
(setq rmail-pop-password-required t)
(setq user-mail-address "karl@@whitehouse.gov")
(setq user-full-name "President Karl Marx")
@end example
@noindent
The string @file{"po:@var{username}"} is used to tell the POP daemon which
mailbox you want to download. The environment variable @code{MAILHOST}
tells Emacs which machine to connect to, to talk with a POP daemon. 
We also tell Emacs to prompt in the minibuffer to request
the password for logging in with the POP daemon. The alternative is to
hardcode the password into the @file{.emacs} file, but doing so is not
a very good idea: if the security of your home computer is compromised, the
cracker also gets your password for another system. Emacs will remember the
password however, after the first time you enter it, so you won't have to 
enter it again later, during the same Emacs session. Finally, we tell Emacs
our internet provider's email address and our ``real name'' in the internet
provider's account. This way, when you send email from your home computer,
Emacs will spoof it to make it look like it was sent from the internet 
provider's computer. 

In addition to telling Rmail where to find your email, you may also
want to add the following configuration options:
@enumerate
@item
Quote messages that you respond to with the @code{>} prefix:
@example
(setq mail-yank-prefix ">")
@end example
@noindent
@item
Send yourself a blind copy of every message
@example
(setq mail-self-blind t)
@end example
@noindent
@item
Alternatively, archive all your outgoing messages to a separate file:
@example
(setq mail-archive-file-name "/home/@var{username}/mail/sent-mail")
@end example
@item
To have Rmail insert your signature in every message that you send:
@example
(setq mail-signature t)
@end example
@noindent
and add the actual contents of your signature to @file{.signature}
at your home directory.
@end enumerate

Once Rmail is configured, to start downloading your email, run 
@code{M-x rmail} in Emacs. Emacs will load your mail, prompt you for 
your POP password if necessary, and download your email from the internet
provider. Then, Emacs will display the first new message. You may quickly
navigate by pressing @kbd{n} to go to the next message or @kbd{p} to go
to the previous message. 
It is much better however to tell Emacs to compile a summary of your messages
and let you to navigate your mailbox using the summary. To do that, press
@kbd{h}. Emacs will split your frame to two windows: one window will
display the current message, and the other window the summary. A highlighted
bar in the summary indicates what the current message is. Emacs will also
display any labels that you have associated with your messages. 
While the current buffer is the summary, you can navigate from message
to message with the cursor keys (@kbd{up} and @kbd{down} in particular).
You can also run any of the following commands:
@table @kbd
@item h
display a summary of all the messages
@item s
save any changes made to the mail box
@item <
go to the first message in the summary
@item >
go to the last message in the summary
@item g
download any new email
@item r
reply to a message
@item f
forward a message
@item m
compose a new message
@item d
delete the current message
@item u
undelete the current message
@item x
expunge messages marked for deletion
@item a @var{label} <RET>
add the label @var{label} to the current message
@item k @var{label} <RET>
remove the label @var{label} from the current message
@item l @var{label} <RET>
display a summary only of the messages with label @var{label}
@item o @var{folder} <RET>
add the current message to another folder
@item w @var{filename} <RET>
write the body of the current message to a file
@end table
@noindent
Other than browing email, here is some things that you will want to do:
@itemize @bullet
@item
@strong{Compose a message}: To compose a message press @kbd{m}. Emacs
will take you to a new buffer where you can write the actual contents of your
message. Emacs separates this buffer with a line that says:
@example
--text follows this line--
@end example
@noindent
Before this line you may edit the message's headers. After this line,
you edit the actual body of the of the message. 
When you are done composing the message, you can do one of the following:
@table @kbd
@item C-c C-w
Insert the signature
@item C-c C-y
Quote (yank) the current message
@item C-c C-c
Send the message
@item Mail @expansion{} Cancel
Cancel the message
@end table
These commands are also available when you reply to or forward email messages.
@item
@strong{Reply to a message}: To reply to a message press @kbd{r}. 
Emacs will do the same thing that it does when you ask it to compose a
message. The only difference is that it writes the headers of the
message for you automatically such that the response is sent to all the
people that have received the original message. You may edit the headers
to add or remove recipient email addresses.
Emacs will not quote the message that you respond to by default. 
To quote it use @kbd{C-c C-y}.
@item
@strong{Forward a message}: To forward a message press @kbd{f}.
Emacs will write the headers for you and it will also quote the message
that you are forwarding, however it will not prefix it with @samp{>}
(or whatever character you use to prefix messages that you reply to).
The quoted message is clearly delimited with markers that indicate that
it is the forwarded message. You can add commentary, preferably, before
the markers so that the recipient can see it before seeing the forwarded
message.
@end itemize
In every one of these three cases you may need to edit the message's headers.
The most commonly used header entries that Emacs recognizes are:
@table @samp
@item To:
list address of the recipient to whom the message is directed 
@item Cc:
list addresses of other recipients that need to recieve courtesy copies
of the message
@item BCC:
list addresses of other recipients to send a copy to, without showing their
email address on the actual message
@item FCC:
list folders (filenames) where you would like the outgoing message to be
appended to
@item Subject:
the subject field for the message
@end table
The fields @samp{To:}, @samp{CC:}, @samp{BCC:} and @samp{FCC:} can also
have continuation lines: any subsequent lines that begin with a space
are considered part of the field.

@c ===============================================================

@node Handling patches, Inserting copyright notices with Emacs, Using Emacs as an email client, Using GNU Emacs
@section Handling patches

@emph{Believe it or not, I really don't know how to do that. I need a volunteer to explain this to me so I can explain it then in this section}


@c ============================================================

@node Inserting copyright notices with Emacs, Hacker sanity with Emacs, Handling patches, Using GNU Emacs
@section Inserting copyright notices with Emacs

When you develop free software, you must place copyright notices at
every file that invokes the General Public License. If you don't place
any notice whatsoever, then the legal meaning is that you refuse 
to give any permissions whatsoever, and the software consequently is not
free. For more details see @ref{Applying the GPL}. 
Many hackers, who don't take the law seriously, complain that adding the
copyright notices takes too much typing. Some of these people live in
countries where copyright is not really enforced. Others simply ignore it.

There is an Emacs package, called @samp{gpl}, which is currently distributed
with Autotools, that makes it possible to insert and maintain copyright
notices with minimal work. To use this package, 
in your @file{.emacs} you must declare your identity
by adding the following commands:
@example
(setq user-mail-address "me@@here.com")
(setq user-full-name "My Name")
@end example
@noindent
Then you must require the packages to be loaded:
@example
(require 'gpl)
(require 'gpl-copying)
@end example
@noindent
This package introduces the following commands:
@table @code
@item gpl
Insert the standard GPL copyright notice using appropriate commenting.
@item gpl-fsf
Toggle FSF mode. Causes the @code{gpl} command to insert a GPL
notice for software that is assigned to the Free Software Foundation.
The @code{gpl} command autodetects what type of file you are editing,
from the filename, and uses the appropriate commenting.
@item gpl-personal
Toggle personal mode. Causes the @code{gpl} command to insert a
GPL notice for software in which you keep the copyright.
@end table
If you are routinely assigning your software to an organization other
than the Free Software Foundation, then insert:
@example
(setq gpl-organization "@var{name}")
@end example
@noindent
after the @samp{require} statements in your @file{.emacs}.

@c ===============================================================

@node Hacker sanity with Emacs, Further reading on Emacs, Inserting copyright notices with Emacs, Using GNU Emacs
@section Hacker sanity with Emacs

Every once in a while, after long heroic efforts in front of the computer
monitor, a software developer will need to some counseling to feel
better about perself. In RL (real life) counseling is very expensive and
it also involves getting up from your computer and transporting yourself
to another location, which descreases your productivity. Emacs can help you.
Run @code{M-x doctor}, and you will talk to a psychiatrist for free.

Many people say that hackers work too hard and they should go out for
a walk once in a while. In Emacs, it is possible to do that without
getting up from your chair. To enter an alternate universe, run 
@code{M-x dunnet}. Aside from being a refreshing experience, it is also
a very effective way to procrastinate away work that you don't want to do.
Why do today, what you can postpone for tomorrow?

@c ================================================================

@node Further reading on Emacs,  , Hacker sanity with Emacs, Using GNU Emacs
@section Further reading on Emacs

This chapter should be enough to get you going with GNU Emacs. This is
really all you need to know to use Emacs to develop software. However,
the more you learn about Emacs, the more effectively you will be able to use
it, and there is still a lot to learn; a lot more than we can fit in this
one chapter. In this section we refer to other manuals that you can read
to learn more about Emacs. Unlike many proprietary manuals that you are
likely to find in bookstores, these manuals are @emph{free}
(@pxref{Why free software needs free documentation}).
Whenever possible, please contribute to the GNU project by ordering
a bound copy of the free documentation from the Free Software Foundation, or
by contributing a donation. 

The Free Software Foundation publishes the following manuals on Emacs:
@table @cite
@item The Emacs Editor
This manual tells you all there is to know about all the spiffy
things that Emacs can do, except for a few things here and there that
are so spiffy that they get to have their own separate manual. The printed
version, published by the Free Software Foundation, features our hero,
Richard Stallman, riding a gnu. It also includes the GNU Manifesto.
The machine readable source for the manual is distributed with GNU Emacs.
@item Programming in Emacs Lisp
A wonderful introduction to Emacs Lisp, written by Robert Chassell. 
If you want to learn programming in Emacs Lisp, start by reading this manual.
You can order this manual as a bound book from the Free Software Foundation.
You can also download a machine readable copy of the manual from any 
GNU ftp site. Look for @file{elisp-manual-@value{elispmanual}.tar.gz}.
@item The GNU Emacs Lisp Reference Manual
This is a comprehensive reference manual for the Emacs Lisp language. 
You can also order this manual as a bound book from the Free Software 
Foundation.
You can also download a machine readable copy of the manual from any 
GNU ftp site. Look for @file{emacs-lisp-intro-@value{emacslispintro}.tar.gz}.
@end table
@noindent
The following manuals are also distributed with the GNU Emacs source code
and they make for some very fun reading:
@table @cite
@item Gnus Manual
Gnus is the Emacs newsreader. You can also use it to sort out your email,
especially if you are subscribed to twenty mailing lists and receive
tons of email every day. This manual will tell you all you need to know
about Gnus to use it effectively. (@file{gnus.dvi})
@item CC Mode
The Emacs C editing mode will help you write C code that is beautifully
formatted and consistent with the GNU coding standards. If you develop
software for an organization that follows different coding standards,
you will have to customize Emacs to use their standards instead. If they
are lame and haven't given you Elisp code for their standards, then this
manual will show you how to roll your own. (@file{cc-mode.dvi})
@item Common Lisp Extensions
Emacs has a package that introduces many Common Lisp extensions to Emacs Lisp.
This manual describes what extensions are available and how to use them.
(@file{cl.dvi})
@item Writing Customization Definitions
Recent versions of Emacs have an elaborate user-friendly customization 
interface that will let users customize Emacs and update their 
@file{.emacs} files automatically for them. If you are writing large
Emacs packages, it is very easy to add a customization interface to them.
This manual explains how to do it. 
(@file{customize.dvi})
@item The Emacs Widget Library
It is possible to insert actual widgets in an Emacs buffer that are
bound to Emacs Lisp functions. This feature of Emacs is used, for example,
in the newly introduced customization interface. This manual documents
the Elisp API for using these widgets in your own Elisp packages.
(@file{widget.dvi})
@item RefTeX User Manual
If you are writing large documents with LaTeX that contain a lot of 
crossreferences, then the RefTeX package will make your life easier.
(@file{reftex.dvi})
@item Ediff User's Manual
Ediff is a comprehensive package for dealing with patches under Emacs.
If you receive a lot of patches to your software projects from contributors,
you can use Ediff to apply them to your source code.
(@file{ediff.dvi})
@item Supercite User's Manual
If you think that quoting your responses to email messages with
@samp{>} is for lamers and you want to be elite, then use Supercite.
(@file{sc.dvi})
@item Viper Is a Package for Emacs Rebels
This manual has more than you will ever need to know about Viper, the
Emacs vi emulation. @ref{Using vi emulation}, actually describes all
the features of Viper that you will ever really need. But still, it's
a good reading for a long airplane trip. 
(@file{viper.dvi})
@end table

@c ============================================================
@c ============================================================

@node Compiling with Makefiles, The GNU build system, Using GNU Emacs, Top
@chapter Compiling with Makefiles

In this chapter we describe how to use the compiler to compile simple software
and libraries, and how to use makefiles. 

@menu
* Compiling simple programs::   
* Programs with many source files::  
* Building libraries::          
* Dealing with header files::   
* The GPL and libraries::       
* The language runtime libraries::  
* Basic Makefile concepts::     
* More about Makefiles::        
@end menu

@node Compiling simple programs, Programs with many source files, Compiling with Makefiles, Compiling with Makefiles
@section Compiling simple programs

It is very easy to compile simple C programs on the GNU system. For example,
consider the famous ``Hello world'' program:
@table @file
@item hello.c
@example
#include <stdio.h>
int
main ()
@{
  printf ("Hello world\n");
@}
@end example
@end table
@noindent
The simplest way to compile this program is to type:
@example
% gcc hello.c
@end example
@noindent
on your shell. The resulting executable file is called @file{a.out}
and you can run it from the shell like this:
@example
% ./a.out
Hello world
@end example
@noindent
To cause the executable to be stored under a different filename pass the
@samp{-o} flag to the compiler:
@example
% gcc hello.c -o hello
% ./hello
Hello world
@end example
@noindent
Even with simple one-file hacks like this, the GNU compiler can accept
many options that modify its behaviour:
@table @samp
@item -g
The @samp{-g} flag causes the compiler to output debugging information
to the executable. This way, you can step your program through a debugger
if it crashes. 
(@emph{FIXME: Crossreference})
@item -O, -O2, -O3
The @samp{-O}, @samp{-O2}, @samp{-O3} flags activate @dfn{optimization}.
The numbers are called @dfn{optimization levels}.
 When you compile your program with optimization
enabled, the compiler applies certain algorithms to the machine code output
to make it go faster. The cost is that your program compiles much more slowly
and that although you can step it through a debugger if you used the @samp{-g}
flag, things will be a little strange. During development the programmer 
usually uses no optimization, and only activates it when person is about to
run the program for a production run. A good advice: always test your code
with optimization activated as well. 
If optimization breaks your code, then this is telling you that you have
a memory bug. Good luck finding it. 
@item -Wall
The @samp{-Wall} flag tells the compiler to issue warnings when it sees
bad programming style. Some of these warning catch actual bugs, but 
occasionally some of the warnings complain about something correct that you
did on purpose. For this reason this flag is feature is not activated
by default.
@end table
@noindent
Here are some variations of the above example:
@example
% gcc -g -O3 hello.c hello
% gcc -g -Wall hello.c -o hello
% gcc -g -Wall -O3 hello.c -o hello
@end example
@noindent

To run a compiled executable in the current directory just type its
name, prepended by @samp{./}. In general, once you compile a useful 
program, you should @dfn{install} it so that it can be run from any current
directory, simply by typing its name without prepending @samp{./}. 
To install an executable, you need to move it to a standard directory
such as @file{/usr/bin} or @file{/usr/local/bin}. If you don't have
permissions to install files there, you can instead install them on
your home directory at @file{/home/username/bin} where @code{username}
is your username. When you write the name of an executable, the shell
looks for the executable in a set of directories listed in the environment
variable @samp{PATH}. To add a nonstandard directory to your path do
@example
% export PATH="$PATH:/home/username/bin"
@end example
@noindent
if you are using the Bash shell, or 
@example
% setenv PATH "$PATH:/home/username/bin"
@end example
@noindent
if you are using a different shell. 

@c ============================================================

@node Programs with many source files, Building libraries, Compiling simple programs, Compiling with Makefiles
@section Programs with many source files

Now let's consider the case where you have a much larger program made
of source files @file{foo1.c}, @file{foo2.c}, @file{foo3.c} and
header files @file{header1.h} and @file{header2.h}.
One way to compile the program is like this:
@example
% gcc foo1.c foo2.c foo3.c -o foo
@end example
@noindent
This is fine when you have only a few files to deal with. Eventually,
when you have more than a few dozen files, it becomes wasteful to 
compile all of the files, all the time, every time you make a change
in only one of the files. For this reason, the compiler allows
you to compile every file separately into an intermediate file
called @dfn{object file}, and link all the object files together at the end.
This can be done with the following commands:
@example
% gcc -c foo1.c
% gcc -c foo2.c
% gcc -c foo3.c
% gcc foo1.o foo2.o foo3.o -o foo
@end example
@noindent
The first three commands generate the object files @file{foo1.o},
@file{foo2.o}, @file{foo3.o} and the last command links them together
to the final executable file @file{foo}. The @file{*.o} suffix is reserved
for use only by object files.

If you make a change only in
@file{foo1.c}, then you can rebuild @file{foo} like this:
@example
% gcc -c foo1.c
% gcc foo1.o foo2.o foo3.o -o foo
@end example
@noindent
The object files @file{foo2.o} and @file{foo3.o} do not need to be
rebuilt since only @file{foo1.c} changed, so it is not necessary to
recompile them.

Object files @file{*.o} contain definitions of variables
and subroutines written out in @dfn{assembly}
(machine language ``pseudocode''). Most of
these definitions will eventually be embedded in the final executable
program at a specific address. At this stage however these memory addresses
are not known so they are being refered to symbolically. These 
symbolic references are called @dfn{symbols}. It is possible to list
the symbols defined in an object file with the @samp{nm} command.
For example:
@example
% nm xmalloc.o
         U error
         U malloc
         U realloc
00000000 D xalloc_exit_failure
00000000 t xalloc_fail
00000004 D xalloc_fail_func
00000014 R xalloc_msg_memory_exhausted
00000030 T xmalloc
00000060 T xrealloc
@end example
@noindent
The first column lists the symbol's address within the object file, when
the symbol is actually defined in that object file. 
The second column lists the symbol type. The third column is the symbolic
name of the symbol. In the final executable, these names become 
irrelevant.
The following types commonly occur:
@table @samp
@item T
A function definition
@item t
A private function definition. Such functions are defined in C with
the keyword @code{static}.
@item D 
A global variable
@item R
A read-only (@code{const}) global variable
@item U
A symbol used but not defined in this object file.
@end table
@noindent
For more details, see the @cite{Binutils manual}. 

The job of the compiler is to translate all the C source files to
object files containing a corresponding set of symbolic definitions.
It is the job of another program, the @dfn{linker}, to put the object files
together, resolve and evaluate all the symbolic addresses, and build
a complete machine language program that can actually be executed.
When you ask @samp{gcc} to link the object files into an executable, the
compiler is actually running the linker to do the job. 

During the process of linking, all the machine language instructions that
refer to a specific memory address need to be modified to use the correct
addresses within the executable, as oppposed to the addresses within their
object file. This becomes an issue when you want to your program to load
and link compiled object files during run-time instead of compile-time. 
To make such @dfn{dynamic linking} possible, your symbols need to be
@dfn{relocatable}. This means that your symbols definitions must be
correct no matter where you place them in memory. There should be no
memory addresses that need to be modified. One way to do this is by
refering to memory addresses within the object file by giving an offset
from the refering address. Memory addresses outside the object file must
be treated as @dfn{interlibrary dependencies} and you must tell the compiler
what you expect them to be when you attempt to build relocatable machine code.
Unfortunately some flavours of Unix do not handle interlibrary dependencies
correctly. Fortunately, all of this mess can be dealt with in a uniform
way, to the extent that this is possible, by using GNU Libtool.
@xref{Using Libtool}, for more details.

On GNU and Unix, all compiled languages compile to object files,
and it is possible, in principle, to link object files that have originated
from source files written in different programming languages. For example
it is possible to link source code written in Fortran together with
source code written in C or C++. In such cases, you need to know how the
compiler converts the names with which the program language calls its
constructs (such as variable, subroutines, etc.) to symbol names. 
Such conversions, when they actually happen, are called 
@dfn{name-mangling}. Both C++ and Fortran do name-mangling. C however is
a very nice language, because it does absolutely no name-mangling. 
This is why when you want to write code that you want to export to
many programming languages, it is best to write it in C.
@xref{Using Fortran effectively}, for more details on how to deal with
the name-mangling done by Fortran compilers.

@c ============================================================

@node Building libraries, Dealing with header files, Programs with many source files, Compiling with Makefiles
@section Building libraries

In many cases a collection of object files form a logical unit that is used
by more than one executable. On both GNU and Unix systems, it is possible
to collect such object files and form a @dfn{library}. On the GNU system,
to create a library, you use the @file{ar} command:
@example
ar cru libfoo.a foo1.o foo2.o foo3.o
@end example
@noindent
This will create a file @file{libfoo.a} from the object files 
@file{foo1.o}, @file{foo2.o} and @file{foo3.o}. The suffix 
@file{*.a} is reserved for object file libraries.
Before using the library, it needs to be ``blessed'' by a program
called @samp{ranlib}:
@example
% ranlib libfoo.a
@end example
@noindent
The GNU system, and most Unix systems require that you run @file{ranlib},
but there have been some Unix systems where doing so is not necessary.
In fact there are Unix systems, like some versions of SGI's Irix, that don't 
even have the @samp{ranlib} command!

The reason for this is historical. Originally @code{ar}
was meant to be used merely for packaging files together. The more
well known program @code{tar} is a descendent of @code{ar} that was designed
to handle making such archives on a tape device. Now that tape devices are
more or less obsolete, @code{tar} is playing the role that was originally
meant for @code{ar}. As for @code{ar}, way back, some people thought to
use it to package @code{*.o} files. However the linker wanted a symbol table
to be passed along with the archive. So the @code{ranlib} 
program was written to generate that table and add it to the @code{*.a} file.
Then some Unix vendors thought that if they incorporated @code{ranlib}
to @code{ar} then users wouldn't have to worry about forgetting to call
@code{ranlib}. So they provided @code{ranlib} but it did nothing. Some
of the more evil ones dropped it all-together breaking many people's scripts.

Once you have a library, you can link it with other object files just
as if it were an object file itself. For example 
@example
% gcc bar.o libfoo.a -o foo
@end example
@noindent
using @file{libfoo.a} as defined above, is equivalent to writing
@example
% gcc bar.o foo1.o foo2.o foo3.o -o foo
@end example
@noindent
Libraries are particularly useful when they are @dfn{installed}.
To install a library you need to move the file @file{libfoo.a} to
a standard directory. The actual location of that directory depends
on your compiler. The GNU compiler looks for installed libraries in
@file{/usr/lib} and @file{/usr/local/lib}. Because many Unix systems
also use the GNU compiler, it is safe to say that both of these
directories are standard in these systems too. However there are
some Unix compilers that don't look at @file{/usr/local/lib} by default.
Once a library is installed, it can be used in any project from any
current directory to compile an executable that uses the subroutines that
that library provides. You can direct the compiler to link an installed
library with a set of executable files to form an executable by using
the @samp{-l} flag like this:
@example
% gcc -o foo bar.o -lfoo
@end example
@noindent
Note that if the filename of the library is @file{libfoo.a}, the 
corresponding argument to the @samp{-l} flag must be only the substring
@file{foo}, hence @samp{-lfoo}. Libraries must be named with names
that have the form @file{lib*.a}. If you have installed the @file{libfoo.a}
library in a non-standard directory, you can tell the linker to look
for the library in that directory as well by using the @samp{-L} flag.
For example, if the library was installed in @file{/home/lf/lib} then
we would have to invoke the linking like this:
@example
gcc -o bar bar.o -L/home/lf/lib -lfoo
@end example
@noindent
The @samp{-L} flag must appear before the @samp{-l} flag. 

Some people
like to pass @samp{-L.} to the compiler so they can link uninstalled 
libraries in the current working directory using the @samp{-l} flag
instead of typing in their full filenames. The idea is that they think
``it looks better'' that way. Actually this is considered bad style.
You should use the @samp{-l} flag to link only libraries that have already
been installed and use the full pathnames to link in uninstalled libraries.
The reason why this is important is because, even though it makes no
difference when dealing with ordinary libraries, it makes a lot of
difference when you are working with @dfn{shared} libraries.
(@emph{FIXME: Crossreference}).
It makes a difference whether or not you are linking
to an uninstalled or installed @emph{shared} library, and in that case
the @samp{-l} semantics mean that you are linking an installed shared 
library. Please stick to this rule, even if you are not
using shared libraries, to make it possible to switch to using shared
libraries without too much hassle.

Also, if you are linking in more than one library, 
please pay attention to the order with which you link your libraries.
When the linker links a library, it does not embed into the executable code 
the entire library, but only the symbols that are needed from the library.
In order for the linker to know what symbols are really needed from any
given library, it must have already parsed all the other libraries and 
object files that depend on that library! This implies that you
first link your object files, then you link the higher-level libraries,
then the lower-level libraries. If you are the author of the libraries,
you must write your libraries in such a manner, that the dependency graph
of your libraries is a tree. If two libraries depend on each other 
bidirectionally, then you may have trouble linking them in. This suggests that
they should be one library instead! 

@c ============================================================

@node Dealing with header files, The GPL and libraries, Building libraries, Compiling with Makefiles
@section Dealing with header files

In general libraries are composed of many @samp{*.c} files that compile
to object files, and a few @dfn{header files} (@samp{*.h}). The header
files declare the resources that are defined by the library and need to
be included by any source files that use the library's resources. 
In general a library comes with two types of header files: 
@dfn{public} and @dfn{private}. The public header files
declare resources that you want to make accessible to other software.
The private header files declare resources that are meant to be used only
for developing the library itself. To make an installed library useful,
it is also necessary to install the corresponding public header files.
The standard directory for installing header files is @file{/usr/include}.
The GNU compiler also understands @file{/usr/local/include} as an 
alternative directory. 
When the compiler encounters the directive
@example
#include <foo.h>
@end example
@noindent
it searches these standard directories for @file{foo.h}. 
If you have installed the header files in a non-standard directory,
you can tell the compiler to search for them in that directory by
using the @samp{-I} flag. For example, to build a program @file{bar}
from a source file @file{bar.c} that uses the @code{libfoo} library
installed at @file{/home/username} you would need to do the following:
@example
% gcc -c -I/home/lf/include bar.c
% gcc -o bar bar.o -L/home/lf/lib -lfoo
@end example
@noindent
You can also do it in one step:
@example
% gcc -I/home/lf/include -o bar bar.o -L/home/lf/lib -lfoo
@end example
@noindent
For portability, it is better that the @samp{-I} appear before the filenames
of the source files that we want to compile.

A good coding standard is to distringuish private from public header files
in your source code by including private header files like
@example
#include "private.h"
@end example
@noindent
and public header files like
@example
#include <public.h>
@end example
@noindent
in your implementation of the library, even when the public header files are 
not yet installed while building the library. This way source code
can be moved in or out of the library without needing to change the 
header file inclusion semantics from @samp{<..>} to @samp{".."} back and
forth. In order for this to work however, you must tell the compiler
to search for ``installed'' header files in the current directory too.
To do that you must pass the @samp{-I} flag with the current directory
@file{.} as argument (@samp{-I.}).

In many cases a header file needs to include other header files, and it
is very easy for some header files to be included more than once. 
When this happens, the compiler will complain about multiple declarations
of the same symbols and throw an error. To prevent this from happening,
please surround the contents of your header files with C preprocessor
conditional like this:
@example
#ifndef __defined_foo_h
#define __defined_hoo_h
[...contents...]
#endif
@end example
@noindent
The defined macro @code{__defined_foo_h} is used as a flag to indicate that
the contents of this header file have been included. To make sure that
each one of these macros is unique to only one header file, please 
combine the prefix @code{__defined} with the pathname of the header file
when it gets installed. If your header file is meant to be installed as
in @file{/usr/local/include/foo.h} or @file{/usr/include/foo.h} then
use @code{__defined_foo_h}. If your header files is meant to be installed
in a subdirectory like @file{/usr/include/dir/foo.h} then please use
@code{__defined_dir_foo_h} instead.

In principle, every library can be implemented using only one public header
file and perhaps only one private header file. There are problems with
this approach however:
@itemize @bullet
@item
This header file grows to be very large and slows down compilation by
processing many symbols declarations that are not relevant to the specific
source file that is being compiled.
@item
If you change the contents of the header file, it will be difficult to 
determine the minimum set of object files that need to be rebuilt since
the change could reflect to all of them, in principle. So you will 
end up rebuilding the entire library unnecessarily.
@end itemize
@noindent
For small libraries, these problems are not very serious. For large
libraries however, you may need to split the one large header file
to many smaller files. Sometimes a good approach is to have a matching
header file for each source file, meaning that if there is a @file{foo.c}
there should be a @file{foo.h}. Some other times it is better to distribute
declarations among header files by splitting the library's provided
resources to various logical categories and declaring each category on a 
separate header file. It is up to the developer to decide how to do this best.

Once this decision is made, a few issues still remain:
@itemize @bullet
@item
We don't want to burden the users of the library that use the library's
features extensively with including many header files. It should be
possible to declare the entire library with only one inclusion.
@item
The more header files we use, the more likely it is that their filenames
conflict with the filenames of header files from other installed libraries.
@end itemize
@noindent
One way of preventing the filename conflicts is to install the library's
header files in a subdirectory bellow the standard directory for 
installing header files. Then we install one header file in the standard
directory itself that includes all the header files in the subdirectory.

For example, if the Foo library wants to install headers @file{foo1.h},
@file{foo2.h} and @file{foo3.h}, it can install them under
@file{/usr/include/foo} and install in @file{/usr/include/} only
a one header file @file{foo.h} containing only:
@example
#include <foo/foo1.h>
#include <foo/foo2.h>
#include <foo/foo3.h>
@end example
@noindent
Please name this ``central'' header and the directory for the
subsidiary headers consistently after the corresponding library.
So the @file{libfoo.a} library should install a central header 
named @file{foo.h} and all subsidiary headers under the subdirectory 
@file{foo}.

The subsidiary header files should be guarded with preprocessor conditionals,
but it is not necessary to also guard the central header file that includes
them. To make the flag macros used in these preprocessor conditionals unique,
you should include the directory name in the flag macro's name. 
For example, @file{foo/foo1.h} should be guarded with
@example
#ifndef __defined_foo_foo1_h
#define __defined_foo_foo1_h
[...contents...]
#endif
@end example
@noindent
and similarly with @file{foo/foo2.h} and @file{foo/foo3.h}.

This approach creates yet another problem that needs to
be addressed. If you recall, we suggested that you use the 
@code{include "..."} semantics for private header files and the
@code{include <...>} semantics for public header files.
This means that when you include the public header file @file{foo1.h}
from one of the source files of the library itself, you should write:
@example
#include <foo/foo1.h>
@end example
@noindent
Unfortunately, if you place the @file{foo1.h} in the same directory
as the file that attempts to include it, using these semantics, 
it will not work, because there is no subdirectory @file{foo} during
compile time. 

The simplest way to resolve this is by placing all of the source code
for a given library under a directory and all such header files in
a subdirectory named @file{foo}. The GNU build system in general requires
that all the object files that build a specific library be under the
same directory. This means that the C files must be in the same directory.
It is okey however to place header files in a subdirectory. 

This will also work if you have many directories, each containing the
sources for a separate library, and a source file in directory @file{bar},
for example, tries to include the header file @file{<foo/foo1.h>} from
a directory @file{foo} bellow the directory containing the source code
for the library @code{libfoo}. To make it work, just pass @samp{-I}
flags to the compiler for every directory of containing the source code
of every library in the package. 
@xref{Libraries with Automake}, for more details.
It will also work even if there are already old versions of 
@file{foo/foo1.h} installed
in a standard directory like @file{/usr/include}, because the compiler
will first search under the directories mentioned in the @samp{-I} flags
before trying the standard directories.


@c ============================================================

@node The GPL and libraries, The language runtime libraries, Dealing with header files, Compiling with Makefiles
@section The GPL and libraries

A very common point of contention is whether or not using a software library
in your program, makes your program derived work from that library. 
For example, suppose that your program uses the @code{readline ()} function
which is defined in the library @file{libreadline.a}. To do this, your
program needs to link with this library. Whether or not this makes the
program derived work makes a big difference. The readline library is
free software published under the GNU General Public License, which requires
that any derived work must also be free software and published under the
same terms. So, if your program is derived work, you have to free it;
if not, then you are not required to by the law.

When you link the library with your object files to create an executable,
you are copying code from the library and combining it with code from your
object files to create a new work. As a result, the executable is derived 
work. It doesn't matter if you create the executable by hand by running
an assembler and putting it together manually, or if you automate the
process by letting the compiler do it for you. Legally, you are doing the
same thing. 

Some people feel that linking to the library dynamically avoids
making the executable derived work of the library. A dynamically linked
executable does not embed a copy of the library. Instead, it contains
code for loading the library from the disk during run-time. 
However, the executable is still derived work.
The law makes no distinction between static linking and
dynamic linking. So, when you compile an executable and you link it 
dynamically to a GPLed library, the executable must be distributed as
free software with the library. This also means that you can not link
dynamically both to a GPLed library and a proprietary library because
the licenses of the two libraries conflict. The best way to resolve
such conflicts is by replacing the proprietary library with a free one,
or by convincing the owners of the proprietary library to license it
as free software.

The law is actually pretty slimy about what is derived work. In the
entertainment industry, if you write an original story that takes
placed in the established universe of a Hollywood serial, like Star Trek,
in which you use characters from that serial, like Captain Kirk, your story
is actually derived work, according to the law, and Paramount can claim
rights to it. Similarly, a dynamically linked executable does not 
contain a copy of the library itself, but it does contain code that refers
to the library, and it is not self-contained without the library.

Note that there is no conflict when a GPLed utility is invoked by a
proprietary program or vice versa via a @code{system ()} call. 
There is a very specific reason why this is allowed: When you were
given a copy of the invoked program, you were given permission to run it. 
As a technical matter, on Unix systems and the GNU system,
@dfn{using} a program means forking some process that is already running to
create a new process and loading up the program to take over the new process,
until it exits. This is exactly what the @code{system ()} call does, so
permission to use a program implies that you have permission to 
call it from any other program via @code{system ()}. This way, you can
run GNU programs under a proprietary @code{sh} shell on Unix, and you
can invoke proprietary programs from a GNU program. However, a free program
that @emph{depends} on a proprietary program for its operation can not
be included in a free operating system, because the proprietary program
would also have to be distributed with the system.

Because any program that uses a library becomes derived work of that library,
the GNU project occasionally uses another license, the @dfn{Lesser GPL},
(often called LGPL) to copyleft libraries. The LGPL protects the freedom
of the library, just like the GPL does,  but allows proprietary executables 
to link and use LGPLed libraries. However, this permission should only be
given when it benefits the free software community, and not to be nice
to proprietary software developers. There's no moral reason why you should
let them use your code if they don't let you use theirs.
@xref{The LGPL vs the GPL}, for a detailed discussion of this issue.

@c ============================================================

@node The language runtime libraries, Basic Makefile concepts, The GPL and libraries, Compiling with Makefiles
@section The language runtime libraries.

When you compile ordinary programs, like the hello world program the
compiler will automatically link to your program a library called
@file{libc.a}. So when you type 
@example
% gcc -c hello.c
% gcc -o hello hello.o
@end example
@noindent
what is actually going on behind the scenes is:
@example
% gcc -c hello.c
% gcc -o hello hello.c -lc
@end example
@noindent
To see why this is necessary, try @samp{nm} on @file{hello.o}:
@example
% nm hello.o
00000000 t gcc2_compiled.
00000000 T main
         U printf
@end example
@noindent
The file @file{hello.o} defines the symbol @samp{main}, but it marks the
symbol @samp{printf} as undefined. The reason for this is that 
@samp{printf} is not a built-in keyword of the C programming language,
but a function call that is defined by the @file{libc.a} library. Most of the
facilities of the C programming language are defined by this library.
The include files @file{stdio.h}, @file{stdlib.h}, and so on are only
header files that declare parts of the C library. You can read
all about the C library in the @cite{Libc manual}.

The catch is that there are many functions that you may consider standard
features of C that are not included in the @file{libc.a} library itself.
For example, all the math functions that are declared in @file{math.h}
are defined in a library called @file{libm.a} which is @emph{not} linked
by default. So if your program is using math functions and including 
@file{math.h}, then you need to explicitly link the math library by
passing the @samp{-lm} flag. The reason for this particular separation is
that mathematicians are very picky about the way their math is being
computed and they may want to use their own implementation of the math
functions instead of the standard implementation. If the math functions
were lumped into @file{libc.a} it wouldn't be possible to do that. 

For example, consider the following program that prompts for a number
and prints its square root:
@table @file
@item dude.c
@example
#include <stdio.h>
#include <math.h>

int 
main ()
@{
  double a;
  printf ("a = ");
  scanf ("%f", &a);
  printf ("sqrt(a) = %f", sqrt(a));
@}
@end example
@end table
@noindent
To compile this program you will need to do:
@example
% gcc -o dude dude.c -lm
@end example
@noindent
otherwise you will get an error message from the linker about @code{sqrt}
being an unresolved symbol.

On GNU, the @file{libc.a} library is very comprehensive. On many Unix systems
however, when you use system-level features you may need to link additional
system libraries such as 
@file{libbsd.a}, @file{libsocket.a}, @file{libnsl.a}, etc.
If you are linking C++ code, the C++ compiler will link
both @file{libc.a} and the C++ standard library @file{libstdc++.a}.
If you are also using GNU C++ features however, you will explicitly need to
link @file{libg++.a} yourself.
Also if you are linking Fortran and C code together
you must also link the Fortran run-time libraries. These libraries
have non-standard names and depend on the Fortran compiler that you use.
(@pxref{Using Fortran effectively})
Finally, a very common problem is encountered when you are writing
X applications. The X libraries and header files like to be placed in
non-standard locations so you must provide system-dependent @code{-I}
and @code{-L} flags so that the compiler can find them. Also the most
recent version of X requires you to link in some additional libraries
on top of @code{libX11.a} and some rare systems require you to link
some additional system libraries to access networking features 
(recall that X is built on top of the sockets interface and it is essentially a
communications protocol between the computer running the program and
computer that controls the screen in which the X program is displayed.)
@emph{FIXME: Crossreferences, if we explain all this in more details}.

Because it is necessary to link system libraries to form an executable,
under copyright law, the executable is derived work from the system libraries.
This means that you must pay attention to the license terms of these libraries.
The GNU @file{libc} library is under the LGPL license which allows you to
link and distribute both free and proprietary executables. The @file{stdc++}
library is also under terms that permit the distribution of proprietary
executables. The @file{libg++} library however only permits you to build
free executables. If you are on a GNU system, including Linux-based GNU
systems, the legalese is pretty straightforward. If you are on a proprietary
Unix system, you need to be more careful. The GNU GPL does not allow 
GPLed code to be linked against proprietary library. Because on Unix systems,
the system libraries are proprietary, their terms also may not allow you to
distribute executables derived from them. In practice, they do however,
since proprietary Unix systems do want to attract proprietary applications. 
In the same spirit, the GNU GPL also makes an exception and explicitly
permits the linking of GPL code with proprietary system libraries, provided
that these libraries are a major component of the operating system
(i.e. they are part of the compiler, or the kernel, and so on), 
@strong{unless} the copy of the library itself accompanies the executable!

This includes 
proprietary @file{libc.a} libraries, the @file{libdxml.a} library in
Digital Unix, proprietary Fortran system libraries like @file{libUfor.a},
and the X11 libraries.

@c ============================================================

@node Basic Makefile concepts, More about Makefiles, The language runtime libraries, Compiling with Makefiles
@section Basic Makefile concepts

To build a very large program, you need an extended set of invocations
to the @samp{gcc} compiler and utilities like @samp{ar}, @samp{ranlib}.
As we explained (@pxref{Programs with many source files}) if you make
changes only to a few files in your source code, it is not necessary to
rebuild everything; you only need to rebuild the object files that get
to change because of your modifications and link those together with
all the other object files to form an updated executable. The @samp{make}
utility was written mainly to automate rebuilding software by determining 
the minimum set of commands that need to be called to do this, and invoking
them for you in the right order. It can also handle, many other 
tasks. For example, you can use @samp{make} to install your program's
files in the standard directories, and clean up the object files 
when you no longer need them.

To learn all about @samp{make} and especially @samp{GNU Make}, please read
the excellent @cite{GNU Make manual}. In general, to use the GNU build
system you don't need to know the most esoteric aspects of the GNU make,
because makefiles will be automatically compiled for you from higher
level descriptions. However it is important to understand the basic
aspects of @samp{make} to use the GNU build system effectively. In the
following sections we will explain only these basic aspects.

The @samp{make} utility reads its instructions from a file named 
@file{Makefile} in the current directory. @samp{make} itself has no
knowledge about the syntax of the files that it works with, and it
relies on the instructions in @file{Makefile} to figure out what it
needs to do. A makefile is essentially a list of @dfn{rules}. Each rule
has the form:
@example
@sc{Target}: @sc{Dependencies}
@key{TAB} @sc{Command}
@key{TAB} .....
@key{TAB} .....
@sc{[Blank Line]}
@end example
@noindent
The @key{TAB}s are mandatory. The blank line at the end of the rule definition
is not necessary when using GNU make but it is a good idea if you would
like backwards compatibility with Unix.
@itemize @bullet
@item
The @dfn{target} is either the name of a file that is generated by a program
or the name of an action to carry out. Object files and executable files
are examples of files that are generated by other programs. Cleaning
up the object files is an example of an action that we might want to 
carry out. Targets that correspond to an action are sometimes called
@dfn{phony targets}.
@item
In general a @dfn{dependency} is a file that is used as input to create a 
target. If a target has more than one dependencies, they must be seperated
by spaces, but they must remain on the same line. It is possible for
a target to have no dependencies. In that case, the space after the 
semicolon must be left blank. It is also possible for a target, even
one that represents an action, to be a dependency for another target. 
@item
The @dfn{commands} following the target and the dependencies must be
prepended with @key{TAB}. If the target is a file, then the commands
explain how to create that file. If the target is an action, then
the commands describe the action. These commands are your usual shell
commands that you get to type in your prompt.
@end itemize
@noindent
When you invoke @file{make} you must tell it which target you want to
build. If you don't specify a target, then @file{make} will build the
first target that is mentioned in the makefile. 

When we talk about @samp{make} @dfn{building} a target, we mean that we want 
@samp{make} to do the following things:
@enumerate 
@item 
@dfn{Build} the dependencies. If a dependency is a file written by 
@emph{you}, this means do nothing. If a dependency is a target defined
elsewhere in the makefile, this means @emph{build that target first},
which recurses this two-step process.
@item
If at least one of the dependencies is @dfn{newer} than the target, or the
file with the name of the target does not exist, then invoke the commands
that correspond to the target. If the target is a file, then the commands
should create the file. If the target is an action, then the commands
will not create any file, but they will carry out the action.
@end enumerate
@noindent
Assuming that both a dependency and the
target are files, we say that the dependency is @dfn{newer} than the target,
if the dependency was last modified more recently than the target. 
The target then should be rebuild to reflect the most recent modifications
of the dependency. 

If the requested target exists as a file, and there are no dependencies
newer than the target, then @samp{make} will do nothing except printing
a message saying that it has nothing to do. If the requested target is
an action, no file will ever exist having the same name as the name
describing the action, so every time you ask @samp{make} to build that
target, it will always carry out your request. If one of the dependencies
is a target corresponding to an action, @samp{make} will always attempt
to build it and consequently always carry out that action. 
These three observations are only corollaries of the general algorithm.

To see how all this comes together in practice let's write a @file{Makefile}
for compiling the hello world program. The simplest way to do this
is with the following makefile:
@example
hello: hello.c
@key{TAB} gcc -o hello hello.c
@end example
@noindent
This simply says that the target @file{hello} is being built from the
file @file{hello.c} by invoking the @file{gcc} command
@example
% gcc -o hello hello.c
@end example
@noindent
A more complicated way of doing the same thing is by explicitly building
the intermediate object file:
@example
hello: hello.o
@key{TAB} gcc -o hello hello.o

hello.o: hello.c
@key{TAB} gcc -c hello.c
@end example
@noindent
Note that the target that we really want to build, @file{hello} is listed
first, to make sure that it is the default target.
Finally, we can add two more phony targets @code{install} and @code{clean}
to install the hello world program and clean up the build after installation.
We get then the following:
@example
hello: hello.o
@key{TAB} gcc -o hello hello.o

hello.o: hello.c
@key{TAB} gcc -c hello.c

clean:
@key{TAB} rm -f hello hello.o

install: hello
@key{TAB} mkdir -p /usr/local/bin
@key{TAB} rm -f /usr/local/bin
@key{TAB} cp hello /usr/local/bin/hello
@end example
@noindent
The @code{clean} needs no dependencies since it just does what it does.
However, the @code{install} target needs to first make sure that the
file @file{hello} exists before attempting to install it, so it is necessary
to list @file{hello} as a dependency to @code{install}.

Please note that this simple @file{Makefile} is for illustration only,
and it is far from ideal. For example, we use the @samp{mkdir} command
to make sure that the installation directory exists before attempting
an install, but the @samp{-p} flag is not portable in Unix. Also, we usually
want to use a BSD compatible version of the @file{install} utility to
install executables instead of @file{cp}. Fortunately, you will almost
never have to worry about writing @samp{clean} and @samp{install} targets,
because those will be generated for you automatically by Automake.

@c ============================================================

@node More about Makefiles,  , Basic Makefile concepts, Compiling with Makefiles
@section More about Makefiles

Now let's consider a more complicated example. Suppose that we want to
build a program @file{foo} whose source code is four source files
@example
foo1.c, foo2.c, foo3.c, foo4.c
@end example
@noindent
and three header files:
@example
gleep1.h, gleep2.h, gleep3.h
@end example
@noindent
Suppose also, for the sake of argument, that
@enumerate
@item
@file{foo1.c} includes @file{gleep2.h} and @file{gleep3.h}
@item
@file{foo2.c} includes @file{gleep1.h}
@item
@file{foo3.c} includes @file{gleep1.h} and @file{gleep2.h}
@item
@file{foo4.c} includes @file{gleep3.h}
@end enumerate
To build the executable file @file{foo}, we need to build the
object files @file{foo1.o}, @file{foo2.o}, @file{foo3.o} and @file{foo4.o}
that correspond to the source files and link them together.
If any of the @file{*.c} files is modified, then only the corresponding
object file and the executable need to be updated. However, if one
of the header files is modified, then all the object files whose corresponding
@file{*.c} file includes the modified header file should be rebuilt.
It follows that each of the object files depends on the corresponding
@file{*.c} file and all the header files that that file includes.
We get then the following @file{Makefile}:
@example
foo: foo1.o foo2.o foo3.o foo4.o
@key{TAB} gcc -o foo1.o foo2.o foo3.o foo4.o 
 
foo1.o: foo1.c gleep2.h gleep3.h
@key{TAB} gcc -c foo1.c

foo2.o: foo2.c gleep1.h
@key{TAB} gcc -c foo2.c

foo3.o: foo3.c gleep1.h gleep2.h
@key{TAB} gcc -c foo3.c

foo4.o: foo4.c gleep3.h
@key{TAB} gcc -c foo4.c

clean:
@key{TAB} rm -f foo foo1.o foo2.o foo3.o foo4.o

install: foo
@key{TAB} mkdir -p /usr/local/bin
@key{TAB} rm -f /usr/local/bin/foo
@key{TAB} cp foo /usr/local/bin/foo
@end example
@noindent
This idea can be easily generalized for any program. If you would like
to build more than one programs, then you should add a phony target 
in the beginning that depends on the programs that you want to build.
The usual way we do this is by adding a line like
@example
all: prog1 prog2 prog3
@end example
@noindent
to the beginning of the @file{Makefile}. 

Unfortunately, this @file{Makefile} has a lot of unnecessary redundancy:
@itemize @bullet
@item
All object files get built the same way. It would be nice then, if
we didn't have to write a rule for every one of them and instead
describe how it's done in general.
@item
If we decide to change the compiler used, we would would need to edit
the @file{Makefile} in 6 places. It should be easier than that.
@item
The list of object files @code{foo1.o, ..., foo4.o} appears in at least
two places. 
@item
The directory name @file{/usr/local/bin} appears in two places.
@end itemize
@noindent
This redundancy can be eliminated by using @dfn{makefile variables} and 
@dfn{abstract rules}.

@itemize @bullet
@item
@dfn{Makefile variables} are actually more like macro definitions. 
The syntax for defining a @dfn{makefile variable} is:
@example
@var{variable} = @var{value}
@end example
@noindent
Then, in every other rule or variable definition, the symbol 
@var{$(variable)} is substituted with @var{value}.

@item
An @dfn{abstract rule} is a definition that explains how to build a
file @file{*.@var{s2}} from a file @file{*.@var{s1}}, where @var{s1}
and @var{s2} are suffixes. The general syntax for an abstract rule is:
@example
.@var{s1}.@var{s2}: 
@key{TAB} @sc{Command}
@key{TAB} @sc{Command}
@key{TAV} .....
@end example
@noindent
where @var{s1} is the suffix of the source file, and @var{s2} is the
suffix of the corresponded generated file and @sc{Command} is the set
of commands that generate @file{*.@var{s2}} from  @file{*.@var{s1}}.
Note that no dependencies are mentioned, because dependencies don't
make sense in the general case. They must be explicitly provided for
each individual case separately.
@end itemize
@noindent
In the context of an abstract rule, the following punctuation marks have
the following meanings:
@table @samp
@item $<
are the dependencies that changed causing the target to need to be rebuilt
@item $@@
is the target
@item $^
are @emph{all} the dependencies for the current rule
@end table
@noindent
For example, the abstract rule for building an object file from a source
file is:
@example
.c.o:
@key{TAB} gcc -c $<
@end example
@noindent
Similarly, the rule for building the executable file from a set of
object files is:
@example
.o:
@key{TAB} gcc $^ -o $@@
@end example
@noindent
Note that because executables don't have a suffix, we only mention the
suffix of the object files. When only one suffix appears, it is
assumed that it is suffix @var{s1} and that suffix @var{s2} is the 
empty string.

The suffixes involved in your abstract rules, need to be listed in
a directory tha takes the form:
@example
.SUFFIXES: @var{s1} @var{s2} ... @var{sn}
@end example
@noindent
where @var{s1}, @var{s2}, etc. are suffixes. Also,
if you've written an abstract rule, you still need to write rules 
where you mention the specific targets and their dependencies, except
that you can omit the command-part since they are covered by the abstract
rule. 

Putting all of this together, we can enhance our @file{Makefile} like
this:
@example
CC = gcc
CFLAGS = -Wall -g
OBJECTS = foo1.o foo2.o foo3.o foo4.o
PREFIX = /usr/local

.SUFFIXES: .c .o

.c.o:
@key{TAB} $(CC) $(CFLAGS) -c $<

.o:
@key{TAB} $(CC) $(CFLAGS) $^ -o $@@

foo: $(OBJECTS)
foo1.o: foo1.c gleep2.h gleep3.h
foo2.o: foo2.c gleep1.h
foo3.o: foo3.c gleep1.h gleep2.h
foo4.o: foo4.c gleep3.h

clean:
@key{TAB} rm -f $(OBJECTS)

install: foo
@key{TAB} mkdir -p $(PREFIX)/bin
@key{TAB} rm -f $(PREFIX)/bin/foo
@key{TAB} cp foo $(PREFIX)/bin/foo
@end example
@noindent
The only part of this Makefile that still requires some thinking on your
part, is the part where you list the object files and their dependencies:
@example
foo1.o: foo1.c gleep2.h gleep3.h
foo2.o: foo2.c gleep1.h
foo3.o: foo3.c gleep1.h gleep2.h
foo4.o: foo4.c gleep3.h
@end example
@noindent
Note however, that in principle even that can be automatically generated. 
Even though the @file{make} utility does not understand C source code
and can not determine the dependencies, the GNU C compiler can. 
If you use the @samp{-MM} flag, then the compiler will compute and output
the dependency lines that you need to include in your Makefile. For example:
@example
% gcc -MM foo1.c
foo1.o: foo1.c gleep2.h gleep3.h
% gcc -MM foo2.c
foo2.o: foo2.c gleep1.h
% gcc -MM foo3.c
foo3.o: foo3.c gleep1.h gleep2.h
% gcc -MM foo4.c
foo4.o: foo4.c gleep3.h
@end example
@noindent
Unfortunately, unlike all the other compiler features we have described
up until now, this feature is not portable in Unix. If you have installed
the GNU compiler on your Unix system however, then you can also do this.

Dealing with dependencies is one of the major drawbacks of writing
makefiles by hand. Another drawback is that even though
we have moved many of the parameters to makefile variables, these
variables still need to be adjusted by somebody. There is something
rude about asking the installer to edit @file{Makefile}. 
Developers that ask their users to edit @file{Makefile} make their
user's life more difficult in an unacceptable way. Yet another annoyance
is writing @code{clean}, @code{install} and such targets. Doing so every
time you write a makefile gets to be tedious on the long run. Also,
because these targets are, in a way, mission critical, it is really important
not to make mistakes when you are writing them. Finally, if you want
to use multiple directories for every one of your libraries and
programs, you need to setup your makefiles to recursively
call @samp{make} on the subdirectories, write a whole lot of makefiles,
and have a way of propagating configuration information to every one of
these makefiles from a centralized source.

These problems are not impossible to deal with, but you need a lot of
experience in makefile writing to overcome them. Most developers don't
want to bother as much with all this, and would rather be debugging
ther source code. The GNU build system helps you set up your source code
to make this possible. For the same example, the GNU developer only needs to
write the following @file{Makefile.am} file:
@example
bin_PROGRAMS = foo
foo_SOURCES = foo1.c foo2.c foo3.c foo4.c 
noinst_HEADERS = gleep1.h gleep2.h gleep3.h
@end example
@noindent
and set a few more things up. This file is then compiled into an
intermediate file, called @file{Makefile.in}, by Automake, and during
installation the final @file{Makefile} is generated from @file{Makefile.in}
by a shell script called @file{configure}. This shell script is provided
by the developer and it is also automatically generated with Autoconf.
For more details see 
@ref{Hello world example with Autoconf and Automake}.

In general you will not need to be writing makefiles by hand. It is 
useful however to understand how makefiles work and how to write 
abstract rules.

@c ============================================================
@c ============================================================

@node The GNU build system, Using Automake, Compiling with Makefiles, Top
@chapter The GNU build system

The GNU build system has two goals. The first is to simplify the development
of portable programs. The second is to simplify the building of programs that
are distributed as source code. The first goal is achieved by the automatic
generation of a @file{configure} shell script, which configures the source 
code to the installer platform. The second goal is achieved
by the automatic generation of Makefiles and other shell scripts that are
typically used in the building process. This way the developer can concentrate
on debugging per source code, instead of per overly complex Makefiles.
And the installer can compile and install the program directly from the 
source code distribution by a simple and automatic procedure.

@menu
* Introducing the GNU tools::   
* Installing the GNU build system::  
* Hello world example with Autoconf and Automake::  
* Understanding the hello world example::  
* Using configuration headers::  
* Maintaining the documentation files::  
* Organizing your project in subdirectories::  
* Applying the GPL::            
* Handling version numbers::    
* Hello world with acmkdir::    
@end menu

@node Introducing the GNU tools, Installing the GNU build system, The GNU build system, The GNU build system
@section Introducing the GNU tools

When we speak of the @dfn{GNU build system} we refer primarily to the 
following four packages:
@enumerate
@item
@strong{Autoconf} produces a @dfn{configuration shell script}, named 
@file{configure}, which probes the installer platform for portability related
information which is required to customize makefiles, configuration header
files, and other application specific files. Then it proceeds to generate
customized versions of these files from generic templates. This way, the
user will not need to customize these files manually.
@item
@strong{Automake} produces makefile templates, @file{Makefile.in} to be used
by Autoconf, from a very high level specification stored in a file called
@file{Makefile.am}. Automake produces makefiles that conform to the GNU
makefile standards, taking away the extraordinary effort required to produce
them by hand. Automake requires Autoconf in order to be used properly.
@item
@strong{Libtool} makes it possible to compile position indepedent code and
build shared libraries in a portable manner. It does not require either
Autoconf, or Automake and can be used indepedently. Automake however supports
libtool and interoperates with it in a seamless manner.
@item
@strong{Autotools} helps you develop portable source code that conforms
to the GNU coding standards by generating various boilerplate
files from which you can plunge into developing your software. 
@end enumerate
@noindent
Some tasks that are simplified by the GNU build system include:
@enumerate
@item
Building multidirectory software packages. It is much more difficult to use
raw @code{make} recursively. Having simplified this step, the developer
is encouraged to organize per source code in a deep directory tree rather than
lump everything under the same directory. Developers that use raw @code{make}
often can't justify the inconvenience of recursive make and prefer to
disorganize their source code. With the GNU tools this is no longer necessary.
@item
Automatic configuration. You will never have to tell your users that they
need to edit your Makefile. You yourself will not have to edit your Makefiles
as you move new versions of your code back and forth between different
machines.
@item
Automatic makefile generation. Writing makefiles involves a lot of repetition,
and in large projects very error-prone. Also, certain portions of a good
makefile, such as the @samp{install} and @samp{uninstall} targets are
very critical because they are run by the superuser. They must be written
without any bugs! The GNU build system automates makefile writing. You
are only required to write @file{Makefile.am} files that are much more
terse and easy to maintain.
@item
Support for test suites. You can very easily write test suite code, and
by adding one extra line in your @file{Makefile.am} make a @code{check}
target available such that you can compile and run the entire test suite
by running @code{make check}.
@item
Automatic distribution building. The GNU build tools are meant to be used
in the development of @dfn{free software}, therefore if you have a working
build system in place for your programs, you can create a source code 
distribution out of
it by running @code{make distcheck}.
@item
Shared libraries. Building shared libraries becomes as easy as building
static libraries.
@end enumerate

The GNU build system needs to be installed only when you are developing
programs that are meant to be distributed. To build a program from 
distributed source code, the installer only needs a working @code{make} 
utility, a compiler, a shell,
and sometimes standard Unix utilities like @code{sed}, @code{awk},
@code{yacc}, @code{lex}. The objective is to make software installation
as simple and as automatic as possible for the installer. Also, by
setting up the GNU build system such that it creates programs that don't
require the build system to be present during their installation, it 
becomes possible to use the build system to bootstrap itself. 

@c ============================================================

@node Installing the GNU build system, Hello world example with Autoconf and Automake, Introducing the GNU tools, The GNU build system
@section Installing the GNU build system

If you are on a Unix system, don't be surprised if the GNU development
tools are not installed. Some Unix sysadmins have never heard about them.
If you do have them installed check to see whether you have the most
recent versions. To do that, type:
@example
% autoconf --version
% automake --version
% libtool --version
@end example
@noindent
This manual is current with Autoconf @value{autoconf}, Automake 
@value{automake} and Libtool @value{libtool}.

If you don't have any of the above packages, you need to get a copy and
install them on your computer. The distribution filenames for the GNU build
tools, are:
@example
autoconf-@value{autoconf}.tar.gz
automake-@value{automake}.tar.gz
libtool-@value{libtool}.tar.gz
autotools-@value{autotools}.tar.gz
@end example
@noindent
Before installing these packages however, you will need to install the 
following needed packages from the FSF:
@example
make-*.tar.gz
m4-*.tar.gz
texinfo-@value{texinfo}.tar.gz
tar-*.shar.gz
@end example
@noindent
The asterisks in the version numbers mean that the version for these
programs is not critically important.

You will need the GNU versions of @code{make}, @code{m4} and 
@code{tar} even if your system already has native versions of these utilities.
To check whether you do have the GNU versions see whether they accept the 
@code{--version} flag. If you have proprietory versions of @code{make} or
@code{m4}, rename them and then install the GNU ones. 
You will also need to install @emph{Perl}, the @emph{GNU C compiler},
and the @emph{TeX} typesetting system. These programs are always installed
on a typical Debian GNU/Linux system.

It is important to note that the end user will only need a decent shell
and a working @code{make} to build a source code distribution. The developer 
however needs to gather all of these tools in order to create the distribution.

The installation process, for all of these tools that you obtain as
@file{*.tar.gz} distributions is rather straightforward:
@example
% ./configure
% make
% make check
% make install
@end example
@noindent
Most of these tools include documentation which you can build with
@example
% make dvi
@end example
@noindent

@c ============================================================

@node Hello world example with Autoconf and Automake, Understanding the hello world example, Installing the GNU build system, The GNU build system
@section Hello world example with Autoconf and Automake


To get started we will show you how to do the Hello world program using
@samp{autoconf} and @samp{automake}. In the fine tradition of @sc{k&r}, the
C version of the hello world program is:
@example
#include <stdio.h>
main()
@{
 printf("Howdy world!\n");
@}
@end example
@noindent
Call this @file{hello.c} and place it under an empty directory.
Simple programs like this can be compiled and ran directly with the
following commands:
@example
% gcc hello.c -o hello
% hello
@end example
@noindent
If you are on a Unix system instead of a GNU system, your compiler might 
be called @samp{cc} but the usage will be pretty much the same. 

Now to do the same thing the @samp{autoconf} and @samp{automake} way
create first the following files:

@table @file
@item Makefile.am
@example
bin_PROGRAMS = hello
hello_SOURCES = hello.c
@end example
@item configure.in
@example
AC_INIT(hello.c)
AM_INIT_AUTOMAKE(hello,0.1)
AC_PROG_CC
AC_PROG_INSTALL
AC_OUTPUT(Makefile)
@end example
@end table

@noindent
Now run @samp{autoconf}:
@example
% aclocal
% autoconf
@end example
@noindent
This will create the shell script @file{configure}.
Next, run @samp{automake}:
@example
% automake -a
required file "./install-sh" not found; installing
required file "./mkinstalldirs" not found; installing
required file "./missing" not found; installing
required file "./INSTALL" not found; installing
required file "./NEWS" not found
required file "./README" not found
required file "./COPYING" not found; installing
required file "./AUTHORS" not found
required file "./ChangeLog" not found
@end example
@noindent
The first time you do this, @samp{automake} will complain a couple of things.
First it notices that the files @file{install-sh}, @file{mkinstalldirs}
and @file{missing} are not present, and it installs copies. These files
contain boiler-plate shell scripts that are needed by the makefiles that 
@samp{automake} generates. It also complains that the following files
are not around:
@example
INSTALL, COPYING, NEWS, README, AUTHORS, ChangeLog
@end example
@noindent
These files are required to be present by the GNU coding standards, and
we discuss them in detail in 
@ref{Maintaining the documentation files}.
At this point, it is important to at least touch these files, otherwise
if you attempt to do a @samp{make distcheck} it will deliberately fail.
To make these files exist, type:
@example
% touch NEWS README AUTHORS ChangeLog
@end example
@noindent
and to make Automake aware of the existence of these files, rerun it:
@example
% automake -a
@end example
@noindent
You can assume that the generated @file{Makefile.in} is correct, only
when Automake completes without any error messages.

Now the package is exactly in the state that the end-user will find
it when person unpacks it from a source code distribution. For future
reference, we will call this state @dfn{autoconfiscated}.
Being in an autoconfiscated state means that, you are ready to type:
@example
% ./configure
% make
% ./hello
@end example
@noindent
to compile and run the hello world program. If you really want to install it,
go ahead and call the @samp{install} target:
@example
# make install
@end example
@noindent
To undo installation, that is to @dfn{uninstall} the package, do:
@example
# make uninstall
@end example
@noindent
If you didn't use the @samp{--prefix} argument to point to your home directory,
or a directory in which you have permissions to write and execute,
you may need to be superuser to invoke the install and uninstall commands.
If you feel like cutting a source code distribution, type:
@example
make distcheck
@end example
@noindent
This will create a file called @file{hello-0.1.tar.gz} in the current
working directory that contains the project's source code, and test it
out to see whether all the files are actually included and whether the
source code passes the regression test suite. 

In order to do all of the above, you need to use the
GNU @samp{gcc} compiler. Automake depends on @samp{gcc}'s ability to
compute dependencies. Also, the @samp{distcheck} target requires 
GNiU make and GNU tar.

The GNU build tools assume that there are two types of hats that people
like to wear: the 
@dfn{developer} hat and the @dfn{installer} hat. Developers develop
the source code and create the source code distribution.
Installers just want to compile and install a source code distribution on
their system. In the free software community, the same people get to wear
either hat depending on what they want to do. If you are a developer, then
you need to install the entire GNU build system, period
(@pxref{Installing the GNU build system}).
If you are an installer, then all you need to compile and install a
GNU package is a minimal @samp{make} utility and a minimal shell.
Any native Unix shell and @samp{make} will work. 

Both Autoconf and Automake take special
steps to ensure that packages generated through the @samp{distcheck}
target can be easily installed with minimal tools. Autoconf generates
@file{configure} shell scripts that use only portable Bourne shell features.
(@pxref{Portable shell programming})
Automake ensures that the source code is in an autoconfiscated state
when it is unpacked. It also regenerates the makefiles before adding them
to the distribution, such that the installer targets
(@samp{all}, @samp{install}, @samp{uninstall}, @samp{check}, @samp{clean},
@samp{distclean}) do not depend on GNU make features. The regenerated
makefiles also do not use the @samp{gcc} cruft to compute dependencies.
Instead, precomputed dependencies are included in the regenerated makefiles,
and the dependencies generation mechanism is disabled. This will allow
the end-user to compile the package using a native compiler, if the GNU
compiler is not available. For future reference we will call this the
@dfn{installer state}.

Now wear your installer hat, and install @file{hello-0.1.tar.gz}:
@example
% gunzip hello-0.1.tar.gz
% tar xf hello-0.1.tar
% cd hello-0.1
% configure
% make 
% ./hello
@end example
@noindent
This is the full circle. The distribution compiles, and by typing
@samp{make install} it installs. If you need to switch back to the
developer hat, then you should rerun @samp{automake} to get regenerate
the makefiles. 

When you run the @samp{distcheck} target, @samp{make} will create the
source code distribution @samp{hello-0.1.tar.gz} @emph{and} it will
pretend that it is an installer and see if it the distribution can be
unpacked, configured, compiled and installed. It will also run the
test suite, if one is bundled. If you would like to skip these tests,
then run the @samp{dist} target instead:
@example
% make dist
@end example
@noindent
Nevertheless, running @samp{distcheck} is extremely helpful in debugging
your build cruft. Please never release a distribution without getting
it through @samp{distcheck}. If you make daily distributions for off-site
backup, please do pass them through @samp{distcheck}. If there are 
files missing from your distribution, the @samp{distcheck} target will
detect them. If you fail to notice such problems, then your backups
will be incomplete leading you to a false sense of security.

@c ============================================================

@node Understanding the hello world example, Using configuration headers, Hello world example with Autoconf and Automake, The GNU build system
@section Understanding the hello world example

When you made the @file{hello-0.1.tar.gz} distribution, most of the files
were automatically generated. The only files that were actually written
by your fingers were:
@table @file
@item hello.c
@example
#include <stdio.h>
main()
@{
 printf("Howdy, world!\n");
@}
@end example
@noindent
@item Makefile.am
@example
bin_PROGRAMS = hello
hello_SOURCES = hello.c
@end example
@noindent
@item configure.in
@example
AC_INIT(hello.cc)
AM_INIT_AUTOMAKE(hello,1.0)
AC_PROG_CC
AC_PROG_INSTALL
AC_OUTPUT(Makefile)
@end example
@noindent
@end table
In this section we explain briefly what the files @file{Makefile.am}
and @file{configure.in} mean.

The language of @file{Makefile.am} is a @dfn{logic language}. There is no
explicit statement of execution. Only a statement of relations from which
execution is inferred. On the other hand, the language of @file{configure.in}
is @dfn{procedural}. Each line of @file{configure.in} is a command that 
is executed. 

Seen in this light, here's what the @file{configure.in} commands shown do:
@itemize @bullet
@item
The @code{AC_INIT} command initializes the configure script. It must be
passed as argument the name of one of the source files. Any source file
will do.
@item
The @code{AM_INIT_AUTOMAKE} performs some further initializations that are
related to the fact that we are using @samp{automake}. If you are writing
your @file{Makefile.in} by hand, then you don't need to call this command.
The two comma-separated arguments are the name of the package and the
version number.
@item
The @code{AC_PROG_CC} checks to see which C compiler you have.
@item
The @code{AC_PROG_INSTALL} checks to see whether your system has a BSD
compatible install utility. If not then it uses @file{install-sh} which
@file{automake} will install at the root of your package directory if it's
not there yet.
@item
The @code{AC_OUTPUT} tells the configure script to generate @file{Makefile}
from @file{Makefile.in}
@end itemize

The @file{Makefile.am} is more obvious. The first line specifies the name
of the program we are building. The second line specifies the source files
that compose the program.

For now, as far as @file{configure.in} is concerned you need to know
the following additional facts:
@itemize @bullet
@item
If you are building a library, then your configure script must determine
how to handle @samp{ranlib}. To do that, add the @code{AC_PROG_RANLIB} 
command.
@item
If your source code contains C++ files, you need to add the
@code{AC_PROG_CXX} to your @file{configure.in}.
@item
If your source code contains @samp{yacc} and @samp{lex} files,
then you need to add:
@example
AC_PROG_YACC
AC_PROG_LEX
@end example
@noindent
to your @file{configure.in}.
@item
If your source code contains Fortran source code, you need to add 
@file{AC_PROG_FC} to your code. If you want to mix C and Fortran,
then you need to do a lot more than just that.
@xref{Using Fortran effectively}, for more details.
@item
If you have any makefiles in subdirectories you must also put them in the
@code{AC_OUTPUT} statement like this:
@example
AC_OUTPUT(Makefile          \
          dir1/Makefile     \
          dir2/Makefile     \
         )
@end example
@noindent
Note that the backslashes are not needed if you are using the bash shell.
For portability reasons, however, it is a good idea to include them.
Make sure that @emph{every} subdirectory where building takes place,
is mentioned!
@end itemize

Now consider the commands that are used to build the hello world distribution:
@example
% aclocal
% autoconf
% touch README AUTHORS NEWS ChangeLog
% automake -a 
% ./configure
% make
@end example
@noindent
The first three commands bring the package in autoconfiscated state. The
remaining two commands do the actual configuration and building. More
specifically:
@itemize @bullet
@item
The @samp{aclocal} command installs a file called @file{aclocal.m4}. Normally,
in that file you are supposed to place the definitions of any @samp{autoconf} 
macros that you've written that happen to be in use in @file{configure.in}.
We will teach you how to write @samp{autoconf} macros later.
The @samp{automake} utility uses the @code{AM_INIT_AUTOMAKE} macro which is
not part of the standard @samp{autoconf} macros. For this reason, it's
definition needs to be placed in @file{aclocal.m4}. If you call @samp{aclocal}
with no arguments then it will generate the appropriate @file{aclocal.m4} file.
Later we will show you how to use @samp{aclocal} to also install your
own @samp{autoconf} macros.
@item
The @samp{autoconf} command combines the @file{aclocal.m4} and 
@file{configure.in} files and produces the @file{configure} script.
And now we are in bussiness.
@item
The @samp{touch} command makes the files @file{README} and friends exist.
It is important that these files exist before calling Automake, because
Automake decides whether to include them in a distribution by checking
if they exist at the time that you invoke @samp{automake}. Automake
@emph{must} decide to include these files, because when you type
@samp{make distcheck} the presense of these files will be required.
@item
The @samp{automake} command compiles a @file{Makefile.in} file from
@file{Makefile.am} and if absent it installs various files that are required
either by the GNU coding standards or by the makefile that will be generated.
@end itemize

The @file{configure} script probes your platform and generates makefiles
that are customized for building the source code on your platform. The 
specifics of how the probing should be done are programmed in 
@file{configure.in}. The generated makefiles are based on templates
that appear in @file{Makefile.in} files. In order for these templates
to cooperate with @file{configure} and produce makefiles that conform
to the GNU coding standards they need to contain a tedious amount of boring
stuff. This is where Automake comes in. Automakes generates the
@file{Makefile.in} files from the more terse description in
@file{Makefile.am}. As you have seen in the example, @file{Makefile.am}
files can be very simple in simple cases. Once you have customized makefiles,
your make utility takes over.

How does @file{configure} actually convert the template @file{Makefile.in}
to the final makefile? The @file{configure} script really does
two things:
@enumerate
@item
It maintains a list of @dfn{substitutions} that it accumulates while
probing the installer platform. Each one of these substitutions consists
of a symbolic name, and the actual text that we want to substitute. 
When the @file{configure} script runs @code{AC_OUTPUT} it parses
all of the files listed in @code{AC_OUTPUT} and every occurance of
@code{@@FOO@@} in these files is substituted with the text that corresponds
to @code{FOO}. For example, if you add the following lines to 
@file{configure.in} you will cause @code{@@FOO@@} to be substituted with
@samp{hello}:
@example
FOO="hello"
AC_SUBST(FOO)
@end example
@noindent
This is how @file{configure}
exports compile-time decisions to the makefile, such as what compiler
to use, what flags to pass the compilers and so on.
Occasionally, you want to use @file{configure}'s substitution capability
directly on files that are not makefiles. This is why it is important
to be aware of it. 
@xref{Scripts with Automake}, for an example.
@item
It maintains a list of C preprocessor macros with defined values that it 
also accumulates while probing the installer platforms. Before finishing
off, @file{configure} will either generate a configuration file that defines 
these C preprocessor macros to the desired values, or set a flag in
the generated makefile (through substitution) that will pass @samp{-D}
flags to the compiler. We discuss configuration headers in the
following 
@iftex
section.
@end iftex
@ifinfo
node.
@end ifinfo
@end enumerate
@xref{Writing Autoconf macros}, for more details on the internals of
@file{configure} scripts.

@c ============================================================

@node Using configuration headers, Maintaining the documentation files, Understanding the hello world example, The GNU build system
@section Using configuration headers

If you inspect the output of @samp{make} while compiling the hello world
example, you will see that the generated Makefile is passing @samp{-D}
flags to the compiler that define the macros @code{PACKAGE} and @code{VERSION}.
These macros are assigned the arguments that are passed to the 
@code{AM_INIT_AUTOMAKE} command in @file{configure.in}. 
One of the ways in which @file{configure} customizes your source code to
a specific platform is by getting such C preprocessors defined. The 
definition is requested by appropriate commands in the @file{configure.in}.
The @code{AM_INIT_AUTOMAKE} command is one such command. 

The GNU build system by default implements C preprocessor macro definitions
by passing @samp{-D} flags to the compiler. When there is too many of these
flags, we have two problems: the @samp{make} output becomes hard to read,
and more importantly we are running the risk of hitting the buffer limits
of braindead Unix implementations of @samp{make}. To work around this problem,
you can ask Autoconf to use another approach in which all macros are
defined in a special header file that is included in all the sources.
This header file is called a @dfn{configuration header}.

A hello world program using this technique looks like this
@table @file
@item configure.in
@example
AC_INIT(hello.c)
AM_CONFIG_HEADER(config.h)
AM_INIT_AUTOMAKE(hello,0.1)
AC_PROG_CC
AC_PROG_INSTALL
AC_OUTPUT(Makefile)
@end example
@noindent
@item Makefile.am
@example
bin_PROGRAMS = hello
hello_SOURCES = hello.c
@end example
@noindent
@item hello.c
@example
#ifdef HAVE_CONFIG_H
#include <config.h>
#endif

#include <stdio.h>
main()
@{
 printf("Howdy, pardner!\n");
@}
@end example
@noindent
@end table
@noindent
To request the use of a configuration header we use the 
@code{AM_CONFIG_HEADER} command. The configuration header must
be installed conditionally with the following three lines:
@example
#if HAVE_CONFIG_H
#include <config.h>
#endif
@end example
@noindent
It is important that @file{config.h} is the first thing that gets included.
Now autoconfiscate the source code by typing:
@example
% aclocal
% autoconf
% touch NEWS README AUTHORS ChangeLog
% autoheader
% automake -a
@end example
@noindent
It is important to type these commands in the order shown. The difference
between this, and what we did in 
@ref{Hello world example with Autoconf and Automake}, is that 
we had to run a new program: @samp{autoheader}. This program scans 
@file{configure.in} and generates a template file @file{config.h.in} listing
all the C preprocessor macros that might be defined and comments that should
accompany the macros describing what they do. When you run @file{configure},
it will load in @file{config.h.in} and use it to generate the final
@file{config.h} that will be used by the source code during compilation.

Now you can go ahead and build the program:
@example
% configure
% make
gcc -DHAVE_CONFIG_H -I. -I. -I.   -g -O2 -c hello.c
gcc -g -O2  -o hello  hello.o 
@end example
@noindent
Note that now instead of multiple @code{-D} flags, there is only one 
such flag passed: @code{-DHAVE_CONFIG_H}. Also, appropriate @code{-I}
flags are passed to make sure that @file{hello.c} can find and include
@file{config.h}.
To test the distribution, type:
@example
% make distcheck
......
========================
hello-0.1.tar.gz is ready for distribution
========================
@end example
@noindent
and it should all work out.

The @file{config.h} files go a long way back in history. In the past, there
used to be packages where you would have to manually edit @file{config.h}
files and adjust the macros you wanted defined by hand. This made these
packages very difficult to install because they required intimate knowledge
of your operating system. For example, it was not unusual to see a comment
saying @emph{``if your system has a broken vfork, then define this macro''}.
Many installers found this frustrating because they didn't really know how
to configure the esoteric details of the @file{config.h} files. 
With autoconfiguring source code all of these details can be taken care
of automatically, shifting this burden from the installer to the developer
where it belongs.

@c =======================================================================

@node Maintaining the documentation files, Organizing your project in subdirectories, Using configuration headers, The GNU build system
@section Maintaining the documentation files

Every software project must have its own directory. A minimal ``project''
is the example that we described in 
@ref{Hello world example with Autoconf and Automake}. In general,
even a minimal project must have the files:
@example
README, INSTALL, AUTHORS, THANKS, NEWS, ChangeLog
@end example
@noindent
Before distributing your source code, it
is important to write the real contents of these files.
In this section we give a summary overview
on how these files should be maintained. For more details, please see
the @emph{GNU coding standards} as published by the FSF.

@itemize @bullet
@item
@strong{The README file:}
Every distribution must contain this file. This is the file that the
installer must read @emph{fully} after unpacking the distribution and
before configuring it. You should briefly explain the purpose of the
distribution, and reference all other documentation available. Instructions
for installing the package normally belong in the @file{INSTALL} file.
However if you have something that you feel the installer @emph{should}
know then mention it in this file. Do not make the configuration or
installation process more complex, because you fear installers will not
@file{README} files. Assume this file is being read.

For pretest releases, @emph{only}, you might also decide to distribute
a file @file{README-alpha} containing special comments for your friendly
pretesters. If you use the recommended version numbering scheme
(@pxref{Handling version numbers}), you can automate it's distribution
by adding the following code in your @file{configure.in}:
@example
changequote(,)dnl
case $VERSION in
 [0-9]*.[0-9]*[a-z]) DIST_ALPHA="README-alpha";;
 [0-9]*.[0-9]*.[0-9]*) DIST_ALPHA="README-alpha";;
 *) DIST_ALPHA=;;
esac
changequote([, ])dnl
AC_SUBST(DIST_ALPHA)
@end example
@noindent
In your top-level @file{Makefile.am}, add something like:
@example
EXTRA_DIST = $(DIST_ALPHA)
@end example
@noindent
@item
@strong{The INSTALL file:}
Because the GNU installation procedure is streamlined, a standard 
@file{INSTALL} file will be created for you automatically by @code{Automake}.
If you have something very important to say, it may be best to say it in
the @file{README} file instead. the @file{INSTALL} file is mostly for
the benefit of people who've never installed a GNU package before. 
However, if your package is very unusual, you may decide that it is
best to modify the standard INSTALL file or write your own. 
@item 
@strong{The AUTHORS file:}
This file should collect a trace of all the legal paperwork that you have
exchanged with contributors for your particular package. This information
is very useful for registering the copyright of your package.
The file might have an introductory blurb similar to this one:
@example
Authors of PACKAGE

The following contributions warranted legal paper exchanges 
with [the Free Software Foundation | Your Name]. 
Also see files ChangeLog and THANKS
@end example
@noindent
Then, list who the
contributors are and what files they have worked on. Indicate whether
they created the file, or whether they modified it. 
For example:
@example
Random J. Hacker:
  entire files  -> foo1.c , foo2.c , foo3.c 
  modifications -> foo4.c , foo5.c
@end example
@noindent
@item 
@strong{The THANKS file:}
All distributions should contain a @file{THANKS} file containing 
a two column list of the contributors, one per line, alphabetically
sorted. The left column gives the contributor's name, while the right
column gives the last known good email address for this contributor.
This list should be introduced with a wording similar to this one:
@example
PACKAGE THANKS file

PACKAGE has originally been written by ORIGINAL AUTHOR. Many
people further contributed to PACKAGE by reporting problems,
suggesting various improvements or submitting actual code.
Here is a list of these people. Help me keep it complete and
exempt of errors.
@end example
@noindent
The easiest policy with this file is to thank everyone who contributes
to the project, without judging the value of the contribution. 

Unlike @file{AUTHORS}, the @file{THANKS} file is not maintained for
legal reasons. It is maintained to thank all the contributors that
helped you out in your project. The @file{AUTHORS} file can not be
used for this purpose because certain contributions, like bug reports
or ideas and suggestions do not require legal paper exchanges. 

You can also decide to send some kind of special greeting when you
initially add a name to your @file{THANKS} file. The mere presense
of a name in @file{THANKS} is then a flag to you that the initial 
greeting has been sent.
@item
@strong{The NEWS file:}
List the major new features of this distribution and identify the
version that they pertain to. Don't discard items from previous
versions. Leave them in the file after the newer items, so that
a user upgrading from any previous version can see what is new.
@item 
@strong{The ChangeLog file}:
Use this file to record all the changes that you make to your source code.
If your source code is distributed among many subdirectories, and there
is reason enough to think of the contents of the subdirectories as 
different subpackages,then please maintain
a separate @file{ChangeLog} file for each subdirectory. For example,
although there is usually no need to maintain a @file{ChangeLog} for 
your documentation, if you do decide to maintain one anyway, it should be
separate from your sources @file{ChangeLog}.

The @emph{GNU coding standards} explain in a lot of detail how you should
structure a @file{ChangeLog}, so you should read about it there.
The basic idea is to record @emph{semi-permenant modifications} you make to 
your source code. It is not necessary to continuously record changes
that you make while you are experimenting with something. But once you
decide that you got a modification worked out, then you should record
Please do record version releases on the central @file{ChangeLog}
(@pxref{Handling version numbers}).
This way, it will be possible to tell what changes happened between
versions.

You can automate @file{ChangeLog} maintainance with emacs.
@xref{Navigating source code}, for more details.
Recently versions of Emacs use
the ISO 8601 standard for dates which is: @code{YYYY-MM-DD} (year-month-date).
A typical @file{ChangeLog} entry looks like this:
@example
1998-05-17  Eleftherios Gkioulekas  <lf@@amath.washington.edu>

 * src/acmkdir.sh: Now acmkdir will put better default content
   to the files README, NEWS, AUTHORS, THANKS
@end example
@noindent
Every entry contains all the changes you made within the period of a day.
The most recent changes
are listed at the top, the older changes slowly scroll to the bottom.
Changes are sorted together in groups, per day of work.
@item 
@strong{COPYING}
This file contains the copyright permissions for your distribution,
in particular the General Public License
(@pxref{Licensing Free Software}).
This file is generated automatically
for you by Automake. However, it requires that you insert copyright headers
in your source code that refer to this file. 
@xref{Applying the GPL}, for more details.

Copyright is one of the many
legal concerns that you need to be aware of if you develop free software.
@xref{Legal issues with Free Software}, for more details. 
The philosophy of the GNU project, that software should be free, is
very important to the future of our community. 
@xref{Philosophical issues}, to read Richard Stallman's essays on this topic.
@end itemize

@c ============================================================

@node Organizing your project in subdirectories, Applying the GPL, Maintaining the documentation files, The GNU build system
@section Organizing your project in subdirectories

If your program is very small, you can place all your files in the
top-level directory, like we did in the Hello World example 
(@pxref{Hello world example with Autoconf and Automake}). 
Such packages are called @dfn{shallow}.

In general, it is prefered to organize your package as a @dfn{deep package}.
In a deep package, the documentation files
@example
README, INSTALL, AUTHORS, THANKS, ChangeLog, COPYING
@end example
@noindent
as well as the build cruft are placed at the top-level directory, and 
the rest of the files are placed in subdirectories. It is standard
practice to use the following subdirectories:
@table @samp
@item src
The actual source code that gets compiled. Every library
should have it's own subdirectory. Executables should get their own
directory as well. If each executable corresponds only to one or two files
then it is sensible to put them all under the same directory. If your 
executables need more source files, or they can be seperated in distinct
classes of functionalities you may like to regroup them under multiple
directories. Feel free to use your judgement on how to do this best.
It is easiest to place the library test suites on the same directory with
the library source code. If that does not sit well with you however, you
should put the test suite for each library in subdirectories @emph{under} that
library's directory. It is a massively bad idea to put the test suites
for different libraries under the same directory.
@item lib
An optional directory where you put portability-related source code.
This is mainly replacement implementation for system calls that
are unavailable on some systems. You can also put tools here that you commonly
use accross many different packages, tools that are too simple to just
make libraries out of every one of them. Common files encountered here
are files that replace system calls to the GNU C library that are not
available in proprietary C libraries. 
@item doc
A directory containing the documentation for your package.
You have the creative freedom to present the documentation in any way that is 
effective. However
the prefered way to document software is by using Texinfo. Texinfo has the 
advantage that you can produce both on-line help as well as nice printed
books from the same source. Documentation is discussed in more detail
in @xref{Maintaining Documentation}.
@item m4 
A directory containing @samp{m4} files that you package may need to 
@emph{install}. 
These files define new @samp{autoconf} macros that you
should make available to other developers who want to use your libraries.
This is discussed in more detail in @strong{FIXME: crossreference}.
@item intl
A directory containing boilerplate portability source code that allows
your program to speak in many human languages. The contents of this
directory are automatically maintained by @samp{gettext}.
(@strong{FIXME: crossreference})
@item po
A directory containing message catalogs for your software package. 
This is where the maintainer places the translations of per software
in multiple human languages.
(@strong{FIXME: crossreference})
@end table
Automake makes it very easy to maintain multidirectory source code
packages, so you shouldn't shy away from taking advantage of it.
Multidirectory packages are more convenient for most projects. 
@c ============================================================

@node Applying the GPL, Handling version numbers, Organizing your project in subdirectories, The GNU build system
@section Applying the GPL

The General Public License (GPL) is the legal implementation of the idea that 
the program, to which it is applied, belongs to the public. It means that
the public is free to use it, free to modify it and redistribute it.
And it also means that no-one can steal it from the public and use it
to create a derived work that is not free. This is different from 
@dfn{public domain}, where anyone can take a work, make a few changes,
slap a copyright notice on it, and forbid the public to use the resulting
work without a proprietary license. The idea, that a work is owned by the
public in this sense, is often called @dfn{copyleft}.

Unfortunately our legal system does not recognize this idea properly.
Every work must have an @dfn{owner}, and that person or entity is the
only one that can enforce per copyright. As a result, when a work is
distributed under the GPL, with the spirit that it belongs to the public,
only the nominal ``owner'' has the right to sue hoarders that use 
the work to create proprietary products. Unfortunately, the law does not
extend that right to the public. Despite this shortcoming, the GPL
has proven to be a very effective way to distribute free software.
Almost all of the components of the GNU system are distributed under the
GPL.

To apply the GPL to your programs you need to do the following things:
@enumerate
@item
Attach a copy of the GNU general public license to the toplevel directory of 
your
source code in a file called @file{COPYING}.
@item
Include a legal notice to @emph{every} file that you want covered by the GPL,
saying that it is covered by the GPL. It is important that all files that
constitute source code must include this notice, including @file{Makefile.am},
@file{configure.in} files and shell scripts.
The legal notice should look like this:
@example
Copyright (C) (years) (Your Name) <your@@email.address>

This program is free software; you can redistribute it and/or 
modify it under the terms of the GNU General Public License 
as published by the Free Software Foundation; either 
version 2 of the License, or (at your option) any later 
version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
@end example
@noindent
If you have assigned your copyright to an organization, like the Free 
Software Foundation, then you should probably fashion your copyright
notice like this:
@example
Copyright (C) (years) Free Software Foundation
(your name) <your@@email.address> (initial year)
etc...
@end example
@noindent
This legal notice works like a subroutine. By invoking it, you invoke the
full text of the GNU General Public License which is too lengthy to include
in every source file. Where you see @samp{(years)} you need to list all the
years in which you finished preparing a version that was actually released,
and which was an ancestor to the current version. This list is 
@emph{not} the list of years in which versions were released. It is a list
of years in which versions, later released, were completed. If you finish
a version on Dec 31, 1997 and release it on Jan 1, 1998, you need to
include 1997, but you do not need to include 1998. This rule is complicated,
but it is dictated by international copyright law. 

Some developers don't like inserting a proper legal notice to every file
in their source code, because they don't want to do the typing. 
However, it is not sufficient to just say something like 
``this file is GPLed''. You have to make
an unambiguous and exact statement, and you have to include the entire 
boilerplate text to do that. Fortunately, you can save typing by 
having Emacs insert copyright notices for you. 
@xref{Inserting copyright notices with Emacs}, for more details.
@item 
Use the @file{AUTHORS} file to keep records of who wrote what. 
@xref{Maintaining the documentation files}, for details.
@item
If you modify someone else's GPL covered file make sure to comply with 
section 2 of the GPL. To do that place notices stating that you changed
the file and the date of the change. Also your program should advertise the
fact that it is free software, that there is no warranty and that it can
be redistributed under the condition of the GPL. A standard way of doing
this is to make your program output this notice when it is passed the 
@code{--version} command-line flag. 
@item
Finally, help others to use and improve your program by writing documentation.
A free software project is not truly complete without documentation.
To make it possible for your users to update the documentation to reflect
the changes that they make, it is necessary to make the documentation free
too. However, the issues for writings are different from the issues for
software. @xref{Why free software needs free documentation}, for a
discussion of these issues. @xref{Maintaining Documentation}, for the
technical details on how to write documentation for your programs.
@end enumerate

@c ============================================================

@node Handling version numbers, Hello world with acmkdir, Applying the GPL, The GNU build system
@section Handling version numbers

The number @samp{0.1} in the filename @file{hello-0.1.tar.gz} is called
the @dfn{version number} of the source code distribution. The purpose
of version numbers is to label the various releases of a source code
distribution so that it's development can be tracked. If you use the
GNU build system, then the name of the package and the version number
are specified in the line that invokes the @samp{AM_INIT_AUTOMAKE} macro.
In the hello world example 
(@pxref{Hello world example with Autoconf and Automake})
we used the following line to set the version number equal to 0.1:
@example
AM_INIT_AUTOMAKE(hello,0.1)
@end example
@noindent
Whenever you publish a new version of your program, you must increase the 
version number. We also recommend that you note on @file{ChangeLog} 
the release of the new version. This way, when someone inspects your
@file{ChangeLog}, person will be able to determine what changes happened
between any two specific versions. 

To release the current version of your source code, run
@example
% make distcheck
@end example
@noindent
to build the distribution and apply the test suite to validate it.
Once you get this to work, change your version number in @file{configure.in},
record an entry in @file{ChangeLog} saying that you are cutting the new 
version, and update the @file{NEWS} file. Without making any other changes,
do 
@example
% make dist
@end example
@noindent
to rebuild the distribution without having to wait for the test suite
to run all over again.

Most packages declare their version with two integers: a @dfn{major number}
and a @dfn{minor number} that are separated by a dot in the middle. In
our example above, the major number is 0 and the minor number is 1. The 
minor number should be increased when you release a version that contains 
new features and improvements over the old version that you want your
users to upgrade to. The major number should be increased when the incremental
improvements bring your porgram into a new level of maturity and stability.
A major number of 0 indicates that your software is still experimental
and not ready for prime time. When you release version 1.0, you are telling
people that your software has developed to the point that you recommend it
for general use. Releasing version 2.0 means that your software has 
significantly @emph{matured} from user feedback. 

Before releasing a new major version, it is a good idea to publish a 
@dfn{prerelease} to your beta-testers. In general, the prerelease
for version 1.0 is labeled 0.90 regardless of what the previous minor number 
was. 
@footnote{In the event that the minor number has already grown larger than 90, I guess you can call your prerelease 0.900}
When releasing a 0.90 version, development should freeze, and you
should only be fixing bugs. If the prerelease turns out to be stable, it 
becomes the stable version. If not, you may need to release further bug-fixing
prereleases: 0.91, 0.92, etc. 

Many maintainers like to publish working versions of their code, so that
contributors can donate code against the most recent version of the 
source code. These unofficial versions should only be used by people who
are interested in contributing to the project, and not by end users. 
It is useful to use a third integer for writing the version numbers for
these ``unofficial'' releases. Please use only two integers for official
releases so that it is easy to distinguish them from unofficial releases.
A possible succession of version numbers might look like this:
@example
0.1, 0.1.1, 0.1.2, ... , 0.2, ..., 0.3, ..., 0.90, ..., 1.0
@end example
@noindent
It is always a good idea to maintain an archive of at least all the official
releases that you ever publish. 

@c ============================================================

@node Hello world with acmkdir,  , Handling version numbers, The GNU build system
@section Hello world with acmkdir

Whenever you start out a new programming project, there is quite a bit
of overhead setup that you need to do in order to use the GNU build system.
You need to install the documentation files described in 
@ref{Maintaining the documentation files}, and set up the directory structure
described in @ref{Organizing your project in subdirectories}. In the quest
for never-ending automation, you can do these tasks automatically with
the @samp{acmkdir} utility. 

Start by typing the following command on the shell:
@example
% ackdir hello
@end example
@noindent
@samp{acmkdir} will ask you to enter the name of your program, your name
and your email address. When you are done, @samp{acmkdir} will ask you
if you really want to go for it. Say @samp{y}. Then, @samp{acmkdir} will
do the following routine work for you:
@itemize @bullet
@item
Create the @file{hello-0.1} directory and the @file{doc}, @file{m4}
and @file{src} subdirectories.
@item
Generate the following @file{configure.in}:
@example
AC_INIT
AM_CONFIG_HEADER(config.h)
AM_INIT_AUTOMAKE(test,0.1)
AC_PROG_CC
AC_PROG_CXX
AC_PROG_RANLIB
AC_OUTPUT(Makefile doc/Makefile m4/Makefile src/Makefile)
@end example
@noindent
By default, both the C and C++ compilers are initialized, but you can take
out @samp{AC_PROG_CXX} if you don't plan to use C++. You can edit and
customize this file to your needs. More specifically, you will need to
update the version number in @samp{AM_INIT_AUTOMAKE}
everytime you cut a new distribution (@pxref{Handling version numbers}).
You should also make sure to list all the subdirectories that have
a @file{Makefile.am} in @samp{AC_OUTPUT}. 
@item
Place boilerplate @file{Makefile.am} files on the toplevel directory as well
as the @file{doc}, @file{m4} and @file{src} subdirectories. The toplevel
@file{Makefile.am} contains:
@example
EXTRA_DIST = reconf configure
SUBDIRS = m4 doc src
@end example
@noindent
The ones in the @code{src} and @code{doc} subdirectories are empty. The
one in @file{m4} contains a template @file{Makefile.am} which you should
edit if you want to add new Autoconf macros.
(@emph{FIXME: Crossreference})
@item
Create the files @file{COPYING}, @file{INSTALL}, @file{AUTHORS}, @file{NEWS},
@file{README}, @file{THANKS} and @file{ChangeLog} and generate their
default contents which you should edit further as you develop your
package. (@pxref{Maintaining the documentation files})
@item
Create a @file{reconf} script for reconfiguring your package every time
you make a change in @file{configure.in}. Running @file{reconf} is
equivalent to running the following commands on the shell from the
top-level directory:
@example
% rm -f config.cache
% rm -f acconfig.h
% aclocal -I m4
% autoconf
% acconfig
% autoheader
% automake -a
@end example
@noindent
Before @samp{acmkdir} exits, it will call the @samp{reconf} script for
you once to set things up. 
@end itemize
@noindent
At this point, you can run
@example
% ./configure
% make
@end example
@noindent
but nothing interesting will happen because the package is still empty.

To add a simple hello world program, all you need to do is create the 
following two files:
@table @file
@item src/Makefile.am
@example
bin_PROGRAMS = hello
hello_SOURCES = hello.c
@end example
@noindent
@item src/hello.c
@example
#if HAVE_CONFIG_H
# include <config.h>
#endif
#include <stdio.h>

int
main ()
@{
  printf ("Hello world\n");
@}
@end example
@end table
@noindent
and type the following commands from the toplevel directory:
@example
% ./reconf
% ./configure
% make
% make distcheck
@end example
@noindent
to compile the hello world program and build a distribution. It's that
simple!

In general, to develop simple programs with the GNU build system you 
setup the project directory tree with @samp{acmkdir}, you write your
source code, you put together the necessary @file{Makefile.am} and
update @file{configure.in} and you are set to go. In fact, at this
point you practically know all you need to know to develop source code
distributions that compile and install simple C programs. All you
need to do is write the source code and list the source files in
@samp{*_SOURCES}. 

In the following chapters we will explain in more detail how to
use the GNU build system to develop software that conforms to the
GNU coding standards.

@c ============================================================
@c ============================================================

@node Using Automake, Using Libtool, The GNU build system, Top
@chapter Using Automake

@menu
* Simple use of Automake::      
* General Automake principles::  
* Installation standard directories::  
* Libraries with Automake::     
* Applications with Automake::  
* Dealing with built sources::  
* Embedded text with Automake::  
* Scripts with Automake::       
* Emacs Lisp with Automake::    
* Guile with Automake::         
* Data files with Automake::    
@end menu

@node Simple use of Automake, General Automake principles, Using Automake, Using Automake
@section Simple use of Automake

When you develop an extensive software package, you should write all
the source code under the @file{src} directory
(@pxref{Organizing your project in subdirectories}). 
Every library should be placed in a separate subdirectory under @file{src}
named after the library, as we explained in 
@ref{Dealing with header files}. It is okey for applications to share
a directory, especially if they need to share source code. Sometimes,
it may be more practical if each applications has its own directory.
Every one of these directories needs a @file{Makefile.am} file and
all of these directories must be mentioned at the end of @file{configure.in}
in the @samp{AC_OUTPUT} invocation.

A typical @file{Makefile.am} is a list of assigments of the form:
@example
@var{variable} = @var{value}
@end example
@noindent
@file{Makefile.am} can also contain target definitions, using the same
syntax as with ordinary makefiles and abstract rules.

Most @file{Makefile.am} files begin with assigning values to the following 
variables:
@table @code
@item INCLUDES = -I/@var{dir1} -I/@var{dir2} ...
@c    ------------------------------------------
Insert the @code{-I} flags
that you want to pass to your compiler when it builds object files. Automake 
will automatically insert for you flags that point to the current source 
directory, its parent directory and the top-level source code directory. 
Please use @samp{$(top_srcdir)} to build a path to a directory within
your source code distribution. For example, to make the contents of
@file{src/foo/bar} available use:
@example
INCLUDES = -I$(top_srcdir)/src/foo/bar
@end example
@noindent
If you want to refer to directories outside your source code distribution's
hierarchy, please use absolute pathnames.
@item LDFLAGS = -L/@var{dir1} -L/@var{dir2} ...
@c    -----------------------------------------
Insert the @code{-L} flags that
you want to pass to your compiler when it builds executables.
Please don't use this flag to make directories within the source code
distribution accessible. Please refer to uninstalled libraries that interest 
you with absolute pathnames instead. 
@item LDADD = @var{foo.o} ... $(top_builddir)/dir1/libfoo.a ... -l@var{foo} ...
@c    -------------------------------------------------------------------------
List a set of object files, uninstalled libraries and installed libraries
that you want to link in with all of your executables.
Please refer to uninstalled libraries with absolute pathnames.
Because uninstalled libraries are built files, you should start your path
with @samp{$(top_builddir)}. For example, to refer to the library 
@file{libfoo.a} under @file{src/foo} write:
@example
$(top_builddir)/src/foo/libfoo.a
@end example
@noindent
The difference between @samp{$(top_srcdir)} and @samp{$(top_builddir)} is
explained in @emph{FIXME: Where?}.
@end table
@noindent
Next we list the targets that we want to build in this directory level:
@table @code
@item EXTRA_DIST = @var{file1} @var{file2} ...
List any files that you want to include into your source code distribution.
@xref{Scripts with Automake}, for an example that uses this assignment.
@item SUBDIRS = @var{dir1} @var{dir2} ...
List all the subdirectories that we want to build before building this
directory. @samp{make} will recursively invoke itself in each subdirectory
before doing anything on the current directory.
For example, this is particularly useful when writing the @file{Makefile.am} 
for the @file{src} directory itself. In that file you should list all the 
subdirectories that you have created under @file{src}.
If you mention the current directory @samp{.} in @samp{SUBDIRS} then
the current directory will be built first, and the subdirectories will be
build afterwords.
@item bin_PROGRAMS = @var{prog1} @var{prog2} ....
Lists the executable files that will
be compiled with @samp{make} and installed with @samp{make install}
under @file{/prefix/bin}, where @file{prefix} is usually @file{/usr/local}.
@item lib_LIBRARIES = @var{libfoo1.a} @var{libfoo2.a} ...
Lists all the library files that will be compiled with @code{make}
and installed with @code{make install} under @file{/prefix/lib}.
@item check_PROGRAMS = @var{prog1} @var{prog2} ...
Lists the executable files that are @strong{not} compiled with a simple
@samp{make} but only when you type @samp{make check}. These programs
are usually test programs that you use to verify pieces of your code.
Mentioning a program in @samp{check_PROGRAMS} will not cause the program
to be automatically executed during @samp{make check}. 
@item TESTS = @var{prog1} @var{prog2} ....
Lists executable files that should be executed when you run @code{make check}.
In order for these files to be compiled in the first place, you must
also mention them in @samp{check_PROGRAMS}. 
It is common to set 
@example
TESTS = $(check_PROGRAMS)
@end example
@noindent
This way by commenting the line in and out, you can modify the behaviour
of @code{make check}. While debugging your test suite, you will want to
comment out this line so that @code{make check} doesn't run the entire
test suite all the time. However, in the end product, you will want to 
comment it back in.
For more about using test suites for debugging see
@ref{Libraries with Automake}.
@item include_HEADERS = @var{foo1.h} @var{foo2.h} ....
List all the public header files in this directory that you want to 
install to @file{/prefix/include}. 
@end table
@noindent
For every program and library we must state information that will allow
Automake and Make to infer the building process.

@itemize @bullet
@item
@strong{For each Program}: You need to declare the set of files that are
sources of the program, the set of libraries that must be linked with the
program and (optionally) a set of dependencies that need to be built before
the program is built. To do this, you need to write in the 
@file{Makefile.am} the following assignments:
@table @code
@item prog_SOURCES = @var{foo1}.c @var{foo2}.c ... @var{header1}.h @var{header2}.h ....
List all the files that compose the source code of the program, including
header files. The presense of a header file here does not cause the filke
to be installed at @file{/prefix/include} but it does cause it to be
added to the distribution when you do @code{make dist}. To cause public
files to be installed you must mention them in @samp{include_HEADERS}.
Automake will generate abstract rules for building C, C++ and Fortran
files. For any other programming languages, you must provide your
own abstract rules. 
(@emph{FIXME: Crossreference})
@item prog_LDADD = $(top_builddir)/@var{dir1}/@var{libfoo.a} -l@var{bar1} -l@var{bar2} ...
List the libraries that need to be linked with your source code. Installed
libraries should be mentioned using @samp{-l} flags. Uninstalled libraries
must be mentioned using absolute pathnames, just like with the global
LDADD mentioned earlier.
@item prog_LDFLAGS = -L/@var{dir1} -L/@var{dir2} -L/@var{dir3} ...
Add the @samp{-L} flags that are needed to find the installed libraries that 
you want to link in @samp{prog_LDADD}.
@item prog_DEPENDENCIES = @var{dep1} @var{dep2} @var{dep3} ...
List any targets that you want to build before building this program.
@end table
In each one of these assignments substitute @var{prog} with the name
of the program that you are building as it appeared in @samp{bin_PROGRAMS}
or @samp{check_PROGRAMS}.

This is all you need to do. There is no need to write an extended Makefile
with all the targets, dependencies and rules for building the program.
All of these are computed for you by Automake. Also, the targets 
@samp{dist}, @samp{distcheck}, @samp{install}, @samp{uninstall}, 
@samp{clean}, @samp{distclean} are setup to handle the program.
 
@item
@strong{For each library:}
You need to make the following four assignments:
@table @code
@item libfoo_a_SOURCES = @var{foo1}.c @var{foo2}.c @var{foo}.h ...
List all the source files that compose the library, including the 
@strong{private} header files. You can list the public header files as
well, if you like, and perhaps you should for documentation, but you don't
have to. Public header files are required to be listed only in 
@samp{include_HEADERS} so that Automake knows that it must get them
installed in @file{/prefix/include}.
@item libfoo_a_LIBADD = @var{obj1}.o @var{obj2}.o @var{obj3}.o ...
List any other object files that you want to include in the library.
This feature is rarely used in cases where an object file is obtained
through an explicitly stated makefile rule. 
@end table
Note that if the name of the library is @file{libfoo.a} the prefix
that appears in the above variables that are related with the library
is @samp{libfoo_a_}
@end itemize


@c ============================================================

@node General Automake principles, Installation standard directories, Simple use of Automake, Using Automake
@section General Automake principles

In the previous section we described how to use Automake to compile 
programs, libraries and test suites. To exploit the full power of Automake
however, it is important to understand the fundamental ideas behind it. 

The simplest way to look at a @file{Makefile.am} is as a collection of
assignments which infer a set of Makefile rules, which in turn infer the
building process. There are three types of such assignments:
@itemize @bullet
@item
@dfn{Global} assignments modify the behaviour of the entire Makefile for the
given subdirectory. Examples of such assignments are @samp{INCLUDES}, 
@samp{LDADD}, @samp{LDFLAGS}, @samp{TESTS}. These assignments affect the
behaviour of the Makefile in the given directory indepedent of what gets
built. In order for an assignment to be @dfn{global}, the name of the 
variable to which you are assigning must have a special meaning to Automake.
If it does not, then the assignment has no effect, but it may be used
as a variable in other assignments.
@item
@dfn{Primitive} assignments declare the primitives that we want to build.
Such assignments are @samp{bin_PROGRAMS}, @samp{lib_LIBRARIES}, and others.
The general pattern of these assignments is two words seperated by an
underscore. The second word is always in all-caps, it is
the type of the primitive being built, and
it affects what Makefile rules are generated for building the primitive.
The first word contains information about where to install the primitive
once its built, so it affects the Makefile rules that handle the
@samp{install} and @samp{uninstall} targets. The way this works is that
for @samp{bin} there corresponds a global assignment for @samp{bindir}
containing the installation directory. For example the symbols @samp{bin}, 
@samp{lib}, @samp{include} have the following default assignments:
@example
bindir     = $(prefix)/bin
libdir     = $(prefix)/lib
includedir = $(prefix)/include
@end example
@noindent
These are the directories where you install executables, libraries and 
public header files. You can override the defaults by inserting different
assignments in your @file{Makefile.am}, but please don't do that. Instead
define new assignments. For example, if you do
@example
foodir = $(prefix)/foo
@end example
@noindent
then you can use @samp{foo_PROGRAMS}, @samp{foo_LIBRARIES}, etc. to 
list programs and libraries that you want installed in @file{/prefix/foo}.
The symbols @samp{check} and @samp{noinst} have special meanings and you
should not ever try to assign to @samp{checkdir} and @samp{noinstdir}.
@itemize @minus
@item
The @samp{check} symbol, suggests that the primitive should only be 
built when the user invokes @samp{make check} and it should not be installed.
It is only meant to be executed as part of a test suite and then get scrapped.
@item
The @samp{noinst} symbol, suggests that the primitive should not be
installed. It will be built however normally, when you invoke @samp{make}. 
You could use this to build convenience libraries which you 
intend to link in statically to executables which you do plan to install.
You could also use this to build executables which will generate source
code that will subsequently be used to build something installable.
@end itemize
Usually, you should install executables in @file{/prefix/bin}, libraries
in @file{/prefix/lib} and public header files in @file{/prefix/include}.
In general however, the GNU coding standards suggest a dozen of different
places on which you may want to install files. For more details
@xref{Installation standard directories}.
@item
@dfn{Property} assignments define the properties for every primitive that
you declare. A property is also made of two words that are seperated by
an underscore. The first word names the primitive to which the property
refers to. The second word names the name of the property itself. For 
example when you define 
@example
bin_PROGRAMS = hello
@end example
@noindent
this means that you can then say:
@example
hello_SOURCES = ...
hello_LDADD   = ...
@end example
@noindent
and so on. The @samp{SOURCES} and @samp{LDADD} are properties of @samp{hello}
which is a @samp{PROGRAMS} primitive. 
@end itemize

In addition to assignments, 
it is also possible to include ordinary targets and abstract targets in a 
@file{Makefile.am} just as you would in an ordinary @file{Makefile.am}.
This can be particularly useful in situations like the following:

@itemize @bullet
@item
You may want to have some of your C, C++ or Fortran source code written
by another program. @xref{Dealing with built sources}.
@item
You may want to generate object files from an obscure kind of source
file. For example, see @ref{Embedded text with Automake}.
@item
You may want to write programs as shell scripts in Bash, Perl or in Guile.
@xref{Scripts with Automake}, and @ref{Guile with Automake}.
@item
You may want to install data files that are generated during compile-time
from a program distributed with your software package.
@xref{Data files with Automake}.
@end itemize

Ordinary rules simply build things. Abstract rules however have a special
meaning to Automake. If you define an abstract rule that compiles
files with an arbitrary suffix into @file{*.o} an object file,
then files with such a suffix can appear in the @samp{*_SOURCES} of
programs and libraries. You must however write the abstract rule early
enough in your @file{Makefile.am} for Automake to parse it before 
encountering a sources assignment in which such files appear.
You must also mention all the additional
suffixes by assigning the variable @samp{SUFFIXES}. Automake will use
the value of that variable to put together the @code{.SUFFIXES} construct
(@pxref{More about Makefiles}).

If you need to write your own rules or abstract rules, then check at
some point that your distribution builds properly with @samp{make distcheck}.
It is very important, when you define your own rules, to follow
the following guidelines:

@itemize @bullet
@item
Prepend all the files that @emph{you} wrote, both in the dependencies
and the rules, with @samp{$(srcdir)}. This variable points to the
directory where your source code is located during the current building.
Note that this may not be necessarily the same directory as the one
returned by @samp{`pwd`} if you are doing a @dfn{VPATH build}
(@pxref{Doing a VPATH build}). During a build, the current working directory
is the directory in which files are @emph{written}, not the directory from
which files are @emph{read}. 
If you mess this up, then you will know when
@code{make distcheck} fails, which attempts to do a VPATH build.
@item
Files that in an ordinary build are @emph{written} by a program in the same 
directory as the corresponding @file{Makefile.am}, in general, are
written in the current working directory during a VPATH build. Therefore,
you can refer to such files in the same @file{Makefile.am} as
@file{./filename}. 
@item
If you need to refer to any files under the top-level directory of your
project, use @code{$(top_srcdir)} for files which @emph{you} write
(and your compiler tools @emph{read}) and @code{$(top_builddir)} for
files which @emph{the compiler tools write}.
@item
The symbols @samp{$<}, @samp{$@@}, @samp{$^} don't need to prepended
with anything, unlike ordinary filenames. GNU make will handle these
symbols correctly during a VPATH build.
Also see @ref{More about Makefiles}.
@item
For your rules use only the following commands directory:
@example
ar cat chmod cmp cp diff echo egrep expr false grep ls 
mkdir mv pwd rm rmdir sed sleep sort tar test touch true 
@end example
@noindent
Any other programs that you want to use, you must use them through make
variables. That includes programs such as these:
@example
awk bash bison cc flex install latex ld ldconfig lex ln make
makeinfo perl ranlib shar texi2dvi yacc
@end example
@noindent
The make variables can be defined through Autoconf in your @file{configure.in}.
For special-purpose tools, use the AC_PATH_PROGS macro. For example:
@example
AC_PATH_PROGS(BASH, bash)
AC_PATH_PROGS(PERL, perl perl5)
@end example
@noindent
Some special tools have their own autoconf macros:
@example
AC_PROG_MAKE_SET @expansion{} $(MAKE)   @expansion{} make
AC_PROG_RANLIB   @expansion{} $(RANLIB) @expansion{} ranlib | (do-nothing)
AC_PROG_AWK      @expansion{} $(AWK)    @expansion{} mawk | gawk | nawk | awk
AC_PROG_LEX      @expansion{} $(LEX)    @expansion{} flex | lex
AC_PROG_YACC     @expansion{} $(YACC)   @expansion{} 'bison -y' | byacc | yacc
AC_PROG_LN_S     @expansion{} $(LN_S)   @expansion{} ln -s
@end example
@noindent
See the @cite{Autoconf manual} for more information.
@end itemize



@c ============================================================

@node Installation standard directories, Libraries with Automake, General Automake principles, Using Automake
@section Installation standard directories

Previously, we mentioned that the symbols @samp{bin}, @samp{lib} and
@samp{include} refer to installation locations that are defined respectively
by the variables @samp{bindir}, @samp{libdir} and @samp{includedir}.
For completeness, we will now list the installation locations available by 
default by Automake and describe their purpose.

All installation locations are placed under one of the following directories:
@table @samp
@item prefix
The default value of @samp{$(prefix)} is @file{/usr/local} and it is used
to construct installation locations for machine-indepedent files. The actual
value is specified at configure-time with the @samp{--prefix} argument.
For example:
@example
configure --prefix=/home/lf
@end example
@noindent
@item exec_prefix
The default value of @samp{$(exec_prefix)} is @samp{$(prefix)} and it
used to construct installation location for machine-dependent files.
The actual value is specified at configure-time with the @samp{--exec-prefix}
argument. For example:
@example
configure --prefix=/home/lf --exec-prefix=/home/lf/gnulinux
@end example
@noindent
The purpose of using a seperate location for machine-dependent files
is because then it makes it possible to install the software 
on a networked file server and make that available to 
machines with different architectures. To do that there must be seperate
copies of all the machine-dependent files for each architecture in use.
@end table

The GNU coding standards describe in detail the standard directories
in which you should install your files. All of these standard locations
are supported by Automake. So, for example, you can write things like
@example
sbin_PROGRAMS = @var{prog} ...
sharedstate_DATA = @var{foo} ...
....
@end example
@noindent
without having to define the variables @samp{sbindir}, @samp{sharedstatedir}
and so on.

@enumerate
@item
Program-related files are installed in one of the following locations:
@table @code
@item bindir = $(exec_prefix)/bin
The directory for installing executable programs that users can run.
The default value for this directory is @file{/usr/local/bin}.
@item sbindir = $(exec_prefix)/sbin
The directory for installing executable programs that can be run
from the shell, but are only generally useful to system administrators.
The default value for this directory is @file{/usr/local/sbin}.
@item libexecdir = $(exec_prefix)/libexec
The directory for installing executable programs to be run by other
programs rather than by users. The default value for this directory
is @file{/usr/local/libexec}.
@item libdir = $(exec_prefix)/lib
The directory for installing libraries to be linked by other programs.
The default value for this directory is @file{/usr/local/lib}.
Please don't use this directory to install data files.
@item includedir = $(prefix)/include
The directory for installing public header files that declare the
symbols of installed libraries.
@end table
@item
Data files should be installed in one of the following directories:
@table @code
@item datadir = $(prefix)/share
The directory for installing read-only architecture independent data files.
The default value for this directory is @file{/usr/local/share}.
Usually, most data files that you would like to install will have to
go under this directory. These files are part of the program implementation
and should not be modified.
@item sysconfdir = $(prefix)/etc
The directory for installing read-only data files that pertain to a
single machine's configuration. Even though applications should only
read, and not modify, these files, the user may have to modify these
files to configure the application. Examples of files that belong
in this directory are mailer and network configuration files, password
files and so on. Do not install files that are modified in the normal
course of their use (programs whose purpose is to change the configuration
of the system excluded). Those probably belond in
@samp{localstatedir}.
@item sharedstatedir = $(prefix)/com
The directory for installing architecture-independent data files which
the programs modify while they run. The default value for this
directory is @file{/usr/local/com}. 
@item localstatedir = $(prefix)/var
The directory for installing data files which the programs modify while
they run, and that pertain to one specific machine. Users should never
have to modify the files in this directory to configure the package's
operation. The default value for this directory is
@file{/usr/local/var}. System logs and mail spools are examples of
data files that belong in this directory.
@end table
@item
Then there are some directories for developing various eccentric
types of files:
@table @code
@item lispdir = $(datadir)/emacs/site-lisp
The directory for installing Emacs Lisp files. The default value
of this directory is 
@example
@file{/usr/local/share/emacs/site-lisp}. 
@end example
@noindent
This directory is not automatically defined by Automake. To define it,
you must invoke
@example
AM_PATH_LISPDIR
@end example
@noindent
from Autoconf. @xref{Emacs Lisp with Automake}.
@item m4dir = $(datadir)/aclocal
The directory for installing Autoconf macros. This directory is not
automatically defined by Automake so you will have to add a line
in @file{Makefile.am}:
@example
m4dir = $(datadir)/aclocal
@end example
@noindent
to define it yourself. @xref{Writing Autoconf macros}.
@end table
@noindent
@ignore
FIXME: WHAT ABOUT GUILE MODULES?
@end ignore
@item
Documentation should be installed in the following directories:
@table @code
@item infodir = $(prefix)/info
The directory for installing the Info files for this package.
The default value for this directory is @file{/usr/local/info}.
@xref{Introduction to Texinfo}.
@item mandir = $(prefix)/man
The top-level directory for installing the man pages (if any) for this
package. The default value for this directory is @file{/usr/local/man}.
@xref{Writing man pages}.
@item man1dir = $(prefix)/man1
The top-level directory for installing section 1 man pages.
@item man2dir = $(prefix)/man2
The top-level directory for installing section 2 man pages.
@end table
@end enumerate
@noindent
Automake also defines the following subdirectories for your convenience:
@example
pkglibdir     = $(libdir)/@@PACKAGE@@
pkgincludedir = $(includedir)/@@PACKAGE@@
pkgdatadir    = $(datadir)/@@PACKAGE@@
@end example
@noindent
These subdirectories are useful for segregating the files of your
package from other packages. Of these three, you are most likely to
want to use @code{pkgincludedir} to segragate public header files,
as we discussed in @ref{Dealing with header files}. For similar
reasons you might like to segregate your data files. 
The only reason for using @code{pkglibdir} is to
install dynamic libraries that are meant to be loaded only at run-time 
while an application is running.
You should not use a subdirectory for libraries that are linked to
programs, even dynamically, while the programs are being compiled, because
that will make it more difficult to compile your programs. However,
things like plug-ins, widget themes and so on should have their own
directory.

@c ============================================================

@node Libraries with Automake, Applications with Automake, Installation standard directories, Using Automake
@section Libraries with Automake

A good example, and all about how libraries should be tested and documented.
Needs thinking.

@c ============================================================

@node Applications with Automake, Dealing with built sources, Libraries with Automake, Using Automake
@section Applications with Automake

Needs thinking.

@c ============================================================

@node Dealing with built sources, Embedded text with Automake, Applications with Automake, Using Automake
@section Dealing with built sources

In some complicated packages, you want to generate part of their source
code by executing a program at compile time. For example, in one of
the packages that I wrote for an assignment, I had to generate a file
@file{incidence.out} that contained a lot of hairy matrix definitions that
were too ugly to just compute and write by hand. That file was then
included by @file{fem.cc} which was part of a library that I wrote to
solve simple finite element problems, with a preprocessor statement:
@example
#include "incidence.out"
@end example
@noindent
All source code files that are to be generated during compile time should
be listed in the global definition of @samp{BUILT_SOURCES}. This will
make sure that these files get compiled before anything else. In our
example, the file @file{incidence.out} is computed by running a program
called @file{incidence} which of course also needs to be compiled before
it is run. So the @file{Makefile.am} that we used looked like this:
@example
noinst_PROGRAMS = incidence
lib_LIBRARIES = libpmf.a

incidence_SOURCES = incidence.cc mathutil.h
incidence_LDADD = -lm

incidence.out: incidence
      ./incidence > incidence.out

BUILT_SOURCES = incidence.out
libpmf_a_SOURCES = laplace.cc laplace.h fem.cc fem.h mathutil.h

check_PROGRAMS = test1 test2
TESTS = $(check_PROGRAMS)

test1_SOURCES = test1.cc
test1_LDADD = libpmf.a -lm

test2_SOURCES = test2.cc
test2_LDADD = libpmf.a -lm
@end example
@noindent
Note that because the executable @file{incidence} has been created at
compile time, the correct path is @file{./incidence}. Always keep in mind,
that the correct path to source files, such as @file{incidence.cc} is
@file{$(srcdir)/incidence.cc}. Because the @file{incidence} program is used
temporarily only for the purposes of building the @file{libpmf.a} library,
there is no reason to install it. So, we use the @samp{noinst} prefix to
instruct Automake not to install it.

@ignore
FIXME: NEED A GUILE EXAMPLE
FIXME: NEED THE C SOURCE TEMPLATE EXAMPLE
@end ignore

@c =============================================================

@node Embedded text with Automake, Scripts with Automake, Dealing with built sources, Using Automake
@section Embedded text with Automake

In some cases, we want to embed text to the executable file of an application.
This may be on-line help pages, or it may be a script of some sort that we 
intend to execute by an interpreter library that we are linking with, like
Guile or Tcl. Whatever the reason, if we want to compile the application as
a stand-alone executable, it is necessary to embed the text in the source
code. Autotools provides with the build tools necessary to do this painlessly.

As a tutorial example, we will write a simple program that prints the contents
of the GNU General Public License. First create the directory tree for
the program:
@example
% acmkdir foo
@end example
@noindent
Enter the directory and create a copy of the @code{txtc} compiler:
@example
% cd foo-0.1
% mktxtc
@end example
@noindent
Then edit the file @file{configure.in} and add a call to the 
@code{LF_PROG_TXTC} macro. This macro depends on 
@example
AC_PROG_CC
AC_PROG_AWK
@end example
@noindent
so make sure that these are invoked also. Finally add @file{txtc.sh} to
your @code{AC_OUTPUT}.
The end-result should look like this:
@example
AC_INIT(reconf)
AM_CONFIG_HEADER(config.h)
AM_INIT_AUTOMAKE(foo,0.1)
AC_PROG_CC
AC_PROG_RANLIB
AC_PROG_AWK
LF_PROG_TXTC
AC_OUTPUT(Makefile txtc.sh doc/Makefile m4/Makefile src/Makefile)
@end example
@noindent
In the @file{src} directory use Emacs to create a file @file{src/text.txt}
containing some random text.
The @file{text.txt} file is the text that we want to print. You can substitute
it with any text you want. This file will be compiled into @file{text.o} 
during the build process. The @file{text.h} file is a header file that gives
access to the symbols defined by @file{text.o}. The file @file{copyleft.cc}
is where the @code{main} will be written. 

Next, create the following files with Emacs:
@table @strong
@item text.h
@example
extern int text_txt_length;
extern char *text_txt[];
@end example
@noindent
@item foo.c
@example
#if HAVE_CONFIG_H
# include <config.h>
#endif

#include <stdio.h>
#include "text.h"
 
main()
@{
  for (i = 1; i<= text_txt_length; i++)
    printf ("%s\n", text_txt[i]);
@}
@end example
@noindent
@item Makefile.am
@example
SUFFIXES = .txt
.txt.o:
       $(TXTC) $<
 
bin_PROGRAMS = foo
foo_SOURCES = foo.c text.h text.txt
@end example
@noindent
@end table
@noindent
and now you're set to build. Go back to the toplevel directory and go for it:
@example
$ cd ..
$ reconf
$ configure
$ make
$ src/foo | less
@end example
@noindent
To verify that this works properly, do the following:
@example
$ cd src
$ foo > foo.out 
$ diff text.txt foo.out
@end example
@noindent
The two files should be identical.
Finally, convince yourself that you can make a distribution:
@example
$ make distcheck
@end example
@noindent
and there you are.

Note that in general the text file, as encoded by the text compiler, will
not be always identical to the original. There is one and only one modification
being made: If any line has any blank spaces at the end, they are trimmed off.
This feature was introduced to deal with a bug in the Tcl interpreter, and
it is in general a good idea since it conserves a few bytes, it never hurts,
and additional whitespace at the end of a line shouldn't really be there.

This magic is put together from many different directions. It begins with
the @code{LF_PROG_TXTC} macro:

@defmac LF_PROG_TXTC
This macro will define the variable @code{TXTC} to point to a Text-to-C 
compiler. To create a copy of the compiler at the toplevel directory of your
source code, use the @code{mktxtc} command:
@example
% mktxtc
@end example
@noindent
The compiler is implemented as a shell script, and it depends on @code{sed},
@code{awk} and the C compiler, so you should call the following two macros
before invoking @code{AC_PROG_TXTC}:
@example
AC_PROG_CC
AC_PROG_AWK
@end example
@noindent
The compiler is intended to be used as follows:
@example
$(TXTC) text1.txt text2.txt text3.txt ...
@end example
@noindent
such that given the files @file{text1.txt}, @file{text2.txt}, etc. 
object files @file{text1.o}, @file{text2.o}, etc, are 
generated that contains the text from these files. 
@end defmac

@noindent
From the Automake point of view, you need to add the following two lines
to Automake:
@example
SUFFIXES = .txt
.txt.o:
        $(TXTC) $<
@end example
@noindent
assuming that your text files will end in the @code{.txt} suffix. The first
line informs Automake that there exist source files using non-standard
suffixes. Then we describe, in terms of an abstract Makefile rule, how to
build an object file from these non-standard suffixes. Recall the use of
the symbol @code{$<}. Also note that it is not necessary
to use @code{$(srcdir)} on @code{$<} for VPATH builds.
If you embed more than one type of files, then you may want to use more
than one suffixes. For example, you may have @file{.hlp} files containing
online help and @file{.scm} files containing Guile code. Then you
want to write a rule for each suffix as follows:
@example
SUFFIXES = .hlp .scm
.hlp.o:
        $(TXTC) $<
.scm.o:
        $(TXTC) $<
@end example
@noindent
It is important to put these lines before mentioning any @code{SOURCES}
assignments. Automake is smart enough to parse these abstract makefile
rules and recognize that files ending in these suffixes are valid source
code that can be built to object code. This allows you to simply list
@file{gpl.txt} with the other source files in the @code{SOURCES} assignment:
@example
foo_SOURCES = foo.c text.h text.txt
@end example
@noindent
In order for this to work however, Automake must be able to see your
abstract rules first.

When you ``compile'' a text file @file{foo.txt} this makes an object file
that defines the following two symbols:
@example
int foo_txt_length;
char *foo_txt[];
@end example
@noindent
Note that the dot characters are converted into underscores. To make these
symbols accessible, you need to define an appropriate header file with 
the following general form:
@example
extern int foo_txt_length; 
extern char *foo_txt[];
@end example
@noindent
When you include this header file into your other C or C++ files then:
@itemize @bullet
@item
You can obtain the filename containing the original text from
@example
foo_txt[0];
@end example
@noindent
and use it to print diagnostic messages.
@item
You can obtain the text itself line by line:
@example
char *foo_txt[1];   @expansion{} first line
char *foo_txt[2];   @expansion{} second line
...
@end example
@noindent
@item
The last line is set to NULL and @code{foo_txt_length} is defined such that
@example
char *foo_txt[foo_txt_length+1] == NULL
@end example
@noindent
The last line of the text is:
@example
char *foo_txt[foo_txt_length];
@end example
@noindent
You can use a @code{for} loop (or the @code{loop} macro defined by 
LF_CPP_PORTABILITY)
together with @code{foo_txt_length} to loop over the entire text, or you can
exploit the fact that the last line points to @code{NULL} and do a 
@code{while} loop.
@end itemize
and that's all there is to it.


@c ============================================================

@node Scripts with Automake, Emacs Lisp with Automake, Embedded text with Automake, Using Automake
@section Scripts with Automake

Sometimes it is better to implement an application in a scripting language
like Bash or Perl. Scripts don't need to be compiled. However, there
are still issues with scripts such as:
@itemize @bullet
@item
You want scripts to be installed with @code{make install}, uninstalled
with @code{make uninstall} and distributed with @code{make dist}.
@item
You want scripts to get the path in the @code{#!} right.
@end itemize
To let Automake deal with all this, you need to use the @samp{SCRIPTS} 
primitive. Listing a file under a @samp{SCRIPTS} primitive assignment
means that this file needs to be built, and must be allowed to
be installed in a location where executable files are normally installed.
Automake by default will not clean scripts when you invoke the @samp{clean}
target. To force Automake to clean all the scripts, you need to add the 
following line in your @file{Makefile.am}:
@example
CLEANFILES = $(bin_SCRIPTS)
@end example
@noindent
You also need to write your own targets for building the script by hand.

@noindent
For example:
@table @samp
@item hello1.sh
@example
# -* bash *-
echo "Howdy, world!"
exit 0
@end example
@noindent
@item hello2.pl
@example
# -* perl *-
print "Howdy, world!\n";
exit(0);
@end example
@noindent
@item Makefile.am
@example
bin_SCRIPTS = hello1 hello2
CLEANFILES = $(bin_SCRIPTS)
EXTRA_DIST = hello1.sh hello2.pl

hello1: $(srcdir)/hello1.sh
      rm -f hello1
      echo "#! " $(BASH) > hello1
      cat $(srcdir)/hello1.sh >> hello1
      chmod ugo+x hello1

hello2: $(srcdir)/hello2.pl
      $(PERL) -c hello2.pl
      rm -f hello2
      echo "#! " $(PERL) > hello2
      cat $(srcdir)/hello2.pl >> hello2
      chmod ugo+x hello2
@end example
@noindent
@item configure.in
@example
AC_INIT
AM_INIT_AUTOMAKE(hello,0.1)
AC_PATH_PROGS(BASH, bash)
AC_PATH_PROGS(PERL, perl)
AC_OUTPUT(Makefile)
@end example
@noindent
@end table
@noindent
Note that in the ``source'' files @file{hello1.sh} and @file{hello2.pl}
we do not include a line like
@example
#!/bin/bash
#!/usr/bin/perl
@end example
@noindent
Instead we let Autoconf pick up the correct path, and then we insert it
during @code{make}. Since we omit the @code{#!} line, we leave a comment
instead that indicates what kind of file this is.

In the special case of @code{perl} we also invoke
@example
perl -c hello2.pl
@end example
@noindent
This checks the perl script for correct syntax. If your scripting language
supports this feature I suggest that you use it to catch errors at
``compile'' time.
The @code{AC_PATH_PROGS} macro looks for a specific utility and returns
the full path.

If you wish to conform to the GNU coding standards, you may want your script
to support the @code{--help} and @code{--version} flags, and you may want
@code{--version} to pick up the version number from 
@code{AM_INIT_AUTOMAKE}.

Here's the enhanced hello world scripts:
@itemize @bullet
@item
@strong{version.sh.in}
@example
VERSION=@@VERSION@@
@end example
@noindent
@item
@strong{version.pl.in}
@example
$VERSION="@@VERSION@@";
@end example
@noindent
@item
@strong{hello1.sh}
@example
# -* bash *-
function usage
@{
 cat << EOF
Usage: 
% hello [OPTION]
 
Options:
  --help     Print this message
  --version  Print version information

Bug reports to: monica@@whitehouse.gov
EOF 
@}
 
function version
@{
 cat << EOF
hello $VERSION 
EOF
@}

function invalid
@{
 echo "Invalid usage. For help:"
 echo "% hello --help"
@}

# -------------------------
if test $# -ne 0
then
  case $1 in
  --help)
    usage
    exit
    ;;
  --version)
    version
    exit
    ;;
  *)
    invalid
    exit
    ;;
fi

# ------------------------ 
echo "Howdy world"
exit
@end example
@noindent
@item
@strong{hello2.pl}
@example
# -* perl *-
sub usage
@{
 print <<"EOF";
Usage: 
% hello [OPTION]

Options:
  --help     Print this message
  --version  Print version information

Bug reports to: monica@@whitehouse.gov
EOF
exit(1);
@}

sub version
@{
 print <<"EOF";
hello $VERSION 
EOF
 exit(1);
@}

sub invalid
@{
 print "Invalid usage. For help:\n";
 print "% hello --help\n";
 exit(1);
@}

# --------------------------
if ($#ARGV == 0)
@{
 do version() if ($ARGV[0] eq "--version");
 do usage()   if ($ARGV[0] eq "--help");
 do invalid();
@}
# --------------------------
print "Howdy world\n";
exit(0);
@end example
@noindent
@item
@strong{Makefile.am}
@example
bin_SCRIPTS = hello1 hello2
CLEANFILES = $(bin_SCRIPTS)
EXTRA_DIST = hello1.sh hello2.pl

hello1: $(srcdir)/hello1.sh $(srcdir)/version.sh
      rm -f hello1
      echo "#! " $(BASH) > hello1
      cat $(srcdir)/version.sh $(srcdir)/hello1.sh >> hello1
      chmod ugo+x hello1

hello2: $(srcdir)/hello2.pl $(srcdir)/version.pl
      $(PERL) -c hello2.pl
      rm -f hello2
      echo "#! " $(PERL) > hello2
      cat $(srcdir)/version.pl $(srcdir)/hello2.pl >> hello2
      chmod ugo+x hello2
@end example
@noindent
@item
@strong{configure.in}
@example
AC_INIT
AM_INIT_AUTOMAKE(hello,0.1)
AC_PATH_PROGS(BASH, bash)
AC_PATH_PROGS(PERL, perl)
AC_OUTPUT(Makefile
          version.sh
          version.pl
         )
@end example
@noindent
@end itemize

Basically the idea with this approach is that when @code{configure} calls
@code{AC_OUTPUT} it will substitute the files @code{version.sh} and
@code{version.pl} with the correct version information. Then, during
building, the version files are merged with the scripts. The scripts
themselves need some standard boilerplate code to handle the options.
I've included that code here as a sample implementation, which I hereby
place in the public domain.

@c =============================================================

@node Emacs Lisp with Automake, Guile with Automake, Scripts with Automake, Using Automake
@section Emacs Lisp with Automake

If your package requires you to edit a certain type of files, you
might wnat to write an Emacs editing mode for it. Emacs modes are written
in Emacs LISP, and Emacs LISP source code is written in files that are 
suffixed with @samp{*.el}. Automake can byte-compile and install Emacs LISP
files using Emacs for you. 

To handle Emacs LISP, you need to invoke the 
@example
AM_PATH_LISPDIR
@end example
@noindent
macro in your @file{configure.in}. In the directory containing the Emacs
LISP files, you must add the following line in your @file{Makefile.am}:
@example
lisp_LISP = file1.el file2.el ...
@end example
@noindent
where @samp{$(lispdir)} is initialized by @samp{AM_PATH_LISPDIR}.
The @samp{LISP} primitive also accepts the @samp{noinst} location.

Most Emacs LISP files are meant to be simply compiled and installed.
Then the user is supposd to add certain invocations in per @file{.emacs}
to use the features that they provide. However, because Emacs LISP is a full
programming language you might like to write full programs in Emacs LISP,
just like you would in any other language, and have these programs be
accessible from the shell. If the installed file is called @file{foo.el}
and it defines a function @code{main} as an entry point, then you can
run it with:
@example
% emacs --batch -l foo -f main
@end example
@noindent
In that case, it may be useful to install a wrapper shell script containing
@example
#!/bin/sh
emacs --batch -l foo -f main
@end example
@noindent
so that the user has a more natural interface to the program. For more
details on handling shell scripts @xref{Scripts with Automake}.
Note that it's not necessary for the wrapper program to be a shell script.
You can have it be a C program, if it should be written in C for some reason.

Here's a tutorial example of how that's done. Start by creating a
directory:
@example
% mkdir hello-0.1
% cd hello-0.1
@end example
@noindent
Then create the following files:
@table @file
@item configure.in
@example
AC_INIT
AM_INIT_AUTOMAKE(hello,0.1)
AM_PATH_LISPDIR
AC_OUTPUT(Makefile)
@end example
@item hello.el
@example
(defun main () 
  "Hello world program"
  (princ "Hello world\n"))
@end example
@item hello.sh
@example
#!/bin/sh
emacs --batch -l hello.el -f main
exit
@end example
@item Makefile.am
@example
lisp_LISP = hello.el
EXTRA_DIST = hello.el hello.sh
bin_SCRIPTS = hello
CLEANFILES = $(bin_SCRIPTS)

hello: $(srcdir)/hello.sh
@key{TAB} rm -f hello
@key{TAB} cp $(srcdir)/hello.sh hello
@key{TAB} chmod ugo+x hello
@end example
@end table
@noindent
Then run the following commands:
@example
% touch NEWS README AUTHORS ChangeLog
% aclocal
% autoconf
% automake -a
% ./configure
% make
% make distcheck
# make install
@end example
@noindent

@emph{FIXME: Discussion}

@node Guile with Automake, Data files with Automake, Emacs Lisp with Automake, Using Automake
@section Guile with Automake

@emph{FIXME: Do you want to volunteer for this section?}

@c ============================================================

@node Data files with Automake,  , Guile with Automake, Using Automake
@section Data files with Automake

To install data files, you should use the @samp{DATA} primitive 
instead of @samp{SCRIPTS}. The main difference is that @samp{DATA} will allow
you to install files in data installation locations, whereas @samp{SCRIPTS}
will only allow you to install files in executable installation locations.

Normally it is assumed that the files listed in @samp{DATA} are written
by @emph{you} and are not generated by a program, therefore they are not
cleaned by default. If you want your data to be generated by a program,
you must provide a target for building the data, and you must also
mention the data file in @samp{CLEANFILES} so that it's cleaned when
you type @samp{make clean}. You should of course include the source for
the program and the appropriate lines in @file{Makefile.am} for building
the program. For example:
@example
noinst_PROGRAMS = mkdata
mkdata_SOURCES = mkdata.cc

pkgdata_DATA = thedata
CLEANFILES = $(pkgdata_DATA)

thedata: mkdata
@key{TAB} ./mkdata > thedata
@end example
@noindent
Note that because the data generation program is a one-time-use program,
we don't want to install it so we list in in @samp{noinst_*}. 

If your data files are written by hand, then all you need to do
is list them in the @samp{DATA} assignment:
@example
pkgdata_DATA = foo1.dat foo2.dat foo3.dat
@end example
@noindent
In general, you should install data files in @samp{pkgdata}. However,
if your data files are configuration files or files that the program
modifies as it runs, they should be installed in other directories.
For more details @xref{Installation standard directories}.

@c ============================================================
@c ============================================================

@node Using Libtool, Using C effectively, Using Automake, Top
@chapter Using Libtool

@c ============================================================
@c ============================================================

@node Using C effectively, Using Fortran effectively, Using Libtool, Top
@chapter Using C effectively


@c ============================================================
@c ============================================================


@node Using Fortran effectively, Internationalization, Using C effectively, Top
@chapter Using Fortran effectively

This chapter is devoted to Fortran. We will show you how to build programs
that combine Fortran and C or C++ code in a portable manner. The main reason
for wanting to do this is because there is a lot of free software written
in Fortran. If you browse @samp{http://www.netlib.org/} you will find a 
repository of lots of old, archaic, but very reliable free sources. 
These programs encapsulate a lot of experience in numerical analysis research
over the last couple of decades, which is crucial to getting work done.
All of these sources
have been written in Fortran. As a developer today, if you know other 
programming languages, it is unlikely that you
will want to write original code in Fortran. You may need, however, to use
legacy Fortran code, or the code of a neighbour who still writes in Fortran. 

The most portable way to mix Fortran with your C/C++ programs is to translate
the Fortran code to C with the @samp{f2c} compiler and compile everything with 
a C/C++ compiler. The @samp{f2c} compiler is available at 
@samp{http://www.netlib.org/} and you will find it installed on a typical
Debian GNU/Linux system. Another alternative is to use
the GNU Fortran compiler @samp{g77} with @samp{g++} and @samp{gcc}. This
compiler is portable among many platforms, so if you want to use a native
Fortran compiler without sacrificing portability, this is one way to do it.
Another way is to use your OS's native Fortran compiler, which is usually
called @samp{f77}, @strong{if} it is compatible with @samp{g77} and @samp{f77}.
Because performance is also very important in numerical codes, a good  
strategy is to prefer to use the native compiler if it is compatible,
and support @samp{f2c} and @samp{g77} as backups. 

@menu
* Fortran compilers and linkage::  
* Walkthrough a simple example::  
* Portability problems with Fortran::  
* Other Fortran dialects::      
* Popular free software in Fortran::  
@end menu

@strong{Warning:} Optimization on the GNU @samp{g77} compiler is still
buggy in many versions. In general, don't compile with optimization greater
than @samp{-O} if you are using @samp{g77}. On a Debian GNU/Linux system
you might find that it is actually more efficient to compile your Fortran
source code with @samp{f2c} and @samp{-O3} optimization, which is
reliable, than using @samp{g77} with @samp{-O} optimization. 

@c ============================================================

@node Fortran compilers and linkage, Walkthrough a simple example, Using Fortran effectively, Using Fortran effectively
@section Fortran compilers and linkage

The traditional Hello world program in Fortran looks like this:
@example
c....:++++++++++++++=
      PROGRAM MAIN
      PRINT*,'Hello World!'
      END
@end example
@noindent
All lines that begin with @samp{c} are comments. The first line is the
equivalent of @code{main()} in C. The second line says hello, and the 
third line indicates the end of the code. It is important that all command
lines are indented by 7 spaces, otherwise the compiler will issue a syntax 
error. Also, if you want to be ANSI compliant, you must write your code all
in caps. Nowadays most compilers don't care, but some may still do. 

To compile this with @samp{g77} (or @samp{f77}) you do something like:
@example
% g77 -o hello hello.f
% hello
@end example
@noindent
To compile it with the f2c translator:
@example
% f2c hello.f
% gcc -o hello hello.c -lf2c -lm
@end example
@noindent
where @samp{-lf2c} links in the translator's system library.
In order for this to work, you will have to make sure that the header file
@code{f2c.h} is present since the translated code in @file{hello.c} includes
it with a statement like 
@example
#include "f2c.h"
@end example
@noindent
which explicitly requires it to be present in the current working directory.

In this case, the @samp{main} is written in Fortran. However most of the
Fortran you will be using will actually be subroutines and functions. 
A subroutine looks like this:
@example
c....:++++++++++++++
      SUBROUTINE FHELLO (C)
      CHARACTER *(*) C
      PRINT*,'From Fortran: ',C
      RETURN
      END
@end example
@noindent
This is the analog of a @samp{void} function in C, because it takes
arguments but doesn't return anything. The prototype declaration is
@dfn{K&R} style: you list all the arguments in parenthesis, seperated with
commas, and you declare the types of the variables in the subsequent lines.

Suppose that this subroutine is saved as @file{fhello.f}. To call it from
C you need to know what it looks like from the point of the C compiler. 
To find out type:
@example
% f2c -P fhello.f
% cat fhello.P
@end example
@noindent
You will find that this subroutine has the following prototype declaration:
@example
extern int fhello_(char *c__, ftnlen c_len);
@end example
@noindent
It may come as a surprise, and this is a moment of revelation, but although
in Fortran it appears that the subroutine is taking @emph{one} argument, in
C it appears that it takes @strong{two}! And this is what makes
it difficult to link code in a portable manner between C and Fortran. In
C, everything is what it appears to be. If a function takes two arguments,
then this means that down to the machine language level, there is two 
arguments that are being passed around. In Fortran, things are being hidden
from you and done in a magic fashion. The Fortran programmer thinks that he
is passing one argument, but the compiler compiles code that actually passes
two arguments around. In this particular case, the reason for this is that
the argument you are passing is a string. In Fortran, strings are not
null-terminated, so the @samp{f2c} compiler passes the length of the string
as an extra hidden argument. This is called the @dfn{linkage method} of the
compiler. Unfortunately, linkage in Fortran is not standard, and there
exist compilers that handle strings differently. For example, some compilers
will prepend the string with a few bytes containing the length and pass
a pointer to the whole thing. This problem is not limitted to strings.
It happens in many other instances. 
The @samp{f2c} and @samp{g77} compilers follow compatible linkage, and
we will use this linkage as the @emph{ad-hoc standard}. A few proprietary
Fortran compilers like the Dec Alpha @samp{f77} and the Irix @samp{f77}
are also @samp{f2c}-compatible. The reason for this is because most of
the compiler developers derived their code from @samp{f2c}. So although
a standard was not really intended, there we have one anyway.

A few things to note about the above prototype declaration is that the 
symbol @samp{fhello} is in lower-case, even though in Fortran we write
everything uppercase, and it is appended with an underscore. On some platforms,
the proprietary Fortran compiler deviates from the @samp{f2c} standard either 
by forcing
the name to be in upper-case or by omitting the underscore. Fortunately,
these cases can be detected with Autoconf and can be worked around with
conditional compilation. However, beyond this, other portability problems,
such as the strings issue, are too involved to deal with and it is best
in these cases that you fall back to @samp{f2c} or @samp{g77}. 
A final thing to note is that although @samp{fhello} doesn't return anything,
it has return type @samp{int} and not @samp{void}. The reason for this is
that @samp{int} is the default return type for functions that are not
declared. Therefore, to prevent compilation problems, in case the user forgets
to declare a Fortran function, @samp{f2c} uses @samp{int} as the return
type for subroutines.

In Fortran parlance, a @dfn{subroutine} is what we'd call a @samp{void} 
function. To Fortran programmers in order for something to be a 
@dfn{function} it has to return something back. This reflects on the syntax.
For example, here's a function that adds two numbers and returns the
result:
@example
c....:++++++++++++++++
      DOUBLE PRECISION FUNCTION ADD(A,B)
      DOUBLE PRECISION A,B
      ADD = A + B
      RETURN
      END
@end example
@noindent
The name of the function is also the name of the return variable. 
If you run this one through @samp{f2c -P} you will find that the C prototype 
is:
@example
extern doublereal add_(doublereal *a, doublereal *b);
@end example
@noindent
There's plenty of things to note here:
@itemize @bullet
@item
The typenames being used are funny. @samp{doublereal}? what's that!?
These are all defined in a header file called @samp{f2c.h} which you are 
supposed to include in your source code before declaring any prototypes.
We will show you how this is all done in the next section. The following
table showes the types that are most likely to interest you. For more info,
take a look at the @samp{f2c.h} file itself:
@example
  integer         @expansion{} int
  real            @expansion{} float
  doublereal      @expansion{} double
  complex         @expansion{} struct @{ real r,i; @};
  doublecomplex   @expansion{} struct @{ doublereal r,i; @};
@end example
@noindent
@item
The arguments are passed by pointer. In Fortran all arguments are passed
by reference. The @samp{f2c} compiler implements this by passing the 
arguments by pointer. On the C/C++ level you may want to wrap the fortran
routine with another routine so that you don't have to directly deal with 
pointers all of the time.
@item
The value returned now is not an @samp{int} but @samp{doublereal}.
Of course, the name of the function is lower-case, as always, and 
there is an underscore at the end.
@end itemize

A more interesting case is when we deal with complex numbers. Consider 
a function that multiplies two complex numbers:
@example
c....:++++++++++++++++++++++++++++++
      COMPLEX*16 FUNCTION MULT(A,B)
      COMPLEX*16 A,B
      MULT = A*B
      RETURN
      END
@end example
@noindent
As it turns out, the prototype for this function is:
@example
extern Z_f mult_ (doublecomplex *ret_val, 
                  doublecomplex *a, 
                  doublecomplex *b);
@end example
@noindent
Because complex numbers are not a native type in C, they can not be returned
efficiently without going through at least one copy. Therefore, for this
special case the return value is placed as the first argument in the prototype!
Actually despite many people's feelings that Fortran must die, it is still
the best language for writing optimized functions that are perform complex
arithmetic.

@c ============================================================

@node Walkthrough a simple example, Portability problems with Fortran, Fortran compilers and linkage, Using Fortran effectively
@section Walkthrough a simple example

@emph{FIXME: Needs to be rewritten}

@c ============================================================

@node Portability problems with Fortran, Other Fortran dialects, Walkthrough a simple example, Using Fortran effectively
@section Portability problems with Fortran

Fortran has a few portability problems.
There exist two important
Fortran standards: one that was written in 1966 and one that was written
in 1977. The 1977 standard is considered to be @emph{the} standard Fortran.
Most of the Fortran code is written by scientists who have never had any
formal training in computer programming. As a result, they often write
code that is dependent on vendor-extensions to the standard, and not 
necessarily easy to port. The standard itself is to blame as well, since
it is sorely lacking in many aspects. For example, even though standard
Fortran has both @code{REAL} and @code{DOUBLE PRECISION} data types
(corresponding to @code{float} and @code{double}) the standard only
supports single precision complex numbers (@code{COMPLEX}). Since many
people will also want double precision complex numbers, many vendors provided
extensions. Most commonly, the double precision complex number is called
@code{COMPLEX*16} but you might also see it called @code{DOUBLE COMPLEX}.
Other such vendors extensions include providing a @code{flush} operation
of some sort for file I/O, and other such esoteric things. 

On the flip side, if you limit your Fortran code just to number-crunching, 
then it becomes much easier to write portable code. There are still a few
things you should take into account however.
Some Fortran code has been written in the archaic 1966 style. An example
of such code is the @code{fftpack} package from @code{netlib}. The main
problems with such code are the following:
@itemize @bullet
@item
@strong{Implicit types}:
In Fortran 66, programmers were too lazy to define the types of their variables.
The idea was that the type was inferred by the first letter of the variable
name. That's horror for you! The convention then is that all variables with
initial @code{I,J,...,N} are type @code{INTEGER}. All others are @code{REAL}
To compile this code with
modern compilers it is necessary to add the following line to every source
file:
@example
IMPLICIT DOUBLE PRECISION (A-H,O-Z)
@end example
@noindent
This instructs the compiler to do the right thing, which is to implicitly
assume that all variables starting with @code{A-H} and @code{O-Z} are
double precision and all other variables are integers. Alternatively you can
say
@example
IMPLICIT REAL (A-H,O-Z)
@end example
@noindent
but it is very rarely that you will ever want to go with single precision.
Occasionally, you may find that the programmer breaks the rules. For example,
in @code{fftpack} the array @code{IFAC} is supposed to be a @code{double}
even though implicitly it is suggested to be an @code{int}. Such inconstances
will probably show up in compiler errors. To fix them, declare the type
of these variables explicitly. If it's an array then you do it like this:
@example
DOUBLE PRECISION IFAC(*)
@end example
@noindent
If the variable also appears in a @code{DIMENSION} declaration, then you
should remove it from the declaration since the two can't coexist in
@emph{some} compilers.
@item
@strong{Pseudo-pointers}:
In archaic Fortran, a dimension declaration of the form:
@example
DIMENSION C(1)
@end example
@noindent
means that @code{C} has an unknown length, instead of meaning that it has 
length 1. In modern Fortran, this is an unacceptable notation and modern 
compilers do get confused over it. So all such instances must be replaced
with the correct form which is:
@example
DIMENSION C(*)
@end example
@noindent
Such ``arrays'' in reality are just pointers. The user can reference the
array as far as person likes, but of course, if person takes it too far, the
program will either do the Wrong Thing or crash with a segmentation fault.
@item
@strong{Constants}:
A most insidious problem has to do with constants and it is confined, to
the best of my knowledge, to the GNU Fortran compiler, but it could
very well be a problem in other compilers to which I have no access to.
Constants tend to appear in @samp{DATA} statements or variable assignments.
The problem is that whenever a constant is in use, the context is never
a determining factor for the @dfn{type} of the constant, unlike C which
does automatic casting. Examples: @samp{1} is always type @code{INTEGER},
@samp{9.435784839284958} is always type @code{REAL} 
(even if the additional precision specified is lost, and even when used in
a @samp{DOUBLE PRECISION} context such as being assigned to a 
@samp{DOUBLE PRECISION} variable!). On the other hand, @code{1E0} is
always @code{REAL} and @code{1D0} is always @samp{DOUBLE PRECISION}.
If you want your code to be exclusively double precision, then you should
scan the entire source for constants, and make sure that they all have the
@code{D0} suffix at the end. Many compilers will tolerate this omission while
others will not and go ahead and introduce single precision error to your
computations leading to hard to find bugs.
@end itemize

In general the code in @code{http://www.netlib.org/} is very reliable and
portable, but you do need to keep your eyes open for little problems like
the above. 

@c ============================================================

@node Other Fortran dialects, Popular free software in Fortran, Portability problems with Fortran, Using Fortran effectively
@section Other Fortran dialects

There are many variants of Fortran like Fortran 90, and HPF.
Fortran 90 attempts, quite miserably, to make Fortran 77 more like
C++. HPF allows engineers to write numerical code that runs on parallel
computers. These variants should be avoided for two reasons: 
@enumerate
@item
There are no free compilers for Fortran 90 or HPF.
If you happen to use a proprietary 
operating system, you might as well make use of proprietary compilers
if they generate highly optimized code and that is important to you. 
Nevertheless, in order for your software to be free in a useful way, it 
should be possible to compile it with free tools on a free operating system. 
A common objection is that since there are no parallel computers running
a free operating ysstem, the point is moot so one might as well use 
HPF or Fortran 90, if doing so is convenient.
This objection
is based on a premise that is now out of date. Nowadays, it is possible to
build parallel computers using commodity hardware, a modified 
version of the Linux kernel, called Beowulf, and the GNU system. 
Parallelized software
can also be free. Therefore both Fortran 90 and HPF should be avoided,
whenever that is possible until we have a free compiler for them.
@item
Another problem with these variants is that they are ad hoc languages
that have been invented to enable Fortran to do things that it can not
do by design. Eventually, when engineers will like to do things that Fortran 
90 can't do either, it will be necessary to extend Fortran again, rewrite the
compilers and produce yet another variant. What engineers really need is
a @emph{real} solid programming language, and a collection of well-designed
scientific libraries written in that language. 
@end enumerate
@noindent
Please don't contribute to the spread of these dialects. Instead contribute
infrastructure to better languages, like C and C++, to support the features 
that compell you to use Fortran 90 or HPF.

@c ============================================================

@node Popular free software in Fortran,  , Other Fortran dialects, Using Fortran effectively
@section Popular free software in Fortran

@emph{FIXME: New section. Needs to be written}

@c ============================================================
@c ============================================================

@node Internationalization, Maintaining Documentation, Using Fortran effectively, Top
@chapter Internationalization

@emph{FIXME: Needs to be written}


@c ============================================================
@c ============================================================

@node Maintaining Documentation, Portable shell programming, Internationalization, Top
@chapter Maintaining Documentation

@menu
* Browsing documentation::      
* Writing proper manuals::      
* Introduction to Texinfo::     
* Markup in Texinfo::           
* GNU Emacs support for Texinfo::  
* Writing man pages::           
* Writing documentation with LaTeX::  
* Creating a LaTeX package::    
* Further reading about LaTeX::  
@end menu

@node Browsing documentation, Writing proper manuals, Maintaining Documentation, Maintaining Documentation
@section Browsing documentation

@node Writing proper manuals, Introduction to Texinfo, Browsing documentation, Maintaining Documentation
@section Writing proper manuals

@emph{FIXME: Advice on how to write a good manual}
@emph{General stuff. Reference manual vs user manual.}
@emph{When to write a manual.}
@emph{How to structure a manual.}
@emph{Texinfo vs. Latex}
@emph{Copyright issues.}

@node Introduction to Texinfo, Markup in Texinfo, Writing proper manuals, Maintaining Documentation
@section Introduction to Texinfo

@node Markup in Texinfo, GNU Emacs support for Texinfo, Introduction to Texinfo, Maintaining Documentation
@section Markup in Texinfo

@node GNU Emacs support for Texinfo, Writing man pages, Markup in Texinfo, Maintaining Documentation
@section GNU Emacs support for Texinfo

@node Writing man pages, Writing documentation with LaTeX, GNU Emacs support for Texinfo, Maintaining Documentation
@section Writing man pages

@node Writing documentation with LaTeX, Creating a LaTeX package, Writing man pages, Maintaining Documentation
@section Writing documentation with LaTeX

@node Creating a LaTeX package, Further reading about LaTeX, Writing documentation with LaTeX, Maintaining Documentation
@section Creating a LaTeX package

@node Further reading about LaTeX,  , Creating a LaTeX package, Maintaining Documentation
@section Further reading about LaTeX


@c ============================================================
@c ============================================================

@node Portable shell programming, Writing Autoconf macros, Maintaining Documentation, Top
@chapter Portable shell programming

@c ============================================================
@c ============================================================

@node Writing Autoconf macros, Legal issues with Free Software, Portable shell programming, Top
@chapter Writing Autoconf macros

@c ============================================================
@c ============================================================

@node Legal issues with Free Software, Philosophical issues, Writing Autoconf macros, Top
@appendix Legal issues with Free Software

If you want to give your programs to other people or use programs that were 
written by other people, then you need to worry about copyright.
The main reason why @file{autoconf} and @file{automake} were developed
was to make sharing software easier. So, if you want to use these
tools to develop free software, it is important to understand copyright.
In this chapter we will address the legal issues involved with releasing
software to the public. @xref{Philosophical issues}, for a discussion
of the philosophical issues involved. 

@menu
* Understanding Copyright::     
* Software patents::            
* Export restrictions on encryption software::  
@end menu

@node Understanding Copyright, Software patents, Legal issues with Free Software, Legal issues with Free Software
@section Understanding Copyright

When you create an original work, like a computer program, or a novel, and so 
on, the government automatically grants you a set of legal rights called 
@dfn{copyright}.
Copyright is the right to obstruct others from @emph{using}, @emph{modifying}
and @emph{redistributing} your work. Anyone that would like to use, modify
or redistribute your work needs to enter an agreement with you. By granting
you this monopoly, the government limits the freedom of the public to
express themselves in ways that involve infringing your copyright. The
government justifies copyright by claiming that it is a bargain that 
benefits the public because it encourages the creation of more works.
@footnote{The Free Software Foundation and many others however believe that
the current policies fall short of this justification and need to be
re-evaluated}
The holder of the copyright, called the @dfn{``owner''}, is the only person
that can enforce per copyright.

Copyright ownership can be transfered to another person or organization.
When a work is being developed by a team, it
makes legal sense to transfer the copyright to a single organization that
can then coordinate enforcement of the copyright. In the free software
community, some people assign their software to the Free Software Foundation.
The arrangement is that copyright is transfered to the FSF. The FSF then
grants you all the rights back in the form of a license agreement, and 
commits itself legally to distributing the work only as free software.
If you want to do this, you should contact the FSF for more information.
It is not a good idea to assign your copyright to anyone else, unless you
know what you are getting into. By assigning you rights to someone and
not getting any of those rights back in the form of an agreement, you may place
yourself in a position where you are not allowed to use your own work. 
Unfortunately, if you are employed or a student in a University you have
probably already signed many of your rights away. Universities as well as
companies like to lay as much claim on any copyrightable work you produce
as possible, even work that you do as a hobby that has little to do with
them.

Because copyright does not allow your users to do much with your software,
other than have a copy, you need to give them permissions that allow them
to freely use, modify and redistribute it.
In the free software community, we standardize on using
a legal document, the @dfn{GNU General Public License} to grant such 
permissions.
@xref{Applying the GPL}, for more details on how to use the GPL.

Copyright covers mainly original works. However, it also introduces the 
concept of @dfn{derived works}. In general, if someone copies a portion
of your work into per work, then it becomes @dfn{derived work} of your
work, and both you and person share copyright interest on per work.

If the only information that you give an impartial observer is a copy of
your work and a copy of per work, the observer has no deterministic
way of deciding whether or not per work is legally derived from your work.
The legal term @dfn{derived work} refers to the @emph{process} with
which person created per work, rather than an actual inherent property
of the end-result of the effort. 
Your copyright interest is established by 
the fact that part of that process involved @emph{copying} some of your
work into per work (and then perhaps modifying it, but that is not
relevant to whether or not you have copyright interest).

So, if you and someone write two very similar programs, because the
programs are simple, then you don't have copyright interest in each others
work, because you both worked indepedently. If, however, the reason for the 
similarity is that person copied your work, then you have copyright interest 
on per work. 
When that happens, person can only distribute the resulting program
(i.e. source code, or the executable) under terms that are consistent
with the terms with which person was allowed to have a copy of your work
and use it in per program. 

The law is less clear about what happens if person refers to your work
without actually doing any copying. A judge will have to decide this if it
goes to court. This is why when you work on a free software project, 
the only way to avoid liabilities like this is by not refering to anyone 
else's work, unless per work is also free software. This is one of the many 
ways that copyright obstructs cooperation between citizens. 

Fortunately there is a legal precedent with derived work and user interfaces.
The courts have decided that user interfaces, such as the 
@dfn{application programming interface} (API) that a software library is
exporting to the programs that link to it can not be copyrighted. So,
if you want to clone a library, while it is not a good idea to refer
to the actual source code of the library, it is okey to refer to a
description of the interface that the library defines. It is best to
do this by reading the documentation, but if no documentation is available,
reading the header files is the next best thing.

The concept of derived work is very slippery ground and has many gray
areas, especially when it pertains to linking libraries that other
people have written to your programs. 
@xref{The GPL and libraries}, for more discussion on this issue.

@c ============================================================

@node Software patents, Export restrictions on encryption software, Understanding Copyright, Legal issues with Free Software
@section Software patents

In addition to copyright law, there is another legal beast: the patent law.
Unlike copyright, which you own automatically by the act of creating the work,
you don't get a patent unless you file an application for it. If approved,
the work is published but others must pay you royalties in order to use it
in any way. 

The problem with patents is that they cover algorithms, and 
if an algorithm is patented you can neither write nor use an implementation 
for it, without a license. 
What makes it worse is that it is very difficult and expensive to
find out whether the algorithms that you use are patented or will be 
patented in the future. What makes it insane is that the patent office,
in its infinite stupidity, has patented algorithms that are very trivial
with nothing innovative about them. For example, the use of
@dfn{backing store} in a multiprocesing window system, like X11, is
covered by patent 4,555,775. In the spring of 1991, the owner of the
patent, AT&T, threatened to sue every member of the X Consortium including
MIT. Backing store is the idea that the windowing system save the contents of 
all windows at all times. This way, when a window is covered by another 
window and then exposed again, it is redrawn by the windowing system, and
not the code responsible for the application. Other insane patents include
the IBM patent 4,674,040 which covers ``cut and paste between files'' in
a text editor. Recently, a stupid corporation called ``Wang'' tried to take
Netscape to court over a patent that covered ``bookmarks'' and lost.

Even though this situation is ridiculous, software patents are
a very serious problem because they are taken very seriously by the
judicial system. Unfortunately they are not taken equally seriously
by the patent office (also called PTO) itself. The more patents the PTO 
approves, the more income the PTO makes. Therefore, the PTO is very eager
to let dubious patents through. After all, they figure that if the patent
is invalid, someone will knock it down in court eventually.

It is not necessary for someone to have a solid case
to get you into trouble. The cost of litigation is often sufficient extortion
to force small bussinesses, non-profit organizations and individual software
developers to settle, even when there is not solid case. The only defense
against a patent attac is to prove that there is ``prior art''; in other
words, you need to show that what is described in the patent had already
been invented before the date on which the application for that patent was
filed. Unfortunately, this is costly, not guaranteed to work, and
the burden of proof rests with the victim of the attack. Another 
defense is to make sure you don't have a lot of money. If you are poor,
lawyers are less likely to waste money suing you. 

Companies like to use software patents as strategic weapons for applying
extortion, which is unfortunately sanctioned by the law. They build
an arsenal of software patents by trying to pass whatever can get
through the Patent Office. Then years later, when they feel like it,
they can go through their patent arsenal and find someone to sue and
extort some cash. 

There have actually been patent attacks aimed directly against the free
sofwtare community. The GNU system does not include the Unix @samp{compress}
utility because it infringes a patent, and the patent owner has specifically
targetted the volunteer that wrote a @samp{compress} program for the
GNU project. 
There may be more patent attacks in the future.
On November of 1998 two 
internal memos were leaked from Microsoft about our community. According to 
these memos, Microsoft perceives the free software community as a competitor 
and they seem to consider a patent-based attack among other things.
It is important to note however that when an algorithm is patented,
and, worse, when that patent is asserted by the owner, this is an
attack on @emph{everyone} that writes software, not only to the free 
software community. This is why it is not important who is being targetted
in each specific incident. Patents hurt all of us. 

@c ============================================================

@node Export restrictions on encryption software,  , Software patents, Legal issues with Free Software
@section Export restrictions on encryption software

An additional legal burden to both copyrights and patents is governmental
boneheadedness over encryption algorithms. According to the US government,
a computer program implementing an encryption algorithm is considered
munition, therefore export-control laws on munitions apply. What is
not allowed under these laws is to export the software outside the
borders of the US. The government is pushing the issue by claiming that
making encryption software available on the internet is the same thing
as exporting it. Zimmermann, the author of a popular encryption program,
was sued by the government based on this interpretation of the law. 
However the government's position was not tested at court because the
government decided to drop the charges, after dragging the case for a few 
years, long enough to send a message of terror to the internet community.
The current wisdom seems to be
that it is okey to make encryption software available on the net provided
that you take strong measures that will prevent foreigners to download your
work. It should be noted however that doing so still @emph{is} taking
a legal risk that could land you to federal prison in the company of
international smugglers of TOW missiles and M1 Abrams tanks.

The reason why the government's attitude towards encryption is 
unconstitutional is because it violates our inalienable right to freedom
of speech. It is the current policy of the government that publishing
a book containing the source code for encryption software is legal, but 
publishing the exact same content in digital form is illegal. As the
internet increasingly becomes the library of the future, part of our
freedom will be lost. The reason why the government maintains such
a strange position today is because in the past they have tried to
assert that publishing encryption software @emph{both} digitally and on 
books is illegal. When the RSA algorithm was discovered, the National
Security Agency (also known as NSA -- No Such Agency)
attempted to prevent the inventors from publishing their discovery in
journals and presenting it at conferences. Judges understand books and 
conferences and the government had to give up fighting that battle. They
still haven't given up on the electronic front however.

Other countries also have restrictive laws against encryption. In certain
places, like France,  you are not be even allowed to run such programs. 
@footnote{The laws in France are now changing and they might be completely
different by the time you read this book}
The 
reason why governments are so paranoid of encryption is because it is the key
to a wide array of technologies that have the potential to empower the 
individual citizens to an extent that makes governments uncomfortable. 
Encryption is routinely used now by human rights activists operating on
totalitarian countries. Encryption can also be used to create an
unsanctioned para-economy based on digital cash, and allow individuals
to carry out transcations and contracts completely anonymously. 
These prospects are not good news for Big Brother.

The Free Software Foundation is fighting the US government export
restrictions very effectively by asking volunteers in a free country
to develop free encryption software. The GNU Privacy Guard is now very
stable, and is already being used by software developers. 
For more information, see @url{http://www.gnupg.org/}.

@c ============================================================
@c ============================================================

@node Philosophical issues, Licensing Free Software, Legal issues with Free Software, Top
@appendix Philosophical issues

The GNU development tools were written primarily to aid the development
and distribution of @dfn{free software} in the form of source code 
distributions. 
The philosophy of the GNU project, that software should be free, is
very important to the future of our community. Now that free software
systems, like GNU/Linux, have been noticed by the mainstream media,
our community will have to face many challenges to our freedom. 
We may have a free 
operating system today, but if we fail to deal with these challenges, 
we will not have one tomorrow. What are these challenges?
Three that we have already had to face are: secret hardware, non-free
libraries, and software patents. Who knows what else we might have to face 
tomorrow. Will we respond to these challenges and protect our freedom?
That depends on our philosophy.

In this appendix we include a few
articles written by Richard Stallman that discuss the philosophical concerns 
that lead to the free software movement. The text of these articles is
included here with permission from the following terms:

@strong{Copying Notice}
@display
Copyright @copyright{} 1998 Free Software Foundation Inc
59 Temple Place, Suite 330, Boston, MA 02111, USA
Verbatim copying and distribution is permitted in any medium,
provided this notice is preserved.
@end display

All of these articles, and others are distributed on the web at:@*
@uref{http://www.gnu.org/philosophy/index.html}

@menu
* The Right to Read::           
* What is Free Software::       
* Why software should not have owners::  
* Why free software needs free documentation::  
* Categories of software::      
* Confusing words::             
@end menu

@node The Right to Read, What is Free Software, Philosophical issues, Philosophical issues
@section The Right to Read

@emph{This article appeared in the February 1997 issue of Communications of the ACM (Volume 40, Number 2).}

@quotation
  (from "The Road To Tycho", a collection of articles about the
     antecedents of the Lunarian Revolution, published in Luna City in
     2096)
@end quotation

For Dan Halbert, the road to Tycho began in college when Lissa Lenz
asked to borrow his computer. Hers had broken down, and unless she
could borrow another, she would fail her midterm project. There was no
one she dared ask, except Dan.

This put Dan in a dilemma. He had to help her, but if he lent her his
computer, she might read his books. Aside from the fact that you could
go to prison for many years for letting someone else read your books,
the very idea shocked him at first. Like everyone, he had been taught
since elementary school that sharing books was nasty and
wrong, something that only pirates would do.
     
And there wasn't much chance that the SPA, the Software Protection
Authority, would fail to catch him. In his software class, Dan had
learned that each book had a copyright monitor that reported when and
where it was read, and by whom, to Central Licensing. (They used this
information to catch reading pirates, but also to sell personal
interest profiles to retailers.) The next time his computer was
networked, Central Licensing would find out. He, as computer owner,
would receive the harshest punishment, for not taking pains to prevent
the crime.
     
Of course, Lissa did not necessarily intend to read his books. She
might want the computer only to write her midterm. But Dan knew she
came from a middle-class family and could hardly afford the tuition,
let alone her reading fees. Reading his books might be the only way
she could graduate. He understood this situation; he himself had had
to borrow to pay for all the research papers he read. (10% of those
fees went to the researchers who wrote the papers; since Dan aimed for
an academic career, he could hope that his own research papers, if
frequently referenced, would bring in enough to repay this loan.)

Later on, Dan would learn there was a time when anyone could go to the
library and read journal articles, and even books, without having to
pay. There were independent scholars who read thousands of pages
without government library grants. But in the 1990s, both commercial
and nonprofit journal publishers had begun charging fees for access.
By 2047, libraries offering free public access to scholarly literature
were a dim memory.

There were ways, of course, to get around the SPA and Central
Licensing. They were themselves illegal. Dan had had a classmate in
software, Frank Martucci, who had obtained an illicit debugging tool,
and used it to skip over the copyright monitor code when reading
books. But he had told too many friends about it, and one of them
turned him in to the SPA for a reward (students deep in debt were
easily tempted into betrayal). In 2047, Frank was in prison, not for
pirate reading, but for possessing a debugger.

Dan would later learn that there was a time when anyone could have
debugging tools. There were even free debugging tools available on CD
or downloadable over the net. But ordinary users started using them to
bypass copyright monitors, and eventually a judge ruled that this had
become their principal use in actual practice. This meant they were
illegal; the debuggers' developers were sent to prison.

Programmers still needed debugging tools, of course, but debugger
vendors in 2047 distributed numbered copies only, and only to
officially licensed and bonded programmers. The debugger Dan used in
software class was kept behind a special firewall so that it could be
used only for class exercises.

It was also possible to bypass the copyright monitors by installing a
modified system kernel. Dan would eventually find out about the free
kernels, even entire free operating systems, that had existed around
the turn of the century. But not only were they illegal, like
debuggers; you could not install one if you had one, without knowing
your computer's root password. And neither the FBI nor Microsoft
Support would tell you that.
     
Dan concluded that he couldn't simply lend Lissa his computer. But he
couldn't refuse to help her, because he loved her. Every chance to
speak with her filled him with delight. And that she chose him to ask
for help, that could mean she loved him too.
   
Dan resolved the dilemma by doing something even more unthinkable--he
lent her the computer, and told her his password. This way, if Lissa
read his books, Central Licensing would think he was reading them. It
was still a crime, but the SPA would not automatically find out about
it. They would only find out if Lissa reported him.

Of course, if the school ever found out that he had given Lissa his
own password, it would be curtains for both of them as students,
regardless of what she had used it for. School policy was that any
interference with their means of monitoring students' computer use was
grounds for disciplinary action. It didn't matter whether you did
anything harmful. The offense was making it hard for the
administrators to check on you. They assumed this meant you were doing
something else forbidden, and they did not need to know what it was.

Students were not usually expelled for this, not directly. Instead
they were banned from the school computer systems, and would
inevitably fail all their classes.

Later, Dan would learn that this kind of university policy started
only in the 1980s, when university students in large numbers began
using computers. Previously, universities maintained a different
approach to student discipline; they punished activities that were
harmful, not those that merely raised suspicion.

Lissa did not report Dan to the SPA. His decision to help her led to
their marriage, and also led them to question what they had been
taught about piracy as children. The couple began reading about the
history of copyright, about the Soviet Union and its restrictions on
copying, and even the original United States Constitution. They moved
to Luna, where they found others who had likewise gravitated away from
the long arm of the SPA. When the Tycho Uprising began in 2062, the
universal right to read soon became one of its central aims.

@sp 1
@noindent
@strong{Author's Note}

The right to read is a battle being fought today. Although it may take
50 years for our present way of life to fade into obscurity, most of
the specific laws and practices described above have already been
proposed, either by the Clinton Administration or by publishers.

There is one exception: the idea that the FBI and Microsoft will keep
the root passwords for personal computers. This is an extrapolation
from the Clipper chip and similar Clinton Administration key-escrow
proposals, together with a long-term trend: computer systems are
increasingly set up to give absentee operators control over the people
actually using the computer system.
   
The SPA, which actually stands for Software Publisher's Association,
is not today an official police force. Unofficially, it acts like one.
It invites people to inform on their coworkers and friends. Like the
Clinton Administration, it advocates a policy of collective
responsibility whereby computer owners must actively enforce copyright
or be punished.

The SPA is currently threatening small Internet service providers,
demanding they permit the SPA to monitor all users. Most ISPs
surrender when threatened, because they cannot afford to fight back in
court. (Atlanta Journal-Constitution, 1 Oct 96, D3.) At least one ISP,
Community ConneXion in Oakland CA, refused the demand and was actually
sued. The SPA is said to have dropped this suit recently, but they are
sure to continue the campaign in various other ways.

The university security policies described above are not imaginary.
For example, a computer at one Chicago-area university prints this
message when you log in (quotation marks are in the original):

@quotation
``This system is for the use of authorized users only. Individuals
using this computer system without authority or in the excess of
their authority are subject to having all their activities on this
system monitored and recorded by system personnel. In the course of
monitoring individuals improperly using this system or in the
course of system maintenance, the activities of authorized user may
also be monitored. Anyone using this system expressly consents to
such monitoring and is advised that if such monitoring reveals
possible evidence of illegal activity or violation of University
regulations system personnel may provide the evidence of such
monitoring to University authorities and/or law enforcement
officials.''
@end quotation

This is an interesting approach to the Fourth Amendment: pressure most
everyone to agree, in advance, to waive their rights under it.

@sp 1
@noindent
@strong{References}

@itemize @bullet
@item
The administration's ``White Paper'': Information Infrastructure Task Force,
Intellectual Property and the National Information Infrastructure: The 
Report of the Working Group on Intellectual Property Rights (1995).
@item
@cite{An explanation of the White Paper: The Copyright Grab}, Pamela Samuelson, Wired,
Jan. 1996
@item
@cite{Sold Out}, James Boyle, New York Times, 31 March 1996
@item
@cite{Public Data or Private Data}, Washington Post, 4 Nov 1996
@item
@uref{http://www.public-domain.org/, Union for the Public Domain},
a new organization which aims to resist and reverse the overextension of
intellectual property powers.
@end itemize

@c ============================================================

@node What is Free Software, Why software should not have owners, The Right to Read, Philosophical issues
@section What is Free Software

@dfn{Free software} is a matter of liberty, not price. To understand the
concept, you should think of @emph{free speech}, not @emph{free beer}.
   
@dfn{Free software} refers to the users' freedom to run, copy,
distribute, study, change and improve the software. More precisely, it
refers to three levels of freedom:

@enumerate
@item
The freedom to study how the program works and adapt it to your
needs.
@item
The freedom to redistribute copies so you can share with your
neighbor.
@item
The freedom to improve the program, and release your improvements
to the public, so that the whole community benefits.
@end enumerate

You may have paid money to get copies of GNU software, or you may have
obtained copies at no charge. But regardless of how you got your
copies, you always have the freedom to copy and change the software.
In the GNU project, we use @dfn{copyleft} to protect these freedoms
legally for everyone.

@xref{Categories of software}, for a description of
how ``free software,'' ``copylefted software'' and other categories of
software relate to each other.
   
When talking about free software, it is best to avoid using terms like
``give away'' or ``for free'', because those terms imply that the
issue is about price, not freedom. Some common terms such as
``piracy'' embody opinions we hope you won't endorse. 
@xref{Confusing words}, for a discussion of these terms.

@c ============================================================

@node Why software should not have owners, Why free software needs free documentation, What is Free Software, Philosophical issues
@section Why software should not have owners

Digital information technology contributes to the world by
making it easier to copy and modify information. Computers
promise to make this easier for all of us. 

Not everyone wants it to be easier. The system of copyright
gives software programs ``owners'', most of whom aim to
withhold software's potential benefit from the rest of the public.
They would like to be the only ones who can copy and modify the
software that we use. 

The copyright system grew up with printing---a technology for
mass production copying. Copyright fit in well with this
technology because it restricted only the mass producers of
copies. It did not take freedom away from readers of books. An
ordinary reader, who did not own a printing press, could copy
books only with pen and ink, and few readers were sued for that.

Digital technology is more flexible than the printing press: when
information has digital form, you can easily copy it to share it
with others. This very flexibility makes a bad fit with a system
like copyright. That's the reason for the increasingly nasty and
draconian measures now used to enforce software copyright.
Consider these four practices of the Software Publishers
Association (SPA): 

@itemize @bullet
@item
Massive propaganda saying it is wrong to disobey the
owners to help your friend. 
@item
Solicitation for stool pigeons to inform on their
coworkers and colleagues. 
@item
Raids (with police help) on offices and schools, in which
people are told they must prove they are innocent of
illegal copying. 
@item
Prosecution (by the US government, at the SPA's
request) of people such as MIT's David LaMacchia, not
for copying software (he is not accused of copying any),
but merely for leaving copying facilities unguarded and
failing to censor their use. 
@end itemize

All four practices resemble those used in the former Soviet
Union, where every copying machine had a guard to prevent
forbidden copying, and where individuals had to copy information
secretly and pass it from hand to hand as ``samizdat''. There is
of course a difference: the motive for information control in the
Soviet Union was political; in the US the motive is profit. But it
is the actions that affect us, not the motive. Any attempt to
block the sharing of information, no matter why, leads to the
same methods and the same harshness. 

Owners make several kinds of arguments for giving them the
power to control how we use information: 
@itemize @bullet
@item
@strong{Name calling}:
Owners use smear words such as ``piracy'' and
``theft'', as well as expert terminology such as
``intellectual property'' and ``damage'', to suggest a
certain line of thinking to the public---a simplistic
analogy between programs and physical objects. 

Our ideas and intuitions about property for material
objects are about whether it is right to @emph{take an object away}
from someone else. They don't directly apply to
@emph{making a copy} of something. But the owners ask us to
apply them anyway. 
@item
@strong{Exaggeration}:
Owners say that they suffer ``harm'' or ``economic
loss'' when users copy programs themselves. But the
copying has no direct effect on the owner, and it harms
no one. The owner can lose only if the person who made
the copy would otherwise have paid for one from the
owner. 

A little thought shows that most such people would not
have bought copies. Yet the owners compute their
``losses'' as if each and every one would have bought a
copy. That is exaggeration---to put it kindly. 
@item
@strong{The law}:
Owners often describe the current state of the law, and
the harsh penalties they can threaten us with. Implicit in
this approach is the suggestion that today's law reflects
an unquestionable view of morality---yet at the same
time, we are urged to regard these penalties as facts of
nature that can't be blamed on anyone. 

This line of persuasion isn't designed to stand up to
critical thinking; it's intended to reinforce a habitual
mental pathway. 

It's elementary that laws don't decide right and wrong.
Every American should know that, forty years ago, it
was against the law in many states for a black person to
sit in the front of a bus; but only racists would say
sitting there was wrong. 
@item
@strong{Natural rights}:
Authors often claim a special connection with programs
they have written, and go on to assert that, as a result,
their desires and interests concerning the program
simply outweigh those of anyone else---or even those
of the whole rest of the world. (Typically companies, not
authors, hold the copyrights on software, but we are
expected to ignore this discrepancy.) 

To those who propose this as an ethical axiom---the
author is more important than you---I can only say that
I, a notable software author myself, call it bunk. 

But people in general are only likely to feel any
sympathy with the natural rights claims for two reasons.

One reason is an overstretched analogy with material
objects. When I cook spaghetti, I do object if someone
else eats it, because then I cannot eat it. His action
hurts me exactly as much as it benefits him; only one of
us can eat the spaghetti, so the question is, which? The
smallest distinction between us is enough to tip the
ethical balance. 

But whether you run or change a program I wrote affects
you directly and me only indirectly. Whether you give a
copy to your friend affects you and your friend much
more than it affects me. I shouldn't have the power to
tell you not to do these things. No one should. 

The second reason is that people have been told that
natural rights for authors is the accepted and
unquestioned tradition of our society. 

As a matter of history, the opposite is true. The idea of
natural rights of authors was proposed and decisively
rejected when the US Constitution was drawn up. That's
why the Constitution only permits a system of copyright
and does not require one; that's why it says that
copyright must be temporary. It also states that the
purpose of copyright is to promote progress---not to
reward authors. Copyright does reward authors
somewhat, and publishers more, but that is intended as a
means of modifying their behavior. 

The real established tradition of our society is that
copyright cuts into the natural rights of the
public---and that this can only be justified for the
public's sake. 
@item
@strong{Economics}
The final argument made for having owners of software
is that this leads to production of more software. 

Unlike the others, this argument at least takes a
legitimate approach to the subject. It is based on a valid
goal---satisfying the users of software. And it is
empirically clear that people will produce more of
something if they are well paid for doing so. 

But the economic argument has a flaw: it is based on the
assumption that the difference is only a matter of how
much money we have to pay. It assumes that
``production of software'' is what we want, whether the
software has owners or not. 

People readily accept this assumption because it
accords with our experiences with material objects.
Consider a sandwich, for instance. You might well be
able to get an equivalent sandwich either free or for a
price. If so, the amount you pay is the only difference.
Whether or not you have to buy it, the sandwich has the
same taste, the same nutritional value, and in either
case you can only eat it once. Whether you get the
sandwich from an owner or not cannot directly affect
anything but the amount of money you have afterwards. 

This is true for any kind of material object---whether or
not it has an owner does not directly affect what it is, or
what you can do with it if you acquire it. 

But if a program has an owner, this very much affects
what it is, and what you can do with a copy if you buy
one. The difference is not just a matter of money. The
system of owners of software encourages software
owners to produce something---but not what society
really needs. And it causes intangible ethical pollution
that affects us all. 

What does society need? It needs information that is
truly available to its citizens---for example, programs
that people can read, fix, adapt, and improve, not just
operate. But what software owners typically deliver is a
black box that we can't study or change. 

Society also needs freedom. When a program has an
owner, the users lose freedom to control part of their
own lives. 

And above all society needs to encourage the spirit of
voluntary cooperation in its citizens. When software
owners tell us that helping our neighbors in a natural
way is ``piracy'', they pollute our society's civic spirit. 

This is why we say that free software is a matter of
freedom, not price. 

The economic argument for owners is erroneous, but the
economic issue is real. Some people write useful
software for the pleasure of writing it or for admiration
and love; but if we want more software than those
people write, we need to raise funds. 

For ten years now, free software developers have tried
various methods of finding funds, with some success.
There's no need to make anyone rich; the median US
family income, around $35k, proves to be enough
incentive for many jobs that are less satisfying than
programming. 

For years, until a fellowship made it unnecessary, I
made a living from custom enhancements of the free
software I had written. Each enhancement was added to
the standard released version and thus eventually
became available to the general public. Clients paid me
so that I would work on the enhancements they wanted,
rather than on the features I would otherwise have
considered highest priority. 

The Free Software Foundation (FSF), a tax-exempt
charity for free software development, raises funds by
selling GNU CD-ROMs, T-shirts, manuals, and deluxe
distributions, (all of which users are free to copy and
change), as well as from donations. It now has a staff of
five programmers, plus three employees who handle mail
orders. 

Some free software developers make money by selling
support services. Cygnus Support, with around 50
employees [when this article was written], estimates
that about 15 per cent of its staff activity is free
software development---a respectable percentage for a
software company. 

Companies including Intel, Motorola, Texas Instruments
and Analog Devices have combined to fund the
continued development of the free GNU compiler for the
language C. Meanwhile, the GNU compiler for the Ada
language is being funded by the US Air Force, which
believes this is the most cost-effective way to get a
high quality compiler. [Air Force funding ended some
time ago; the GNU Ada Compiler is now in service, and
its maintenance is funded commercially.] 

All these examples are small; the free software
movement is still small, and still young. But the example
of listener-supported radio in this country [the US]
shows it's possible to support a large activity without
forcing each user to pay. 
@end itemize

As a computer user today, you may find yourself using a
proprietary program. If your friend asks to
make a copy, it would be wrong to refuse. Cooperation is more
important than copyright. But underground, closet cooperation
does not make for a good society. A person should aspire to live
an upright life openly with pride, and this means saying ``No'' to
proprietary software. 

You deserve to be able to cooperate openly and freely with other
people who use software. You deserve to be able to learn how
the software works, and to teach your students with it. You
deserve to be able to hire your favorite programmer to fix it when
it breaks. 

You deserve free software. 

@c ============================================================

@node Why free software needs free documentation, Categories of software, Why software should not have owners, Philosophical issues
@section Why free software needs free documentation

The biggest deficiency in free operating systems is not in the
software--it is the lack of good free manuals that we can include in
these systems. Many of our most important programs do not come with
full manuals. Documentation is an essential part of any software
package; when an important free software package does not come with a
free manual, that is a major gap. We have many such gaps today. 

Once upon a time, many years ago, I thought I would learn Perl. I got a
copy of a free manual, but I found it hard to read. When I asked Perl
users about alternatives, they told me that there were better introductory
manuals--but those were not free. 

Why was this? The authors of the good manuals had written them for
O'Reilly Associates, which published them with restrictive terms--no
copying, no modification, source files not available--which exclude
them from the free software community. 

That wasn't the first time this sort of thing has happened, and (to our
community's great loss) it was far from the last. Proprietary manual
publishers have enticed a great many authors to restrict their manuals
since then. Many times I have heard a GNU user eagerly tell me about a
manual that he is writing, with which he expects to help the GNU
project--and then had my hopes dashed, as he proceeded to explain that
he had signed a contract with a publisher that would restrict it so that
we cannot use it. 

Given that writing good English is a rare skill among programmers, we
can ill afford to lose manuals this way. 

Free documentation, like free software, is a matter of freedom, not price.
The problem with these manuals was not that O'Reilly Associates
charged a price for printed copies--that in itself is fine. (The Free
Software Foundation sells printed copies of free GNU manuals, too.)
But GNU manuals are available in source code form, while these
manuals are available only on paper. GNU manuals come with
permission to copy and modify; the Perl manuals do not. These
restrictions are the problems. 

The criterion for a free manual is pretty much the same as for free
software: it is a matter of giving all users certain freedoms.
Redistribution (including commercial redistribution) must be permitted,
so that the manual can accompany every copy of the program, on-line or
on paper. Permission for modification is crucial too. 

As a general rule, I don't believe that it is essential for people to have
permission to modify all sorts of articles and books. The issues for
writings are not necessarily the same as those for software. For
example, I don't think you or I are obliged to give permission to modify
articles like this one, which describe our actions and our views. 

But there is a particular reason why the freedom to modify is crucial for
documentation for free software. When people exercise their right to
modify the software, and add or change its features, if they are
conscientious they will change the manual too--so they can provide
accurate and usable documentation with the modified program. A manual
which forbids programmers to be conscientious and finish the job, or
more precisely requires them to write a new manual from scratch if they
change the program, does not fill our community's needs. 

While a blanket prohibition on modification is unacceptable, some kinds
of limits on the method of modification pose no problem. For example,
requirements to preserve the original author's copyright notice, the
distribution terms, or the list of authors, are ok. It is also no problem to
require modified versions to include notice that they were modified, even
to have entire sections that may not be deleted or changed, as long as
these sections deal with nontechnical topics. (Some GNU manuals have
them.) 

These kinds of restrictions are not a problem because, as a practical
matter, they don't stop the conscientious programmer from adapting the
manual to fit the modified program. In other words, they don't block the
free software community from doing its thing with the program and the
manual together. 

However, it must be possible to modify all the technical content of the
manual; otherwise, the restrictions do block the community, the manual
is not free, and so we need another manual. 

Unfortunately, it is often hard to find someone to write another manual
when a proprietary manual exists. The obstacle is that many users think
that a proprietary manual is good enough--so they don't see the need to
write a free manual. They do not see that the free operating system has
a gap that needs filling. 

Why do users think that proprietary manuals are good enough? Some
have not considered the issue. I hope this article will do something to
change that. 

Other users consider proprietary manuals acceptable for the same
reason so many people consider proprietary software acceptable: they
judge in purely practical terms, not using freedom as a criterion. These
people are entitled to their opinions, but since those opinions spring from
values which do not include freedom, they are no guide for those of us
who do value freedom. 

Please spread the word about this issue. We continue to lose manuals to
proprietary publishing. If we spread the word that proprietary manuals
are not sufficient, perhaps the next person who wants to help GNU by
writing documentation will realize, before it is too late, that he must
above all make it free. 

We can also encourage commercial publishers to sell free, copylefted
manuals instead of proprietary ones. One way you can help this is to
check the distribution terms of a manual before you buy it, and prefer
copylefted manuals to non-copylefted ones. 

@c ============================================================

@node Categories of software, Confusing words, Why free software needs free documentation, Philosophical issues
@section Categories of software

Here is a glossary of various categories of software that are often
mentioned in discussions of free software. It explains which categories
overlap or are part of other categories. 

@itemize @bullet
@item
@strong{Free software}:
Free software is software that comes with permission for
anyone to use, copy, and distribute, either verbatim or with
modifications, either gratis or for a fee. In particular, this means
that source code must be available. ``If it's not source, it's not
software.'' 

If a program is free, then it can potentially be included in a free
operating system such as GNU, or free GNU/Linux systems . 

There are many different ways to make a program free---many
questions of detail, which could be decided in more than one way
and still make the program free. Some of the possible variations
are described below. 

Free software is a matter of freedom, not price. But proprietary
software companies sometimes use the term ``free software'' to
refer to price. Sometimes they mean that you can obtain a binary
copy at no charge; sometimes they mean that a copy is included
on a computer that you are buying. This has nothing to do with
what we mean by free software in the GNU project. 

Because of this potential confusion, when a software company
says its product is free software, always check the actual
distribution terms to see whether users really have all the
freedoms that free software implies. Sometimes it really is free
software; sometimes it isn't. 

Many languages have two separate words for ``free'' as in
freedom and ``free'' as in zero price. For example, French has
``libre'' and ``gratuit''. English has a word ``gratis'' that refers
unambiguously to price, but no common adjective that refers
unambiguously to freedom. This is unfortunate, because such a
word would be useful here. 

Free software is often more reliable than non-free software. 
@item
@strong{Open Source software}:
The term ``open source'' software is used by some people to
mean more or less the same thing as free software. 
@item
@strong{Public domain software}:
Public domain software is software that is not copyrighted. It is
a special case of non-copylefted free software, which means
that some copies or modified versions may not be free at all. 

Sometimes people use the term ``public domain'' in a loose
fashion to mean ``free'' or ``available gratis.'' However, ``public
domain'' is a legal term and means, precisely, ``not
copyrighted''. For clarity, we recommend using ``public domain''
for that meaning only, and using other terms to convey the other
meanings. 
@item
@strong{Copylefted software}:
Copylefted software is free software whose distribution terms
do not let redistributors add any additional restrictions when
they redistribute or modify the software. This means that every
copy of the software, even if it has been modified, must be free
software. 

In the GNU Project, we copyleft almost all the software we
write, because our goal is to give every user the freedoms
implied by the term ``free software.'' See Copylefted for more
explanation of how copyleft works and why we use it. 

Copyleft is a general concept; to actually copyleft a program, you
need to use a specific set of distribution terms. There are many
possible ways to write copyleft distribution terms. 
@item
@strong{Non-copylefted free software}:
Non-copylefted free software comes from the author with
permission to redistribute and modify, and also to add additional
restrictions to it. 

If a program is free but not copylefted, then some copies or
modified versions may not be free at all. A software company
can compile the program, with or without modifications, and
distribute the executable file as a proprietary software product. 

The X Window System illustrates this. The X Consortium
releases X11 with distribution terms that make it
non-copylefted free software. If you wish, you can get a copy
which has those distribution terms and is free. However, there
are non-free versions as well, and there are popular
workstations and PC graphics boards for which non-free
versions are the only ones that work. If you are using this
hardware, X11 is not free software for you. 
@item
@strong{GPL-covered software}:
The GNU GPL is one
specific set of distribution terms for copylefting a program. The
GNU Project uses it as the distribution terms for most GNU
software. 
@item
@strong{The GNU system}:
The GNU system is a complete free Unix-like operating system.

A Unix-like operating system consists of many programs. We
have been accumulating components for this system since 1984;
the first test release of a ``complete GNU system'' was in 1996.
We hope that in a year or so this system will be mature enough
to recommend it for ordinary users. 

The GNU system includes all the GNU software, as well as
many other packages such as the X Window System and TeX
which are not GNU software. 

Since the purpose of GNU is to be free, every single component
in the GNU system has to be free software. They don't all have
to be copylefted, however; any kind of free software is legally
suitable to include if it helps meet technical goals. We can and
do use non-copylefted free software such as the X Window
System. 
@item
@strong{GNU software}:
GNU software is software that is released under the auspices of
the GNU Project. Most GNU software is copylefted, but not all;
however, all GNU software must be free software. 

Some GNU software is written by staff of the Free Software
Foundation, but most GNU software is contributed by
volunteers. Some contributed software is copyrighted by the
Free Software Foundation; some is copyrighted by the
contributors who wrote it. 
@item
@strong{Semi-free software}:
Semi-free software is software that is not free, but comes with
permission for individuals to use, copy, distribute, and modify
(including distribution of modified versions) for non-profit
purposes. PGP is an example of a semi-free program. 

Semi-free software is much better than proprietary software,
but it still poses problems, and we cannot use it in a free
operating system. 

The restrictions of copyleft are designed to protect the essential
freedoms for all users. For us, the only justification for any
substantive restriction on using a program is to prevent other
people from adding other restrictions. Semi-free programs have
additional restrictions, motivated by purely selfish goals. 

It is impossible to include semi-free software in a free operating
system. This is because the distribution terms for the operating
system as a whole are the conjunction of the distribution terms
for all the programs in it. Adding one semi-free program to the
system would make the system as a whole just semi-free. There
are two reasons we do not want that to happen: 
@itemize @bullet
@item
We believe that free software should be for
everyone--including businesses, not just schools and
hobbyists. We want to invite business to use the whole
GNU system, and therefore we must not include a
semi-free program in it. 
@item
Commercial distribution of free operating systems,
including Linux-based GNU systems, is very important,
and users appreciate being able to buy commercial
CD-ROM distributions. Including one semi-free
program in an operating system would cut off
commercial CD-ROM distribution for it. 
@end itemize
The Free Software Foundation itself is non-commercial, and
therefore we would be legally permitted to use a semi-free
program ``internally''. But we don't do that, because that would
undermine our efforts to obtain a program which we could also
include in GNU. 

If there is a job that needs doing with software, then until we
have a free program to do the job, the GNU system has a gap.
We have to tell volunteers, ``We don't have a program yet to do
this job in GNU, so we hope you will write one.'' If we ourselves
used a semi-free program to do the job, that would undermine
what we say; it would take away the impetus (on us, and on
others who might listen to our views) to write a free
replacement. So we don't do that. 
@item
@strong{Proprietary software}:
Proprietary software is software that is not free or semi-free.
Its use, redistribution or modification is prohibited, or requires
you to ask for permission, or is restricted so much that you
effectively can't do it freely. 

The Free Software Foundation follows the rule that we cannot
install any proprietary program on our computers except
temporarily for the specific purpose of writing a free replacement
for that very program. Aside from that, we feel there is no
possible excuse for installing a proprietary program. 

For example, we felt justified in installing Unix on our computer
in the 1980s, because we were using it to write a free
replacement for Unix. Nowadays, since free operating systems
are available, the excuse is no longer applicable; we have
eliminated all our non-free operating systems, and any new
computer we install must run a completely free operating
system. 

We don't insist that users of GNU, or contributors to GNU,
have to live by this rule. It is a rule we made for ourselves. But
we hope you will decide to follow it too. 
@item
@strong{Freeware}:
The term ``freeware'' has no clear accepted definition, but it is
commonly used for packages which permit redistribution but not
modification (and their source code is not available). These
packages are not free software, so please don't use ``freeware''
to refer to free software. 
@item
@strong{Shareware}:
Shareware is software which comes with permission for people
to redistribute copies, but says that anyone who continues to
use a copy is required to pay a license fee. 

Shareware is not free software, or even semi-free. There are
two reasons it is not: 
@itemize @bullet
@item
For most shareware, source code is not available; thus you cannot modiy the
program at all.
@item
Shareware does not come with permission to make a
copy and install it without paying a license fee, not even
for individuals engaging in nonprofit activity. (In
practice, people often disregard the distribution terms
and do this anyway, but the terms don't permit it.) 
@end itemize

@item
@strong{Commercial Software}:
Commercial software is software being developed by a business
which aims to make money from the use of the software.
``Commercial'' and ``proprietary'' are not the same thing! Most
commercial software is proprietary , but there is commercial free
software, and there is non-commercial non-free software. 

For example, GNU Ada is always distributed under the terms of
the GNU GPL, and every copy is free software; but its
developers sell support contracts. When their salesmen speak to
prospective customers, sometimes the customers say, ``We
would feel safer with a commercial compiler.'' The salesmen
reply, ``GNU Ada is a commercial compiler; it happens to be free
software.'' 

For the GNU Project, the emphasis is in the other order: the
important thing is that GNU Ada is free software; whether it is
commercial is not a crucial question. However, the additional
development of GNU Ada that results from the business that
supports it is definitely beneficial. 
@end itemize

@c ============================================================

@node Confusing words,  , Categories of software, Philosophical issues
@section Confusing words

There are a number of words and phrases which we recommend
avoiding, either because they are ambiguous or because they imply an
opinion that we hope you may not entirely agree with. 

@itemize @bullet
@item
@strong{For free}:
If you want to say that a program is free software, please don't say that
it is available ``for free.'' That term specifically means ``for zero price.''
Free software is a matter of freedom, not price. 

Free software is often available for free--for example, on many FTP
servers. But free software copies are also available for a price on
CD-ROMs, and proprietary software copies may occasionally be
available for free. 

To avoid confusion, you can say that the program is available
``as free software''.
@item
@strong{Freeware}:
Please don't use the term ``freeware'' as a synonym for ``free
software.'' The term ``freeware'' was used often in the 1980s for
programs released only as executables, with source code not available.
Today it has no clear definition. 
@item
@strong{Give away software}:
It's misleading to use the term ``give away'' to mean ``distribute a
program as free software.'' It has the same problem as ``for free'': it
implies the issue is price, not freedom. One way to avoid the confusion
is to say ``release as free software''.
@item
@strong{Intellectual property}:
Publishers and lawyers like to describe copyright as ``intellectual
property.'' This term carries a hidden assumption---that the most
natural way to think about the issue of copying is based on an analogy
with physical objects, and our ideas of them as property. 

But this analogy overlooks the crucial difference between material
objects and information: information can be copied and shared almost
effortlessly, while material objects can't be. Basing your thinking on this
analogy is tantamount to ignoring that difference. 

Even the US legal system does not entirely accept this analogy, since it
does not treat copyrights just like physical object property rights. 

If you don't want to limit yourself to this way of thinking, it is best to
avoid using the term ``intellectual property'' in your words and thoughts. 

Another problem with ``intellectual property'' is that it is an attempt
to generalize about several legal systems, including copyright, patents,
and trademarks, which are much more different than similar. Unless you have
studied these areas of law and you know the differences, lumping them
together will surely lead you to incorrect generalizations.

To avoid confusion, it is best not to look for alternative way
of saying ``intellectual property.'' Instead, talk about copyright, patents,
or whichever specific legal system is the issue.
@item
@strong{Piracy}:
Publishers often refer to prohibited copying as ``piracy.'' In this way,
they imply that illegal copying is ethically equivalent to attacking ships
on the high seas, kidnaping and murdering the people on them. 

If you don't believe that illegal copying is just like kidnaping and murder,
you might prefer not to use the word ``piracy'' to describe it. Neutral
terms such as ``prohibited copying'' or ``illegal copying'' are available
for use instead. Some of us might even prefer to use a positive term such
as ``sharing information with your neighbor.'' 
@item
@strong{Protection}:
Publishers' lawyers love to use the term ``protection'' to describe
copyright. This word carries the implication of preventing destruction or
suffering; therefore, it encourages people to identify with the owner and
publisher who benefit from copyright, rather than with the users who are
restricted by it. 

It is easy to avoid ``protection'' and use neutral terms instead. For
example, instead of ``Copyright protection lasts a very long time,'' you
can say, ``Copyright lasts a very long time.''
@item
@strong{Sell software}:
The term ``sell software'' is ambiguous. Strictly speaking, exchanging a
copy of a free program for a sum of money is ``selling''; but people
usually associate the term ``sell'' with proprietary restrictions on the
subsequent use of the software. You can be more precise, and prevent
confusion, by saying either ``distributing copies of a program for a fee''
or ``imposing proprietary restrictions on the use of a program,''
depending on what you mean. 
@item
@strong{Theft}:
Copyright apologists often use words like ``stolen'' and ``theft'' to
describe copyright infringement. At the same time, they ask us to treat
the legal system as an authority on ethics: if copying is forbidden, it
must be wrong. 

So it is pertinent to mention that the legal system--at least in the
US--rejects the idea that copyright infringement is ``theft''. Copyright
advocates who use terms like ``stolen'' are misrepresenting the
authority that they appeal to. 

The idea that laws decide what is right or wrong is mistaken in general.
Laws are, at their best, an attempt to achieve justice; to say that laws
define justice or ethical conduct is turning things upside down. 
@end itemize

@c ============================================================
@c ============================================================

@node Licensing Free Software, GNU GENERAL PUBLIC LICENSE, Philosophical issues, Top
@appendix Licensing Free Software

The following articles by Richard Stallman describe how we license
free software in our community. The text of these articles in included
here with permission under the following terms:

@strong{Copying Notice}
@display
Copyright @copyright{} 1998 Free Software Foundation Inc
59 Temple Place, Suite 330, Boston, MA 02111, USA
Verbatim copying and distribution is permitted in any medium,
provided this notice is preserved.
@end display

An exception is the article in @ref{Why you should use the GPL}.
This article was written by Eleftherios Gkioulekas to make this appendix
more self contained and you may copy it under the following terms:

@strong{Copying Notice}
@display
Copyright @copyright{} 1998 Eleftherios Gkioulekas
Verbatim copying and distribution is permitted in any medium,
provided this notice is preserved.
@end display

@menu
* What is Copyleft::            
* Why you should use the GPL::  
* The LGPL vs the GPL::         
@end menu

@node What is Copyleft, Why you should use the GPL, Licensing Free Software, Licensing Free Software
@section What is Copyleft

The simplest way to make a program free is to put it in the public
domain, uncopyrighted. This allows people to share
the program and their improvements, if they are so minded. But it also
allows uncooperative people to convert the program into proprietary
software. They can make changes, many or few, and
distribute the result as a proprietary product. People who receive the
program in that modified form do not have the freedom that the
original author gave them; the middleman has stripped it away.
   
In the GNU project, our aim is to give all users the freedom to
redistribute and change GNU software. If middlemen could strip off the
freedom, we might have many users, but those users would not have
freedom. So instead of putting GNU software in the public domain, we
@dfn{copyleft} it. Copyleft says that anyone who redistributes the
software, with or without changes, must pass along the freedom to
further copy and change it. Copyleft guarantees that every user has
freedom.
     
Copyleft also provides an incentive for other programmers to add to
free software. Important free programs such as the GNU C++ compiler
exist only because of this.
   
Copyleft also helps programmers who want to contribute improvements to
free software get permission to do that. These programmers often work
for companies or universities that would do almost anything to get
more money. A programmer may want to contribute her changes to the
community, but her employer may want to turn the changes into a
proprietary software product.
   
When we explain to the employer that it is illegal to distribute the
improved version except as free software, the employer usually decides
to release it as free software rather than throw it away.
   
To copyleft a program, first we copyright it; then we add distribution
terms, which are a legal instrument that gives everyone the rights to
use, modify, and redistribute the program's code or any program
derived from it but only if the distribution terms are unchanged.
Thus, the code and the freedoms become legally inseparable.
   
Proprietary software developers use copyright to take away the users'
freedom; we use copyright to guarantee their freedom. That's why we
reverse the name, changing ``copyright'' into ``copyleft.''
   
Copyleft is a general concept; there are many ways to fill in the
details. In the GNU Project, the specific distribution terms that we
use are contained in the GNU General Public License (GNU GPL). 
An alternate form, the GNU
Library General Public License 
(GNU LGPL), applies to a few (but not all) GNU libraries. The
license permits linking the libraries into proprietary
executables under certain conditions.
   
The appropriate license is included in many manuals and in each GNU
source code distribution (usually in files named @file{COPYING}
and @file{COPYING.LIB}).
   
The GNU GPL is designed so that you can easily apply it to your own
program if you are the copyright holder. You don't have to modify the
GNU GPL to do this, just add notices to your program which refer
properly to the GNU GPL.
   
If you would like to copyleft your program with the GNU GPL, please
see the instructions at the end of the GPL text. If
you would like to copyleft your library with the GNU LGPL, please see
the instructions at the end of the LGPL text 
(note you can also use the ordinary GPL for libraries).

Using the same distribution terms for many different programs makes it
easy to copy code between various different programs. Since they all
have the same distribution terms, there is no need to think about
whether the terms are compatible. The Library GPL includes a provision
that lets you alter the distribution terms to the ordinary GPL, so
that you can copy code into another program covered by the GPL.

@c ============================================================

@node Why you should use the GPL, The LGPL vs the GPL, What is Copyleft, Licensing Free Software
@section Why you should use the GPL

The GPL is not the only way to implement copyleft. However, as a practical
matter, it is convenient to standardize on using the GPL to copyleft 
software because that allows to copy source code from copylefted programs
and use it on other copylefted programs without worrying about license
compatibility. 

If you want your program to be free, then GPL grants all the permissions
that are necessary to make it free. Some people do not like the GPL because
they feel it gives too many permissions. In that case, these people do
not really want their program to be free. When they choose to use a more
restrictive license, as a result, they are effectively choosing not to be part
of the free software community. 

One very common restriction, that often comes up, is to allow free use only 
for ``non-commercial'' purposes. The idea behind such a restriction
is to prevent anyone from making any money without giving you a cut of their
profit. Copyleft actually also serves this goal, but from a different angle. 
The angle is that making money is only one of the many benefits that one
can derive from using a computer program, and it should not be discriminated
against all the other benefits. Copyleft however does prevent others from
making money by modifying your program and distributing it as proprietary
software with restrictive licensing. If person wants to distribute the program,
person also has to distribute the source code, in which case you benefit
by having access to per @emph{modifications}, or person has to negotiate
with you for special terms. 

Another peculiar restriction that often comes up is allowing use and
modification but @emph{requiring} the redistribution of any modified versions.
The reason why this is a peculiar restriction is because at first sight,
it doesn't sound that bad; it does sound like free software. 
The advocates of this idea explain that there
are certain situations where it is very anti-social to make a useful 
modification on a free program, use the program and benefit from it, and
not release it. However, if you legally require your users to
release any modifications they make, then this creates another problem,
especially when this requirement conflicts with privacy rights.
The public should be free to redistribute your program, but they
should also be free to choose not to redistribute the program at all. 
The fundamental idea behind copylefted works is that they are owned by
the public. But, ``the public'' is the individual, as much as it is
the entire community. Copyleft protects the community by forbidding 
hoarding, but the individual also deserves an equivalent protection; 
the protection of both their privacy and their freedom.

Some developers, who do want to be part of our community, use licenses
that do not restrict any of our freedoms but which ask for a ``favor''
from the user. An example of such a favor is to request that you change the
name of the program if you modify it, or to not use the name of some
organization in advertising. There is nothing ethically wrong with
asking for such favors. Requiring them legally however creates a serious
problem; it makes their terms incompatible with the terms of the GPL. 
It is very inefficient to inflict the price of such an incompatibility 
on our community for the sake of a favor. Instead, in almost all cases, it
is just as good an idea to ask for such favors in the documentation 
distributed with the program, where there is more latitude in what 
restrictions you can impose 
(@pxref{Why free software needs free documentation}).

Some people complain
that the GPL is ``too restrictive'' because it says no to software hoarding.
They say that this makes the program ``less free''. They say that 
``free flow of ideas'' means that you should not say no to anyone. 
If you would like to give your users more permissions, than provided by the
GPL, all you need to do is append the text of these permissions to the
copyright notices that you attach to every file; there is no need to 
write a new license from scratch. You can do this, if you
are the original author of the file. For files that were written by
others, you need their permission. In general, however, doing this is not 
a good idea. 

The GPL has been very carefully thought-out to only give 
permissions that give @emph{freedom} to the users, without allowing any
permissions that would give @emph{power} to some users to take freedom from
all of the other users. As a result, even though the terms say no to certain
things, doing so guarantees that the program remains free for all the users
in our community. The US constitution guarantees some of our rights by making
them @dfn{inalienable}. This means that no-one, not even the person 
entitled to the rights, is allowed to waive them. For example, you can't
waive your right to freedom and sell yourself as a slave. While this can
be seen as a restriction in terms of what you are allowed to do, the effect is
that this restriction gives you more freedom. It is not @emph{you} that
the restriction really is targetting, but all the people, that have power 
over you, that might have an interest in taking your freedom away. 

In many countries, other than the US, copyright law is not strictly 
enforced. As a result, the citizens in these countries can afford not
to care about copyright. However, the free software community trascends
nations and borders, and many of us do not have the same latitude. 
So, if you write a program that you want to share with other people,
please be clear about the copyright terms. The easiest way to do this
is by applying the terms of the GPL.

@c ============================================================

@node The LGPL vs the GPL,  , Why you should use the GPL, Licensing Free Software
@section The LGPL vs the GPL

The GNU Project has two principal licenses to use for libraries.  One
is the GNU Library GPL; the other is the ordinary GNU GPL.  The choice
of license makes a big difference: using the Library GPL permits use
of the library in proprietary programs; using the ordinary GPL for a
library makes it available only for free programs.

Which license is best for a given library is a matter of strategy, and
it depends on the details of the situation.  At present, most GNU
libraries are covered by the Library GPL, and that means we are using
only one of these two strategies, neglecting the other.  So we are
now seeking more libraries to release @emph{under the ordinary GPL}.

Proprietary software developers have the advantage of money; free
software developers need to make advantages for each other.  Using the
ordinary GPL for a library gives free software developers an advantage
over proprietary developers: a library that they can use, while
proprietary developers cannot use it.

Using the ordinary GPL is not advantageous for every library.  There
are reasons that can make it better to use the Library GPL in certain
cases.  The most common case is when a free library's features are
readily available for proprietary software through other alternative
libraries.  In that case, the library cannot give free software any
particular advantage, so it is better to use the Library GPL for that
library.

This is why we used the Library GPL for the GNU C library.  After all,
there are plenty of other C libraries; using the GPL for ours would
have driven proprietary software developers to use another--no problem
for them, only for us.

However, when a library provides a significant unique capability, like
GNU Readline, that's a horse of a different color.  The Readline
library implements input editing and history for interactive programs,
and that's a facility not generally available elsewhere.  Releasing it
under the GPL and limiting its use to free programs gives our
community a real boost.  At least one application program is free
software today specifically because that was necessary for using
Readline.

If we amass a collection of powerful GPL-covered libraries that have
no parallel available to proprietary software, they will provide a
range of useful modules to serve as building blocks in new free
programs.  This will be a significant advantage for further free
software development, and some projects will decide to make software
free in order to use these libraries.  University projects can easily
be influenced; nowadays, as companies begin to consider making
software free, even some commercial projects can be influenced in this
way.

Proprietary software developers, seeking to deny the free competition
an important advantage, will try to convince authors not to contribute
libraries to the GPL-covered collection.  For example, they may appeal
to the ego, promising ``more users for this library'' if we let them use
the code in proprietary software products.  Popularity is tempting,
and it is easy for a library developer to rationalize the idea that
boosting the popularity of that one library is what the community
needs above all.

But we should not listen to these temptations, because we can achieve
much more if we stand together.  We free software developers should
support one another.  By releasing libraries that are limited to free
software only, we can help each other's free software packages outdo
the proprietary alternatives.  The whole free software movement will
have more popularity, because free software as a whole will stack up
better against the competition.

Since the name ``Library GPL'' conveys the wrong idea about this
question, we are planning to change the name to ``Lesser GPL.''
Actually implementing the name change may take some time, but you
don't have to wait--you can release GPL-covered libraries now.

@c ============================================================
@c ============================================================
@cindex warranty
@cindex copyright
@node GNU GENERAL PUBLIC LICENSE,  , Licensing Free Software, Top
@appendix GNU GENERAL PUBLIC LICENSE
@center Version 2, June 1991

@display
Copyright @copyright{} 1989, 1991 Free Software Foundation, Inc.
59 Temple Place - Suite 330, Boston, MA  02111-1307, USA

Everyone is permitted to copy and distribute verbatim copies
of this license document, but changing it is not allowed.
@end display

@appendixsec Preamble

  The licenses for most software are designed to take away your
freedom to share and change it.  By contrast, the GNU General Public
License is intended to guarantee your freedom to share and change free
software---to make sure the software is free for all its users.  This
General Public License applies to most of the Free Software
Foundation's software and to any other program whose authors commit to
using it.  (Some other Free Software Foundation software is covered by
the GNU Library General Public License instead.)  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
this service if you wish), that you receive source code or can get it
if you want it, that you can change the software or use pieces of it
in new free programs; and that you know you can do these things.

  To protect your rights, we need to make restrictions that forbid
anyone to deny you these rights or to ask you to surrender the rights.
These restrictions translate to certain responsibilities for you if you
distribute copies of the software, or if you modify it.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must give the recipients all the rights that
you have.  You must make sure that they, too, receive or can get the
source code.  And you must show them these terms so they know their
rights.

  We protect your rights with two steps: (1) copyright the software, and
(2) offer you this license which gives you legal permission to copy,
distribute and/or modify the software.

  Also, for each author's protection and ours, we want to make certain
that everyone understands that there is no warranty for this free
software.  If the software is modified by someone else and passed on, we
want its recipients to know that what they have is not the original, so
that any problems introduced by others will not reflect on the original
authors' reputations.

  Finally, any free program is threatened constantly by software
patents.  We wish to avoid the danger that redistributors of a free
program will individually obtain patent licenses, in effect making the
program proprietary.  To prevent this, we have made it clear that any
patent must be licensed for everyone's free use or not licensed at all.

  The precise terms and conditions for copying, distribution and
modification follow.

@iftex
@appendixsec TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
@end iftex
@ifinfo
@center TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
@end ifinfo

@enumerate 0
@item
This License applies to any program or other work which contains
a notice placed by the copyright holder saying it may be distributed
under the terms of this General Public License.  The ``Program'', below,
refers to any such program or work, and a ``work based on the Program''
means either the Program or any derivative work under copyright law:
that is to say, a work containing the Program or a portion of it,
either verbatim or with modifications and/or translated into another
language.  (Hereinafter, translation is included without limitation in
the term ``modification''.)  Each licensee is addressed as ``you''.

Activities other than copying, distribution and modification are not
covered by this License; they are outside its scope.  The act of
running the Program is not restricted, and the output from the Program
is covered only if its contents constitute a work based on the
Program (independent of having been made by running the Program).
Whether that is true depends on what the Program does.

@item
You may copy and distribute verbatim copies of the Program's
source code as you receive it, in any medium, provided that you
conspicuously and appropriately publish on each copy an appropriate
copyright notice and disclaimer of warranty; keep intact all the
notices that refer to this License and to the absence of any warranty;
and give any other recipients of the Program a copy of this License
along with the Program.

You may charge a fee for the physical act of transferring a copy, and
you may at your option offer warranty protection in exchange for a fee.

@item
You may modify your copy or copies of the Program or any portion
of it, thus forming a work based on the Program, and copy and
distribute such modifications or work under the terms of Section 1
above, provided that you also meet all of these conditions:

@enumerate a
@item
You must cause the modified files to carry prominent notices
stating that you changed the files and the date of any change.

@item
You must cause any work that you distribute or publish, that in
whole or in part contains or is derived from the Program or any
part thereof, to be licensed as a whole at no charge to all third
parties under the terms of this License.

@item
If the modified program normally reads commands interactively
when run, you must cause it, when started running for such
interactive use in the most ordinary way, to print or display an
announcement including an appropriate copyright notice and a
notice that there is no warranty (or else, saying that you provide
a warranty) and that users may redistribute the program under
these conditions, and telling the user how to view a copy of this
License.  (Exception: if the Program itself is interactive but
does not normally print such an announcement, your work based on
the Program is not required to print an announcement.)
@end enumerate

These requirements apply to the modified work as a whole.  If
identifiable sections of that work are not derived from the Program,
and can be reasonably considered independent and separate works in
themselves, then this License, and its terms, do not apply to those
sections when you distribute them as separate works.  But when you
distribute the same sections as part of a whole which is a work based
on the Program, the distribution of the whole must be on the terms of
this License, whose permissions for other licensees extend to the
entire whole, and thus to each and every part regardless of who wrote it.

Thus, it is not the intent of this section to claim rights or contest
your rights to work written entirely by you; rather, the intent is to
exercise the right to control the distribution of derivative or
collective works based on the Program.

In addition, mere aggregation of another work not based on the Program
with the Program (or with a work based on the Program) on a volume of
a storage or distribution medium does not bring the other work under
the scope of this License.

@item
You may copy and distribute the Program (or a work based on it,
under Section 2) in object code or executable form under the terms of
Sections 1 and 2 above provided that you also do one of the following:

@enumerate a
@item
Accompany it with the complete corresponding machine-readable
source code, which must be distributed under the terms of Sections
1 and 2 above on a medium customarily used for software interchange; or,

@item
Accompany it with a written offer, valid for at least three
years, to give any third party, for a charge no more than your
cost of physically performing source distribution, a complete
machine-readable copy of the corresponding source code, to be
distributed under the terms of Sections 1 and 2 above on a medium
customarily used for software interchange; or,

@item
Accompany it with the information you received as to the offer
to distribute corresponding source code.  (This alternative is
allowed only for noncommercial distribution and only if you
received the program in object code or executable form with such
an offer, in accord with Subsection b above.)
@end enumerate

The source code for a work means the preferred form of the work for
making modifications to it.  For an executable work, complete source
code means all the source code for all modules it contains, plus any
associated interface definition files, plus the scripts used to
control compilation and installation of the executable.  However, as a
special exception, the source code distributed need not include
anything that is normally distributed (in either source or binary
form) with the major components (compiler, kernel, and so on) of the
operating system on which the executable runs, unless that component
itself accompanies the executable.

If distribution of executable or object code is made by offering
access to copy from a designated place, then offering equivalent
access to copy the source code from the same place counts as
distribution of the source code, even though third parties are not
compelled to copy the source along with the object code.

@item
You may not copy, modify, sublicense, or distribute the Program
except as expressly provided under this License.  Any attempt
otherwise to copy, modify, sublicense or distribute the Program is
void, and will automatically terminate your rights under this License.
However, parties who have received copies, or rights, from you under
this License will not have their licenses terminated so long as such
parties remain in full compliance.

@item
You are not required to accept this License, since you have not
signed it.  However, nothing else grants you permission to modify or
distribute the Program or its derivative works.  These actions are
prohibited by law if you do not accept this License.  Therefore, by
modifying or distributing the Program (or any work based on the
Program), you indicate your acceptance of this License to do so, and
all its terms and conditions for copying, distributing or modifying
the Program or works based on it.

@item
Each time you redistribute the Program (or any work based on the
Program), the recipient automatically receives a license from the
original licensor to copy, distribute or modify the Program subject to
these terms and conditions.  You may not impose any further
restrictions on the recipients' exercise of the rights granted herein.
You are not responsible for enforcing compliance by third parties to
this License.

@item
If, as a consequence of a court judgment or allegation of patent
infringement or for any other reason (not limited to patent issues),
conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot
distribute so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you
may not distribute the Program at all.  For example, if a patent
license would not permit royalty-free redistribution of the Program by
all those who receive copies directly or indirectly through you, then
the only way you could satisfy both it and this License would be to
refrain entirely from distribution of the Program.

If any portion of this section is held invalid or unenforceable under
any particular circumstance, the balance of the section is intended to
apply and the section as a whole is intended to apply in other
circumstances.

It is not the purpose of this section to induce you to infringe any
patents or other property right claims or to contest validity of any
such claims; this section has the sole purpose of protecting the
integrity of the free software distribution system, which is
implemented by public license practices.  Many people have made
generous contributions to the wide range of software distributed
through that system in reliance on consistent application of that
system; it is up to the author/donor to decide if he or she is willing
to distribute software through any other system and a licensee cannot
impose that choice.

This section is intended to make thoroughly clear what is believed to
be a consequence of the rest of this License.

@item
If the distribution and/or use of the Program is restricted in
certain countries either by patents or by copyrighted interfaces, the
original copyright holder who places the Program under this License
may add an explicit geographical distribution limitation excluding
those countries, so that distribution is permitted only in or among
countries not thus excluded.  In such case, this License incorporates
the limitation as if written in the body of this License.

@item
The Free Software Foundation may publish revised and/or new versions
of the General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

Each version is given a distinguishing version number.  If the Program
specifies a version number of this License which applies to it and ``any
later version'', you have the option of following the terms and conditions
either of that version or of any later version published by the Free
Software Foundation.  If the Program does not specify a version number of
this License, you may choose any version ever published by the Free Software
Foundation.

@item
If you wish to incorporate parts of the Program into other free
programs whose distribution conditions are different, write to the author
to ask for permission.  For software which is copyrighted by the Free
Software Foundation, write to the Free Software Foundation; we sometimes
make exceptions for this.  Our decision will be guided by the two goals
of preserving the free status of all derivatives of our free software and
of promoting the sharing and reuse of software generally.

@iftex
@heading NO WARRANTY
@end iftex
@ifinfo
@center NO WARRANTY
@end ifinfo

@item
BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
PROVIDE THE PROGRAM ``AS IS'' WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
REPAIR OR CORRECTION.

@item
IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
POSSIBILITY OF SUCH DAMAGES.
@end enumerate

@iftex
@heading END OF TERMS AND CONDITIONS
@end iftex
@ifinfo
@center END OF TERMS AND CONDITIONS
@end ifinfo

@page
@appendixsec Appendix: How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
convey the exclusion of warranty; and each file should have at least
the ``copyright'' line and a pointer to where the full notice is found.

@smallexample
@var{one line to give the program's name and a brief idea of what it does.}
Copyright (C) 19@var{yy}  @var{name of author}

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
02111-1307, USA.
@end smallexample

Also add information on how to contact you by electronic and paper mail.

If the program is interactive, make it output a short notice like this
when it starts in an interactive mode:

@smallexample
Gnomovision version 69, Copyright (C) 19@var{yy} @var{name of author}
Gnomovision comes with ABSOLUTELY NO WARRANTY; for details
type `show w'.  This is free software, and you are welcome
to redistribute it under certain conditions; type `show c'
for details.
@end smallexample

The hypothetical commands @samp{show w} and @samp{show c} should show
the appropriate parts of the General Public License.  Of course, the
commands you use may be called something other than @samp{show w} and
@samp{show c}; they could even be mouse-clicks or menu items---whatever
suits your program.

You should also get your employer (if you work as a programmer) or your
school, if any, to sign a ``copyright disclaimer'' for the program, if
necessary.  Here is a sample; alter the names:

@example
Yoyodyne, Inc., hereby disclaims all copyright interest in the program
`Gnomovision' (which makes passes at compilers) written by James Hacker.

@var{signature of Ty Coon}, 1 April 1989
Ty Coon, President of Vice
@end example

This General Public License does not permit incorporating your program into
proprietary programs.  If your program is a subroutine library, you may
consider it more useful to permit linking proprietary applications with the
library.  If this is what you want to do, use the GNU Library General
Public License instead of this License.

@c ================ Biographical information ================

@iftex
@tex
\ifodd\pageno 
    \par\vfill\supereject
    \global\evenheadline={\hfil} \global\evenfootline={\hfil}
    \global\oddheadline={\hfil} \global\oddfootline={\hfil}
    \page\hbox{}\page
\else
    \par\vfill\supereject
    \par\vfill\supereject
    \global\evenheadline={\hfil} \global\evenfootline={\hfil}
    \global\oddheadline={\hfil} \global\oddfootline={\hfil}
    \page\hbox{}\page
    \page\hbox{}\page
\fi
@end tex
@w{ }
@sp 8
@center About the Author
@sp 1

@quotation
Eleftherios Gkioulekas has received his Bachelors in Applied Mathematics
from the California Institute of Technology. He is now a graduate student,
contributing slave labor in exchange for poverty-level wages, and hopefully
a degree, at the department of Applied Mathematics in the University of 
Washington.
He loves Elif Akcetin, computers, mathematics, and comic books.
He uses Debian GNU/Linux and he is a Saint of the Church of Emacs;
his computer runs completely on free software.

If you have enjoyed this manual, then please send a donation to the
author:
@quotation
Eleftherios Gkioulekas @*
408 Guggenheim Hall @*
Box 352420 @*
University of Washington @*
Seattle, WA 98195 @*
@end quotation
To send comments to the author, email 
@email{lf@@amath.washington.edu}
@end quotation
@end iftex
@bye
